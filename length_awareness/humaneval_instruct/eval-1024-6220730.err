The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2025-11-10:14:14:28 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:14:28 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:14:28 INFO     [__main__:450] Selected Tasks: ['humaneval_instruct']
2025-11-10:14:14:28 INFO     [__main__:450] Selected Tasks: ['humaneval_instruct']
2025-11-10:14:14:28 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:14:28 INFO     [__main__:450] Selected Tasks: ['humaneval_instruct']
2025-11-10:14:14:28 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:14:28 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:14:28 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:14:28 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 14:14:28.935636966 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 14:14:28.935639963 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:14:28 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:14:28 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 14:14:28.941701453 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:14:28 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:14:28 INFO     [__main__:450] Selected Tasks: ['humaneval_instruct']
2025-11-10:14:14:28 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:14:28 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:14:28 INFO     [__main__:450] Selected Tasks: ['humaneval_instruct']
2025-11-10:14:14:28 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:14:28 INFO     [__main__:450] Selected Tasks: ['humaneval_instruct']
2025-11-10:14:14:28 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:14:28 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
[W1110 14:14:28.220841841 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:14:28 INFO     [__main__:450] Selected Tasks: ['humaneval_instruct']
2025-11-10:14:14:28 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:14:28 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:14:28 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:14:28 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:14:28 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
[W1110 14:14:28.232858888 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:14:28 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
[W1110 14:14:28.233973857 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:14:28 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:14:28 INFO     [__main__:450] Selected Tasks: ['humaneval_instruct']
[W1110 14:14:28.238973477 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:14:28 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:14:28 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 14:14:28.252667956 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:14:28 WARNING  [accelerate.utils.other:441] Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.13it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.14it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.12it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.12it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.12it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.12it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.13it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.09it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.12s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.25s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.25s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.23s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.26s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.26s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.26s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.26s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.28s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.24s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.27s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.28s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.27s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.28s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.27s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.28s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.28s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.29s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.29s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.29s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.29s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]





[rank3]:[W1110 14:14:40.070810338 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank4]:[W1110 14:14:40.070956272 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank6]:[W1110 14:14:40.071045240 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank2]:[W1110 14:14:40.071092577 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank7]:[W1110 14:14:40.071134125 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank5]:[W1110 14:14:40.071167447 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank0]:[W1110 14:14:40.071168441 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank1]:[W1110 14:14:40.071246181 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:14:56 INFO     [evaluator:305] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-11-10:14:14:56 INFO     [evaluator:320] num_fewshot has been set to 0 for humaneval_instruct in its config. Manual configuration will be ignored.
2025-11-10:14:14:56 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:14:56 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 7...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 847.71it/s]
2025-11-10:14:14:58 INFO     [evaluator:305] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-11-10:14:14:58 INFO     [evaluator:320] num_fewshot has been set to 0 for humaneval_instruct in its config. Manual configuration will be ignored.
2025-11-10:14:14:58 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:14:58 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 5...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 839.03it/s]
2025-11-10:14:14:58 INFO     [evaluator:305] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-11-10:14:14:58 INFO     [evaluator:320] num_fewshot has been set to 0 for humaneval_instruct in its config. Manual configuration will be ignored.
2025-11-10:14:14:58 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:14:58 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 2...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 846.60it/s]
2025-11-10:14:14:58 INFO     [evaluator:305] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-11-10:14:14:58 INFO     [evaluator:320] num_fewshot has been set to 0 for humaneval_instruct in its config. Manual configuration will be ignored.
2025-11-10:14:14:58 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:14:58 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 4...
2025-11-10:14:14:58 INFO     [evaluator:305] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-11-10:14:14:58 INFO     [evaluator:320] num_fewshot has been set to 0 for humaneval_instruct in its config. Manual configuration will be ignored.
  0%|          | 0/10 [00:00<?, ?it/s]2025-11-10:14:14:58 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:14:58 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 831.97it/s]
100%|██████████| 10/10 [00:00<00:00, 808.81it/s]
2025-11-10:14:14:58 INFO     [evaluator:305] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-11-10:14:14:58 INFO     [evaluator:320] num_fewshot has been set to 0 for humaneval_instruct in its config. Manual configuration will be ignored.
2025-11-10:14:14:58 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:14:58 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 840.61it/s]
2025-11-10:14:14:58 INFO     [evaluator:305] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-11-10:14:14:58 INFO     [evaluator:320] num_fewshot has been set to 0 for humaneval_instruct in its config. Manual configuration will be ignored.
2025-11-10:14:14:58 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:14:58 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 843.04it/s]
2025-11-10:14:15:00 INFO     [evaluator:305] humaneval_instruct: Using gen_kwargs: {'until': ['\nclass', '\ndef', '\n#', '\nif', '\nprint'], 'max_gen_toks': 1024, 'do_sample': False}
2025-11-10:14:15:00 INFO     [evaluator:320] num_fewshot has been set to 0 for humaneval_instruct in its config. Manual configuration will be ignored.
2025-11-10:14:15:00 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:15:00 INFO     [api.task:434] Building contexts for humaneval_instruct on rank 3...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 850.60it/s]
2025-11-10:14:15:00 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:15:00 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:15:00 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:15:00 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:15:00 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:15:00 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:15:00 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:15:00 INFO     [evaluator:574] Running generate_until requests
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7effdc0b2560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:15:03 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7effdc0b2560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f3f20146560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/10 [00:00<?, ? examples/s]2025-11-10:14:15:03 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f3f20146560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f7444152560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:15:03 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f7444152560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fc2b5f5a560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/10 [00:00<?, ? examples/s]2025-11-10:14:15:03 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fc2b5f5a560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fd81c08e560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:15:03 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fd81c08e560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map: 100%|██████████| 10/10 [00:00<00:00, 855.16 examples/s]
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Generating...:   0%|          | 0/10 [00:00<?, ?it/s]Map: 100%|██████████| 10/10 [00:00<00:00, 818.38 examples/s]
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fa5c4d32560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Generating...:   0%|          | 0/10 [00:00<?, ?it/s]2025-11-10:14:15:03 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fa5c4d32560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f24dfe0a560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:15:03 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f24dfe0a560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 956.64 examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f8b9ffba560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.

Map:   0%|          | 0/10 [00:00<?, ? examples/s]2025-11-10:14:15:03 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f8b9ffba560> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Generating...:   0%|          | 0/10 [00:00<?, ?it/s]Map:   0%|          | 0/10 [00:00<?, ? examples/s]Map: 100%|██████████| 10/10 [00:00<00:00, 770.62 examples/s]
Generating...:   0%|          | 0/10 [00:00<?, ?it/s]Map: 100%|██████████| 10/10 [00:00<00:00, 856.29 examples/s]
Generating...:   0%|          | 0/10 [00:00<?, ?it/s]Map: 100%|██████████| 10/10 [00:00<00:00, 901.34 examples/s]
Generating...:   0%|          | 0/10 [00:00<?, ?it/s]Map: 100%|██████████| 10/10 [00:00<00:00, 762.92 examples/s]
Generating...:   0%|          | 0/10 [00:00<?, ?it/s]Map: 100%|██████████| 10/10 [00:00<00:00, 765.86 examples/s]
Generating...:   0%|          | 0/10 [00:00<?, ?it/s]Generating...:  10%|█         | 1/10 [02:13<20:00, 133.39s/it]Generating...:  10%|█         | 1/10 [02:13<20:00, 133.39s/it]Generating...:  10%|█         | 1/10 [02:13<20:00, 133.41s/it]Generating...:  10%|█         | 1/10 [02:13<20:00, 133.41s/it]Generating...:  10%|█         | 1/10 [02:13<20:00, 133.40s/it]Generating...:  10%|█         | 1/10 [02:13<20:00, 133.40s/it]Generating...:  10%|█         | 1/10 [02:13<20:00, 133.39s/it]Generating...:  10%|█         | 1/10 [02:13<20:00, 133.39s/it]Generating...:  20%|██        | 2/10 [04:33<18:19, 137.38s/it]Generating...:  20%|██        | 2/10 [04:33<18:18, 137.37s/it]Generating...:  20%|██        | 2/10 [04:33<18:18, 137.37s/it]Generating...:  20%|██        | 2/10 [04:33<18:18, 137.37s/it]Generating...:  20%|██        | 2/10 [04:33<18:18, 137.37s/it]Generating...:  20%|██        | 2/10 [04:33<18:18, 137.37s/it]Generating...:  20%|██        | 2/10 [04:33<18:18, 137.37s/it]Generating...:  20%|██        | 2/10 [04:33<18:18, 137.37s/it]Generating...:  30%|███       | 3/10 [06:58<16:25, 140.73s/it]Generating...:  30%|███       | 3/10 [06:58<16:25, 140.74s/it]Generating...:  30%|███       | 3/10 [06:58<16:25, 140.74s/it]Generating...:  30%|███       | 3/10 [06:58<16:25, 140.73s/it]Generating...:  30%|███       | 3/10 [06:58<16:25, 140.73s/it]Generating...:  30%|███       | 3/10 [06:58<16:25, 140.73s/it]Generating...:  30%|███       | 3/10 [06:58<16:25, 140.73s/it]Generating...:  30%|███       | 3/10 [06:58<16:25, 140.73s/it]Generating...:  40%|████      | 4/10 [09:08<13:40, 136.73s/it]Generating...:  40%|████      | 4/10 [09:08<13:40, 136.73s/it]Generating...:  40%|████      | 4/10 [09:08<13:40, 136.73s/it]Generating...:  40%|████      | 4/10 [09:08<13:40, 136.73s/it]Generating...:  40%|████      | 4/10 [09:08<13:40, 136.73s/it]Generating...:  40%|████      | 4/10 [09:08<13:40, 136.73s/it]Generating...:  40%|████      | 4/10 [09:08<13:40, 136.73s/it]Generating...:  40%|████      | 4/10 [09:08<13:40, 136.73s/it]Generating...:  50%|█████     | 5/10 [11:41<11:53, 142.61s/it]Generating...:  50%|█████     | 5/10 [11:41<11:53, 142.61s/it]Generating...:  50%|█████     | 5/10 [11:41<11:53, 142.61s/it]Generating...:  50%|█████     | 5/10 [11:41<11:53, 142.61s/it]Generating...:  50%|█████     | 5/10 [11:41<11:53, 142.62s/it]Generating...:  50%|█████     | 5/10 [11:41<11:53, 142.61s/it]Generating...:  50%|█████     | 5/10 [11:41<11:53, 142.61s/it]Generating...:  50%|█████     | 5/10 [11:41<11:53, 142.61s/it]Generating...:  60%|██████    | 6/10 [14:02<09:27, 141.84s/it]Generating...:  60%|██████    | 6/10 [14:02<09:27, 141.84s/it]Generating...:  60%|██████    | 6/10 [14:02<09:27, 141.84s/it]Generating...:  60%|██████    | 6/10 [14:02<09:27, 141.84s/it]Generating...:  60%|██████    | 6/10 [14:02<09:27, 141.84s/it]Generating...:  60%|██████    | 6/10 [14:02<09:27, 141.84s/it]Generating...:  60%|██████    | 6/10 [14:02<09:27, 141.84s/it]Generating...:  60%|██████    | 6/10 [14:02<09:27, 141.84s/it]Generating...:  70%|███████   | 7/10 [16:14<06:55, 138.64s/it]Generating...:  70%|███████   | 7/10 [16:14<06:55, 138.64s/it]Generating...:  70%|███████   | 7/10 [16:14<06:55, 138.64s/it]Generating...:  70%|███████   | 7/10 [16:14<06:55, 138.64s/it]Generating...:  70%|███████   | 7/10 [16:14<06:55, 138.64s/it]Generating...:  70%|███████   | 7/10 [16:14<06:55, 138.64s/it]Generating...:  70%|███████   | 7/10 [16:14<06:55, 138.64s/it]Generating...:  70%|███████   | 7/10 [16:14<06:55, 138.64s/it]Generating...:  80%|████████  | 8/10 [18:28<04:34, 137.35s/it]Generating...:  80%|████████  | 8/10 [18:28<04:34, 137.35s/it]Generating...:  80%|████████  | 8/10 [18:28<04:34, 137.35s/it]Generating...:  80%|████████  | 8/10 [18:28<04:34, 137.35s/it]Generating...:  80%|████████  | 8/10 [18:28<04:34, 137.35s/it]Generating...:  80%|████████  | 8/10 [18:28<04:34, 137.35s/it]Generating...:  80%|████████  | 8/10 [18:28<04:34, 137.35s/it]Generating...:  80%|████████  | 8/10 [18:28<04:34, 137.35s/it]Generating...:  90%|█████████ | 9/10 [21:30<02:31, 151.12s/it]Generating...:  90%|█████████ | 9/10 [21:30<02:31, 151.12s/it]Generating...:  90%|█████████ | 9/10 [21:30<02:31, 151.12s/it]Generating...:  90%|█████████ | 9/10 [21:30<02:31, 151.12s/it]Generating...:  90%|█████████ | 9/10 [21:30<02:31, 151.12s/it]Generating...:  90%|█████████ | 9/10 [21:30<02:31, 151.12s/it]Generating...:  90%|█████████ | 9/10 [21:30<02:31, 151.12s/it]Generating...:  90%|█████████ | 9/10 [21:30<02:31, 151.12s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 158.33s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 158.33s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 158.33s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 158.33s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 158.33s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 158.33s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 158.33s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 158.33s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 146.48s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 146.48s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 146.48s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 146.48s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 146.48s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 146.48s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 146.48s/it]Generating...: 100%|██████████| 10/10 [24:24<00:00, 146.48s/it]







[rank7]:W1110 14:39:30.924000 46194 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37893 hash value: 2274409662826903120
[rank3]:W1110 14:39:34.688000 46190 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40158 hash value: 15240087177115683648
[rank0]:W1110 14:39:34.958000 46187 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 47442 hash value: 11081330107098173230
[rank2]:W1110 14:39:37.008000 46189 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34433 hash value: 11599163167111788420
[rank6]:W1110 14:39:37.547000 46193 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40529 hash value: 3884756332146360410
[rank4]:W1110 14:39:38.348000 46191 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 42174 hash value: 2513837292474328517
[rank5]:W1110 14:39:38.574000 46192 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41512 hash value: 13856147733537024152
[rank1]:W1110 14:39:39.571000 46188 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40385 hash value: 5204844989789853236
[rank0]:W1110 14:39:39.770000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47442 hash value: 14375105916140447233
[rank0]:W1110 14:39:39.774000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47442 hash value: 14375105916140447233
[rank0]:W1110 14:39:39.776000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47442 hash value: 14375105916140447233
[rank6]:W1110 14:39:39.777000 46193 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 291 hash value: 10462387475064696176
[rank3]:W1110 14:39:39.777000 46190 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 291 hash value: 1892600311987657058
[rank1]:W1110 14:39:39.777000 46188 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 291 hash value: 11888772715519004810
[rank7]:W1110 14:39:39.777000 46194 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 291 hash value: 7986107118602456524
[rank5]:W1110 14:39:39.777000 46192 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 291 hash value: 9686548071315526909
[rank2]:W1110 14:39:39.777000 46189 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 291 hash value: 5032981802388863815
[rank4]:W1110 14:39:39.777000 46191 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 291 hash value: 14712373174771148005
[rank0]:W1110 14:39:39.778000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47442 hash value: 14375105916140447233
[rank0]:W1110 14:39:39.783000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47442 hash value: 14375105916140447233
[rank0]:W1110 14:39:39.785000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47442 hash value: 14375105916140447233
[rank0]:W1110 14:39:39.788000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47442 hash value: 14375105916140447233
[rank0]:W1110 14:39:39.790000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47442 hash value: 14375105916140447233
[rank0]:W1110 14:39:39.791000 46187 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 291 hash value: 6102112901267973909
[rank0]:W1110 14:39:39.796000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 291 hash value: 10169073017162043085
[rank0]:W1110 14:39:39.797000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 291 hash value: 10169073017162043085
[rank0]:W1110 14:39:39.798000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 291 hash value: 10169073017162043085
[rank0]:W1110 14:39:39.799000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 291 hash value: 10169073017162043085
[rank0]:W1110 14:39:39.800000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 291 hash value: 10169073017162043085
[rank0]:W1110 14:39:39.801000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 291 hash value: 10169073017162043085
[rank0]:W1110 14:39:39.802000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 291 hash value: 10169073017162043085
[rank0]:W1110 14:39:39.803000 46187 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 291 hash value: 10169073017162043085
2025-11-10:14:39:47 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
2025-11-10:14:39:47 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: humaneval_instruct
[rank0]:[W1110 14:39:48.782707113 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
