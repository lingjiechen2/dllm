The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2025-11-10:14:04:51 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:51 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:51 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:51 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:51 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:51 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:51 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 256, 'steps': 256, 'block_length': 256, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:04:51 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 256, 'steps': 256, 'block_length': 256, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 14:04:51.298301595 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 14:04:51.298304385 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:51 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:51 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:51 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:51 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:52 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:52 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:52 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:52 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:52 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:52 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:52 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:52 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:52 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:52 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 256, 'steps': 256, 'block_length': 256, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:04:52 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:52 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 256, 'steps': 256, 'block_length': 256, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:04:52 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:52 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 256, 'steps': 256, 'block_length': 256, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 14:04:52.610533629 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 14:04:52.611534494 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:52 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:52 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 256, 'steps': 256, 'block_length': 256, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:14:04:52 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:52 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 256, 'steps': 256, 'block_length': 256, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 14:04:52.613642934 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:52 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
[W1110 14:04:52.616768569 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:52 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 256, 'steps': 256, 'block_length': 256, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 14:04:52.617848613 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 14:04:52.621483102 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:52 WARNING  [accelerate.utils.other:441] Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:10,  2.16s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.24s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.29s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.29s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.31s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.62s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.64s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.65s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.66s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.73s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.76s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.79s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.78s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.79s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.80s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.78s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:08<00:08,  2.79s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.71s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.74s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.75s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.75s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.74s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.74s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.76s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.75s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.66s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.68s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.43s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.55s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.44s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.55s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.45s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.45s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.46s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.45s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.45s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.45s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.56s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.57s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.56s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.57s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.57s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:15<00:00,  2.56s/it]




[rank4]:[W1110 14:05:12.632186198 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank1]:[W1110 14:05:12.632646324 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank3]:[W1110 14:05:12.675679547 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank6]:[W1110 14:05:12.675763431 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank5]:[W1110 14:05:12.675842537 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank7]:[W1110 14:05:12.676022481 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank2]:[W1110 14:05:12.676206699 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank0]:[W1110 14:05:12.676642467 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:29 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:29 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 5...
  0%|          | 0/10 [00:00<?, ?it/s]2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:29 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:29 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 0...
100%|██████████| 10/10 [00:00<00:00, 355.09it/s]
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 361.32it/s]
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:29 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:29 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 2...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 360.94it/s]
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:29 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:29 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:29 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:30 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 4...
  0%|          | 0/10 [00:00<?, ?it/s]2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:30 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
100%|██████████| 10/10 [00:00<00:00, 354.48it/s]
2025-11-10:14:05:30 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 6...
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
  0%|          | 0/10 [00:00<?, ?it/s]2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:30 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:30 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 7...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 354.82it/s]
100%|██████████| 10/10 [00:00<00:00, 363.89it/s]
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:30 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:30 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:30 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 3...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 347.94it/s]
2025-11-10:14:05:32 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:32 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:32 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:32 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:32 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:32 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:32 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:32 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 346.95it/s]
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 1...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 3...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 7...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 2...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 5...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 4...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 0...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 411.03it/s]
100%|██████████| 10/10 [00:00<00:00, 408.61it/s]
100%|██████████| 10/10 [00:00<00:00, 398.67it/s]100%|██████████| 10/10 [00:00<00:00, 394.74it/s]
100%|██████████| 10/10 [00:00<00:00, 392.60it/s]100%|██████████| 10/10 [00:00<00:00, 397.62it/s]
100%|██████████| 10/10 [00:00<00:00, 389.80it/s]

100%|██████████| 10/10 [00:00<00:00, 381.89it/s]

2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 6...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 5...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 4...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 3...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 7...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 2...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 1...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 407.50it/s]100%|██████████| 10/10 [00:00<00:00, 396.98it/s]
100%|██████████| 10/10 [00:00<00:00, 401.59it/s]
100%|██████████| 10/10 [00:00<00:00, 393.75it/s]
100%|██████████| 10/10 [00:00<00:00, 392.47it/s]100%|██████████| 10/10 [00:00<00:00, 382.51it/s]
100%|██████████| 10/10 [00:00<00:00, 387.64it/s]100%|██████████| 10/10 [00:00<00:00, 385.20it/s]



2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 5...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 2...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 3...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 4...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 6...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 7...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 0...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 420.09it/s]100%|██████████| 10/10 [00:00<00:00, 409.57it/s]

100%|██████████| 10/10 [00:00<00:00, 404.82it/s]100%|██████████| 10/10 [00:00<00:00, 397.14it/s]100%|██████████| 10/10 [00:00<00:00, 400.13it/s]100%|██████████| 10/10 [00:00<00:00, 404.81it/s]

100%|██████████| 10/10 [00:00<00:00, 398.42it/s]

100%|██████████| 10/10 [00:00<00:00, 390.04it/s]

2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 5...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 2...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 4...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 3...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 6...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 7...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 1...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 410.52it/s]
100%|██████████| 10/10 [00:00<00:00, 394.15it/s]100%|██████████| 10/10 [00:00<00:00, 404.07it/s]
100%|██████████| 10/10 [00:00<00:00, 395.77it/s]
100%|██████████| 10/10 [00:00<00:00, 398.88it/s]
100%|██████████| 10/10 [00:00<00:00, 390.93it/s]
100%|██████████| 10/10 [00:00<00:00, 382.64it/s]100%|██████████| 10/10 [00:00<00:00, 364.63it/s]


2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 0...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 7...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 1...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 6...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 2...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 3...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 4...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 5...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 412.41it/s]
100%|██████████| 10/10 [00:00<00:00, 409.86it/s]100%|██████████| 10/10 [00:00<00:00, 413.86it/s]
100%|██████████| 10/10 [00:00<00:00, 405.62it/s]
100%|██████████| 10/10 [00:00<00:00, 402.39it/s]100%|██████████| 10/10 [00:00<00:00, 400.22it/s]
100%|██████████| 10/10 [00:00<00:00, 398.18it/s]
100%|██████████| 10/10 [00:00<00:00, 391.14it/s]


2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 7...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 6...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 1...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 2...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 5...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 3...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 0...
2025-11-10:14:05:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 4...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 411.66it/s]100%|██████████| 10/10 [00:00<00:00, 415.25it/s]100%|██████████| 10/10 [00:00<00:00, 418.25it/s]


100%|██████████| 10/10 [00:00<00:00, 403.50it/s]100%|██████████| 10/10 [00:00<00:00, 395.60it/s]100%|██████████| 10/10 [00:00<00:00, 399.25it/s]
100%|██████████| 10/10 [00:00<00:00, 391.64it/s]100%|██████████| 10/10 [00:00<00:00, 394.87it/s]



2025-11-10:14:05:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:32 INFO     [evaluator:574] Running generate_until requests
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fc6901c7400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fc6901c7400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f371015f400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f371015f400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fbbd5c77490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fbbd5c77490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fb2dc13b0a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fb2dc13b0a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f0650093400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f0650093400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f66400a7400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f96c0127400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f66400a7400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f96c0127400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f4f1c127400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:14:05:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f4f1c127400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 698.12 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 686.69 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 676.50 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 699.18 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 681.13 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 671.03 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 683.52 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 673.36 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 699.40 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 696.49 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 686.73 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 681.99 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 681.29 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 664.57 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Generating...:   1%|▏         | 1/70 [00:25<28:52, 25.11s/it]Generating...:   1%|▏         | 1/70 [00:25<28:52, 25.11s/it]Generating...:   1%|▏         | 1/70 [00:25<28:51, 25.09s/it]Generating...:   1%|▏         | 1/70 [00:25<28:51, 25.09s/it]Generating...:   1%|▏         | 1/70 [00:25<28:51, 25.09s/it]Generating...:   1%|▏         | 1/70 [00:25<28:52, 25.11s/it]Generating...:   1%|▏         | 1/70 [00:25<28:51, 25.10s/it]Generating...:   1%|▏         | 1/70 [00:25<28:51, 25.09s/it]Generating...:   3%|▎         | 2/70 [00:53<30:45, 27.13s/it]Generating...:   3%|▎         | 2/70 [00:53<30:45, 27.14s/it]Generating...:   3%|▎         | 2/70 [00:53<30:44, 27.13s/it]Generating...:   3%|▎         | 2/70 [00:53<30:45, 27.14s/it]Generating...:   3%|▎         | 2/70 [00:53<30:45, 27.14s/it]Generating...:   3%|▎         | 2/70 [00:53<30:45, 27.14s/it]Generating...:   3%|▎         | 2/70 [00:53<30:44, 27.13s/it]Generating...:   3%|▎         | 2/70 [00:53<30:44, 27.13s/it]Generating...:   4%|▍         | 3/70 [01:18<29:00, 25.98s/it]Generating...:   4%|▍         | 3/70 [01:18<29:01, 25.99s/it]Generating...:   4%|▍         | 3/70 [01:18<29:00, 25.98s/it]Generating...:   4%|▍         | 3/70 [01:18<29:00, 25.98s/it]Generating...:   4%|▍         | 3/70 [01:18<29:00, 25.98s/it]Generating...:   4%|▍         | 3/70 [01:18<29:01, 25.99s/it]Generating...:   4%|▍         | 3/70 [01:18<29:00, 25.98s/it]Generating...:   4%|▍         | 3/70 [01:18<29:00, 25.98s/it]Generating...:   6%|▌         | 4/70 [01:42<27:57, 25.42s/it]Generating...:   6%|▌         | 4/70 [01:42<27:57, 25.42s/it]Generating...:   6%|▌         | 4/70 [01:42<27:57, 25.42s/it]Generating...:   6%|▌         | 4/70 [01:42<27:57, 25.42s/it]Generating...:   6%|▌         | 4/70 [01:42<27:57, 25.42s/it]Generating...:   6%|▌         | 4/70 [01:42<27:57, 25.42s/it]Generating...:   6%|▌         | 4/70 [01:42<27:57, 25.42s/it]Generating...:   6%|▌         | 4/70 [01:42<27:57, 25.42s/it]Generating...:   7%|▋         | 5/70 [02:07<27:09, 25.06s/it]Generating...:   7%|▋         | 5/70 [02:07<27:08, 25.06s/it]Generating...:   7%|▋         | 5/70 [02:07<27:09, 25.06s/it]Generating...:   7%|▋         | 5/70 [02:07<27:09, 25.06s/it]Generating...:   7%|▋         | 5/70 [02:07<27:08, 25.06s/it]Generating...:   7%|▋         | 5/70 [02:07<27:09, 25.06s/it]Generating...:   7%|▋         | 5/70 [02:07<27:08, 25.06s/it]Generating...:   7%|▋         | 5/70 [02:07<27:08, 25.06s/it]Generating...:   9%|▊         | 6/70 [02:32<26:37, 24.96s/it]Generating...:   9%|▊         | 6/70 [02:32<26:37, 24.96s/it]Generating...:   9%|▊         | 6/70 [02:32<26:37, 24.96s/it]Generating...:   9%|▊         | 6/70 [02:32<26:37, 24.96s/it]Generating...:   9%|▊         | 6/70 [02:32<26:37, 24.96s/it]Generating...:   9%|▊         | 6/70 [02:32<26:37, 24.96s/it]Generating...:   9%|▊         | 6/70 [02:32<26:37, 24.96s/it]Generating...:   9%|▊         | 6/70 [02:32<26:37, 24.96s/it]Generating...:  10%|█         | 7/70 [03:04<28:41, 27.32s/it]Generating...:  10%|█         | 7/70 [03:04<28:41, 27.32s/it]Generating...:  10%|█         | 7/70 [03:04<28:41, 27.32s/it]Generating...:  10%|█         | 7/70 [03:04<28:41, 27.32s/it]Generating...:  10%|█         | 7/70 [03:04<28:41, 27.32s/it]Generating...:  10%|█         | 7/70 [03:04<28:41, 27.32s/it]Generating...:  10%|█         | 7/70 [03:04<28:41, 27.32s/it]Generating...:  10%|█         | 7/70 [03:04<28:41, 27.32s/it]Generating...:  11%|█▏        | 8/70 [03:28<27:12, 26.34s/it]Generating...:  11%|█▏        | 8/70 [03:28<27:13, 26.34s/it]Generating...:  11%|█▏        | 8/70 [03:28<27:12, 26.34s/it]Generating...:  11%|█▏        | 8/70 [03:28<27:13, 26.34s/it]Generating...:  11%|█▏        | 8/70 [03:28<27:12, 26.34s/it]Generating...:  11%|█▏        | 8/70 [03:28<27:12, 26.34s/it]Generating...:  11%|█▏        | 8/70 [03:28<27:12, 26.34s/it]Generating...:  11%|█▏        | 8/70 [03:28<27:12, 26.34s/it]Generating...:  13%|█▎        | 9/70 [03:57<27:47, 27.34s/it]Generating...:  13%|█▎        | 9/70 [03:57<27:47, 27.34s/it]Generating...:  13%|█▎        | 9/70 [03:57<27:47, 27.34s/it]Generating...:  13%|█▎        | 9/70 [03:57<27:47, 27.34s/it]Generating...:  13%|█▎        | 9/70 [03:57<27:47, 27.34s/it]Generating...:  13%|█▎        | 9/70 [03:57<27:47, 27.34s/it]Generating...:  13%|█▎        | 9/70 [03:57<27:47, 27.34s/it]Generating...:  13%|█▎        | 9/70 [03:57<27:47, 27.34s/it]Generating...:  14%|█▍        | 10/70 [04:22<26:27, 26.46s/it]Generating...:  14%|█▍        | 10/70 [04:22<26:27, 26.46s/it]Generating...:  14%|█▍        | 10/70 [04:22<26:27, 26.46s/it]Generating...:  14%|█▍        | 10/70 [04:22<26:27, 26.46s/it]Generating...:  14%|█▍        | 10/70 [04:22<26:27, 26.46s/it]Generating...:  14%|█▍        | 10/70 [04:22<26:27, 26.46s/it]Generating...:  14%|█▍        | 10/70 [04:22<26:27, 26.46s/it]Generating...:  14%|█▍        | 10/70 [04:22<26:27, 26.46s/it]Generating...:  16%|█▌        | 11/70 [04:48<26:00, 26.45s/it]Generating...:  16%|█▌        | 11/70 [04:48<26:00, 26.45s/it]Generating...:  16%|█▌        | 11/70 [04:48<26:00, 26.45s/it]Generating...:  16%|█▌        | 11/70 [04:48<26:00, 26.45s/it]Generating...:  16%|█▌        | 11/70 [04:48<26:00, 26.45s/it]Generating...:  16%|█▌        | 11/70 [04:48<26:00, 26.45s/it]Generating...:  16%|█▌        | 11/70 [04:48<26:00, 26.45s/it]Generating...:  16%|█▌        | 11/70 [04:48<26:00, 26.45s/it]Generating...:  17%|█▋        | 12/70 [05:13<25:02, 25.90s/it]Generating...:  17%|█▋        | 12/70 [05:13<25:02, 25.90s/it]Generating...:  17%|█▋        | 12/70 [05:13<25:02, 25.90s/it]Generating...:  17%|█▋        | 12/70 [05:13<25:02, 25.90s/it]Generating...:  17%|█▋        | 12/70 [05:13<25:02, 25.90s/it]Generating...:  17%|█▋        | 12/70 [05:13<25:02, 25.90s/it]Generating...:  17%|█▋        | 12/70 [05:13<25:02, 25.90s/it]Generating...:  17%|█▋        | 12/70 [05:13<25:02, 25.90s/it]Generating...:  19%|█▊        | 13/70 [05:38<24:14, 25.52s/it]Generating...:  19%|█▊        | 13/70 [05:38<24:14, 25.52s/it]Generating...:  19%|█▊        | 13/70 [05:38<24:14, 25.52s/it]Generating...:  19%|█▊        | 13/70 [05:38<24:14, 25.52s/it]Generating...:  19%|█▊        | 13/70 [05:38<24:14, 25.52s/it]Generating...:  19%|█▊        | 13/70 [05:38<24:14, 25.52s/it]Generating...:  19%|█▊        | 13/70 [05:38<24:14, 25.52s/it]Generating...:  19%|█▊        | 13/70 [05:38<24:14, 25.52s/it]Generating...:  20%|██        | 14/70 [06:03<23:43, 25.43s/it]Generating...:  20%|██        | 14/70 [06:03<23:43, 25.43s/it]Generating...:  20%|██        | 14/70 [06:03<23:43, 25.43s/it]Generating...:  20%|██        | 14/70 [06:03<23:43, 25.43s/it]Generating...:  20%|██        | 14/70 [06:03<23:43, 25.43s/it]Generating...:  20%|██        | 14/70 [06:03<23:43, 25.43s/it]Generating...:  20%|██        | 14/70 [06:03<23:43, 25.43s/it]Generating...:  20%|██        | 14/70 [06:03<23:43, 25.43s/it]Generating...:  21%|██▏       | 15/70 [06:27<23:04, 25.17s/it]Generating...:  21%|██▏       | 15/70 [06:27<23:04, 25.17s/it]Generating...:  21%|██▏       | 15/70 [06:27<23:04, 25.17s/it]Generating...:  21%|██▏       | 15/70 [06:27<23:04, 25.17s/it]Generating...:  21%|██▏       | 15/70 [06:27<23:04, 25.17s/it]Generating...:  21%|██▏       | 15/70 [06:27<23:04, 25.17s/it]Generating...:  21%|██▏       | 15/70 [06:27<23:04, 25.17s/it]Generating...:  21%|██▏       | 15/70 [06:27<23:04, 25.17s/it]Generating...:  23%|██▎       | 16/70 [06:57<23:53, 26.54s/it]Generating...:  23%|██▎       | 16/70 [06:57<23:53, 26.54s/it]Generating...:  23%|██▎       | 16/70 [06:57<23:53, 26.54s/it]Generating...:  23%|██▎       | 16/70 [06:57<23:53, 26.54s/it]Generating...:  23%|██▎       | 16/70 [06:57<23:53, 26.54s/it]Generating...:  23%|██▎       | 16/70 [06:57<23:53, 26.54s/it]Generating...:  23%|██▎       | 16/70 [06:57<23:53, 26.54s/it]Generating...:  23%|██▎       | 16/70 [06:57<23:53, 26.54s/it]Generating...:  24%|██▍       | 17/70 [07:26<24:05, 27.27s/it]Generating...:  24%|██▍       | 17/70 [07:26<24:05, 27.27s/it]Generating...:  24%|██▍       | 17/70 [07:26<24:05, 27.27s/it]Generating...:  24%|██▍       | 17/70 [07:26<24:05, 27.27s/it]Generating...:  24%|██▍       | 17/70 [07:26<24:05, 27.27s/it]Generating...:  24%|██▍       | 17/70 [07:26<24:05, 27.27s/it]Generating...:  24%|██▍       | 17/70 [07:26<24:05, 27.27s/it]Generating...:  24%|██▍       | 17/70 [07:26<24:05, 27.27s/it]Generating...:  26%|██▌       | 18/70 [07:52<23:12, 26.79s/it]Generating...:  26%|██▌       | 18/70 [07:52<23:12, 26.79s/it]Generating...:  26%|██▌       | 18/70 [07:52<23:12, 26.79s/it]Generating...:  26%|██▌       | 18/70 [07:52<23:12, 26.79s/it]Generating...:  26%|██▌       | 18/70 [07:52<23:12, 26.79s/it]Generating...:  26%|██▌       | 18/70 [07:52<23:12, 26.79s/it]Generating...:  26%|██▌       | 18/70 [07:52<23:12, 26.79s/it]Generating...:  26%|██▌       | 18/70 [07:52<23:12, 26.79s/it]Generating...:  27%|██▋       | 19/70 [08:24<24:12, 28.47s/it]Generating...:  27%|██▋       | 19/70 [08:24<24:12, 28.47s/it]Generating...:  27%|██▋       | 19/70 [08:24<24:12, 28.47s/it]Generating...:  27%|██▋       | 19/70 [08:24<24:12, 28.47s/it]Generating...:  27%|██▋       | 19/70 [08:24<24:12, 28.47s/it]Generating...:  27%|██▋       | 19/70 [08:24<24:12, 28.47s/it]Generating...:  27%|██▋       | 19/70 [08:24<24:12, 28.47s/it]Generating...:  27%|██▋       | 19/70 [08:24<24:12, 28.47s/it]Generating...:  29%|██▊       | 20/70 [08:54<24:02, 28.86s/it]Generating...:  29%|██▊       | 20/70 [08:54<24:02, 28.86s/it]Generating...:  29%|██▊       | 20/70 [08:54<24:02, 28.86s/it]Generating...:  29%|██▊       | 20/70 [08:54<24:02, 28.86s/it]Generating...:  29%|██▊       | 20/70 [08:54<24:02, 28.86s/it]Generating...:  29%|██▊       | 20/70 [08:54<24:02, 28.86s/it]Generating...:  29%|██▊       | 20/70 [08:54<24:02, 28.86s/it]Generating...:  29%|██▊       | 20/70 [08:54<24:02, 28.86s/it]Generating...:  30%|███       | 21/70 [09:26<24:15, 29.70s/it]Generating...:  30%|███       | 21/70 [09:26<24:15, 29.70s/it]Generating...:  30%|███       | 21/70 [09:26<24:15, 29.70s/it]Generating...:  30%|███       | 21/70 [09:26<24:15, 29.70s/it]Generating...:  30%|███       | 21/70 [09:26<24:15, 29.70s/it]Generating...:  30%|███       | 21/70 [09:26<24:15, 29.70s/it]Generating...:  30%|███       | 21/70 [09:26<24:15, 29.70s/it]Generating...:  30%|███       | 21/70 [09:26<24:15, 29.70s/it]Generating...:  31%|███▏      | 22/70 [10:02<25:20, 31.67s/it]Generating...:  31%|███▏      | 22/70 [10:02<25:20, 31.67s/it]Generating...:  31%|███▏      | 22/70 [10:02<25:20, 31.67s/it]Generating...:  31%|███▏      | 22/70 [10:02<25:20, 31.67s/it]Generating...:  31%|███▏      | 22/70 [10:02<25:20, 31.67s/it]Generating...:  31%|███▏      | 22/70 [10:02<25:20, 31.67s/it]Generating...:  31%|███▏      | 22/70 [10:02<25:20, 31.67s/it]Generating...:  31%|███▏      | 22/70 [10:02<25:20, 31.67s/it]Generating...:  33%|███▎      | 23/70 [10:34<25:01, 31.95s/it]Generating...:  33%|███▎      | 23/70 [10:35<25:01, 31.95s/it]Generating...:  33%|███▎      | 23/70 [10:34<25:01, 31.95s/it]Generating...:  33%|███▎      | 23/70 [10:35<25:01, 31.95s/it]Generating...:  33%|███▎      | 23/70 [10:35<25:01, 31.95s/it]Generating...:  33%|███▎      | 23/70 [10:34<25:01, 31.95s/it]Generating...:  33%|███▎      | 23/70 [10:35<25:01, 31.95s/it]Generating...:  33%|███▎      | 23/70 [10:35<25:01, 31.95s/it]Generating...:  34%|███▍      | 24/70 [11:04<23:59, 31.30s/it]Generating...:  34%|███▍      | 24/70 [11:04<23:59, 31.30s/it]Generating...:  34%|███▍      | 24/70 [11:04<23:59, 31.30s/it]Generating...:  34%|███▍      | 24/70 [11:04<23:59, 31.30s/it]Generating...:  34%|███▍      | 24/70 [11:04<23:59, 31.30s/it]Generating...:  34%|███▍      | 24/70 [11:04<23:59, 31.30s/it]Generating...:  34%|███▍      | 24/70 [11:04<23:59, 31.30s/it]Generating...:  34%|███▍      | 24/70 [11:04<23:59, 31.30s/it]Generating...:  36%|███▌      | 25/70 [11:33<23:00, 30.67s/it]Generating...:  36%|███▌      | 25/70 [11:33<23:00, 30.67s/it]Generating...:  36%|███▌      | 25/70 [11:34<23:00, 30.67s/it]Generating...:  36%|███▌      | 25/70 [11:34<23:00, 30.67s/it]Generating...:  36%|███▌      | 25/70 [11:33<23:00, 30.67s/it]Generating...:  36%|███▌      | 25/70 [11:33<23:00, 30.67s/it]Generating...:  36%|███▌      | 25/70 [11:33<23:00, 30.67s/it]Generating...:  36%|███▌      | 25/70 [11:34<23:00, 30.67s/it]Generating...:  37%|███▋      | 26/70 [12:03<22:16, 30.37s/it]Generating...:  37%|███▋      | 26/70 [12:03<22:16, 30.37s/it]Generating...:  37%|███▋      | 26/70 [12:03<22:16, 30.37s/it]Generating...:  37%|███▋      | 26/70 [12:03<22:16, 30.37s/it]Generating...:  37%|███▋      | 26/70 [12:03<22:16, 30.37s/it]Generating...:  37%|███▋      | 26/70 [12:03<22:16, 30.37s/it]Generating...:  37%|███▋      | 26/70 [12:03<22:16, 30.37s/it]Generating...:  37%|███▋      | 26/70 [12:03<22:16, 30.37s/it]Generating...:  39%|███▊      | 27/70 [12:30<20:54, 29.18s/it]Generating...:  39%|███▊      | 27/70 [12:30<20:54, 29.18s/it]Generating...:  39%|███▊      | 27/70 [12:30<20:54, 29.18s/it]Generating...:  39%|███▊      | 27/70 [12:30<20:54, 29.18s/it]Generating...:  39%|███▊      | 27/70 [12:30<20:54, 29.18s/it]Generating...:  39%|███▊      | 27/70 [12:30<20:54, 29.18s/it]Generating...:  39%|███▊      | 27/70 [12:30<20:54, 29.18s/it]Generating...:  39%|███▊      | 27/70 [12:30<20:54, 29.18s/it]Generating...:  40%|████      | 28/70 [13:00<20:39, 29.52s/it]Generating...:  40%|████      | 28/70 [13:00<20:39, 29.52s/it]Generating...:  40%|████      | 28/70 [13:00<20:39, 29.52s/it]Generating...:  40%|████      | 28/70 [13:00<20:39, 29.52s/it]Generating...:  40%|████      | 28/70 [13:00<20:39, 29.52s/it]Generating...:  40%|████      | 28/70 [13:00<20:39, 29.52s/it]Generating...:  40%|████      | 28/70 [13:00<20:39, 29.52s/it]Generating...:  40%|████      | 28/70 [13:00<20:39, 29.52s/it]Generating...:  41%|████▏     | 29/70 [13:29<20:05, 29.40s/it]Generating...:  41%|████▏     | 29/70 [13:29<20:05, 29.40s/it]Generating...:  41%|████▏     | 29/70 [13:29<20:05, 29.40s/it]Generating...:  41%|████▏     | 29/70 [13:29<20:05, 29.40s/it]Generating...:  41%|████▏     | 29/70 [13:29<20:05, 29.40s/it]Generating...:  41%|████▏     | 29/70 [13:29<20:05, 29.40s/it]Generating...:  41%|████▏     | 29/70 [13:29<20:05, 29.40s/it]Generating...:  41%|████▏     | 29/70 [13:29<20:05, 29.40s/it]Generating...:  43%|████▎     | 30/70 [13:59<19:40, 29.52s/it]Generating...:  43%|████▎     | 30/70 [13:59<19:40, 29.52s/it]Generating...:  43%|████▎     | 30/70 [13:59<19:40, 29.52s/it]Generating...:  43%|████▎     | 30/70 [13:59<19:40, 29.52s/it]Generating...:  43%|████▎     | 30/70 [13:59<19:40, 29.52s/it]Generating...:  43%|████▎     | 30/70 [13:59<19:40, 29.52s/it]Generating...:  43%|████▎     | 30/70 [13:59<19:40, 29.52s/it]Generating...:  43%|████▎     | 30/70 [13:59<19:40, 29.52s/it]Generating...:  44%|████▍     | 31/70 [14:25<18:33, 28.55s/it]Generating...:  44%|████▍     | 31/70 [14:25<18:33, 28.55s/it]Generating...:  44%|████▍     | 31/70 [14:25<18:33, 28.55s/it]Generating...:  44%|████▍     | 31/70 [14:25<18:33, 28.55s/it]Generating...:  44%|████▍     | 31/70 [14:25<18:33, 28.55s/it]Generating...:  44%|████▍     | 31/70 [14:25<18:33, 28.55s/it]Generating...:  44%|████▍     | 31/70 [14:25<18:33, 28.55s/it]Generating...:  44%|████▍     | 31/70 [14:25<18:33, 28.55s/it]Generating...:  46%|████▌     | 32/70 [14:50<17:21, 27.41s/it]Generating...:  46%|████▌     | 32/70 [14:50<17:21, 27.41s/it]Generating...:  46%|████▌     | 32/70 [14:50<17:21, 27.41s/it]Generating...:  46%|████▌     | 32/70 [14:50<17:21, 27.41s/it]Generating...:  46%|████▌     | 32/70 [14:50<17:21, 27.41s/it]Generating...:  46%|████▌     | 32/70 [14:50<17:21, 27.41s/it]Generating...:  46%|████▌     | 32/70 [14:50<17:21, 27.41s/it]Generating...:  46%|████▌     | 32/70 [14:50<17:21, 27.41s/it]Generating...:  47%|████▋     | 33/70 [15:36<20:17, 32.90s/it]Generating...:  47%|████▋     | 33/70 [15:36<20:17, 32.90s/it]Generating...:  47%|████▋     | 33/70 [15:36<20:17, 32.90s/it]Generating...:  47%|████▋     | 33/70 [15:36<20:17, 32.90s/it]Generating...:  47%|████▋     | 33/70 [15:36<20:17, 32.90s/it]Generating...:  47%|████▋     | 33/70 [15:36<20:17, 32.90s/it]Generating...:  47%|████▋     | 33/70 [15:36<20:17, 32.90s/it]Generating...:  47%|████▋     | 33/70 [15:36<20:17, 32.90s/it]Generating...:  49%|████▊     | 34/70 [16:02<18:33, 30.94s/it]Generating...:  49%|████▊     | 34/70 [16:02<18:33, 30.94s/it]Generating...:  49%|████▊     | 34/70 [16:02<18:33, 30.94s/it]Generating...:  49%|████▊     | 34/70 [16:02<18:33, 30.94s/it]Generating...:  49%|████▊     | 34/70 [16:02<18:33, 30.94s/it]Generating...:  49%|████▊     | 34/70 [16:02<18:33, 30.94s/it]Generating...:  49%|████▊     | 34/70 [16:02<18:33, 30.94s/it]Generating...:  49%|████▊     | 34/70 [16:02<18:33, 30.94s/it]Generating...:  50%|█████     | 35/70 [16:27<16:56, 29.03s/it]Generating...:  50%|█████     | 35/70 [16:26<16:56, 29.03s/it]Generating...:  50%|█████     | 35/70 [16:26<16:56, 29.03s/it]Generating...:  50%|█████     | 35/70 [16:27<16:56, 29.03s/it]Generating...:  50%|█████     | 35/70 [16:27<16:56, 29.03s/it]Generating...:  50%|█████     | 35/70 [16:27<16:56, 29.03s/it]Generating...:  50%|█████     | 35/70 [16:26<16:56, 29.03s/it]Generating...:  50%|█████     | 35/70 [16:27<16:56, 29.03s/it]Generating...:  51%|█████▏    | 36/70 [16:51<15:43, 27.74s/it]Generating...:  51%|█████▏    | 36/70 [16:51<15:43, 27.74s/it]Generating...:  51%|█████▏    | 36/70 [16:51<15:43, 27.74s/it]Generating...:  51%|█████▏    | 36/70 [16:51<15:43, 27.74s/it]Generating...:  51%|█████▏    | 36/70 [16:51<15:43, 27.74s/it]Generating...:  51%|█████▏    | 36/70 [16:51<15:43, 27.74s/it]Generating...:  51%|█████▏    | 36/70 [16:51<15:43, 27.74s/it]Generating...:  51%|█████▏    | 36/70 [16:51<15:43, 27.74s/it]Generating...:  53%|█████▎    | 37/70 [17:18<15:04, 27.41s/it]Generating...:  53%|█████▎    | 37/70 [17:18<15:04, 27.41s/it]Generating...:  53%|█████▎    | 37/70 [17:18<15:04, 27.41s/it]Generating...:  53%|█████▎    | 37/70 [17:18<15:04, 27.41s/it]Generating...:  53%|█████▎    | 37/70 [17:18<15:04, 27.41s/it]Generating...:  53%|█████▎    | 37/70 [17:18<15:04, 27.41s/it]Generating...:  53%|█████▎    | 37/70 [17:18<15:04, 27.41s/it]Generating...:  53%|█████▎    | 37/70 [17:18<15:04, 27.41s/it]Generating...:  54%|█████▍    | 38/70 [17:43<14:15, 26.75s/it]Generating...:  54%|█████▍    | 38/70 [17:43<14:15, 26.75s/it]Generating...:  54%|█████▍    | 38/70 [17:43<14:15, 26.75s/it]Generating...:  54%|█████▍    | 38/70 [17:43<14:15, 26.75s/it]Generating...:  54%|█████▍    | 38/70 [17:43<14:15, 26.75s/it]Generating...:  54%|█████▍    | 38/70 [17:43<14:15, 26.75s/it]Generating...:  54%|█████▍    | 38/70 [17:43<14:15, 26.75s/it]Generating...:  54%|█████▍    | 38/70 [17:43<14:15, 26.75s/it]Generating...:  56%|█████▌    | 39/70 [18:08<13:34, 26.29s/it]Generating...:  56%|█████▌    | 39/70 [18:08<13:34, 26.29s/it]Generating...:  56%|█████▌    | 39/70 [18:08<13:34, 26.29s/it]Generating...:  56%|█████▌    | 39/70 [18:08<13:34, 26.29s/it]Generating...:  56%|█████▌    | 39/70 [18:08<13:34, 26.29s/it]Generating...:  56%|█████▌    | 39/70 [18:08<13:34, 26.29s/it]Generating...:  56%|█████▌    | 39/70 [18:08<13:34, 26.29s/it]Generating...:  56%|█████▌    | 39/70 [18:08<13:34, 26.29s/it]Generating...:  57%|█████▋    | 40/70 [18:33<12:53, 25.78s/it]Generating...:  57%|█████▋    | 40/70 [18:33<12:53, 25.78s/it]Generating...:  57%|█████▋    | 40/70 [18:33<12:53, 25.78s/it]Generating...:  57%|█████▋    | 40/70 [18:33<12:53, 25.78s/it]Generating...:  57%|█████▋    | 40/70 [18:33<12:53, 25.78s/it]Generating...:  57%|█████▋    | 40/70 [18:33<12:53, 25.78s/it]Generating...:  57%|█████▋    | 40/70 [18:33<12:53, 25.78s/it]Generating...:  57%|█████▋    | 40/70 [18:33<12:53, 25.78s/it]Generating...:  59%|█████▊    | 41/70 [18:57<12:17, 25.43s/it]Generating...:  59%|█████▊    | 41/70 [18:58<12:17, 25.43s/it]Generating...:  59%|█████▊    | 41/70 [18:57<12:17, 25.43s/it]Generating...:  59%|█████▊    | 41/70 [18:58<12:17, 25.43s/it]Generating...:  59%|█████▊    | 41/70 [18:57<12:17, 25.43s/it]Generating...:  59%|█████▊    | 41/70 [18:57<12:17, 25.43s/it]Generating...:  59%|█████▊    | 41/70 [18:58<12:17, 25.43s/it]Generating...:  59%|█████▊    | 41/70 [18:57<12:17, 25.43s/it]Generating...:  60%|██████    | 42/70 [19:22<11:48, 25.29s/it]Generating...:  60%|██████    | 42/70 [19:22<11:48, 25.29s/it]Generating...:  60%|██████    | 42/70 [19:22<11:48, 25.29s/it]Generating...:  60%|██████    | 42/70 [19:22<11:48, 25.29s/it]Generating...:  60%|██████    | 42/70 [19:22<11:48, 25.29s/it]Generating...:  60%|██████    | 42/70 [19:22<11:48, 25.29s/it]Generating...:  60%|██████    | 42/70 [19:22<11:48, 25.29s/it]Generating...:  60%|██████    | 42/70 [19:22<11:48, 25.29s/it]Generating...:  61%|██████▏   | 43/70 [19:47<11:16, 25.04s/it]Generating...:  61%|██████▏   | 43/70 [19:47<11:16, 25.04s/it]Generating...:  61%|██████▏   | 43/70 [19:47<11:16, 25.04s/it]Generating...:  61%|██████▏   | 43/70 [19:47<11:16, 25.04s/it]Generating...:  61%|██████▏   | 43/70 [19:47<11:16, 25.04s/it]Generating...:  61%|██████▏   | 43/70 [19:47<11:16, 25.04s/it]Generating...:  61%|██████▏   | 43/70 [19:47<11:16, 25.04s/it]Generating...:  61%|██████▏   | 43/70 [19:47<11:16, 25.04s/it]Generating...:  63%|██████▎   | 44/70 [20:12<10:47, 24.92s/it]Generating...:  63%|██████▎   | 44/70 [20:12<10:47, 24.92s/it]Generating...:  63%|██████▎   | 44/70 [20:12<10:47, 24.92s/it]Generating...:  63%|██████▎   | 44/70 [20:12<10:47, 24.92s/it]Generating...:  63%|██████▎   | 44/70 [20:12<10:47, 24.92s/it]Generating...:  63%|██████▎   | 44/70 [20:12<10:47, 24.92s/it]Generating...:  63%|██████▎   | 44/70 [20:12<10:47, 24.92s/it]Generating...:  63%|██████▎   | 44/70 [20:12<10:47, 24.92s/it]Generating...:  64%|██████▍   | 45/70 [20:36<10:19, 24.78s/it]Generating...:  64%|██████▍   | 45/70 [20:36<10:19, 24.78s/it]Generating...:  64%|██████▍   | 45/70 [20:36<10:19, 24.78s/it]Generating...:  64%|██████▍   | 45/70 [20:36<10:19, 24.78s/it]Generating...:  64%|██████▍   | 45/70 [20:36<10:19, 24.78s/it]Generating...:  64%|██████▍   | 45/70 [20:36<10:19, 24.78s/it]Generating...:  64%|██████▍   | 45/70 [20:36<10:19, 24.78s/it]Generating...:  64%|██████▍   | 45/70 [20:36<10:19, 24.78s/it]Generating...:  66%|██████▌   | 46/70 [21:02<10:03, 25.15s/it]Generating...:  66%|██████▌   | 46/70 [21:02<10:03, 25.15s/it]Generating...:  66%|██████▌   | 46/70 [21:02<10:03, 25.15s/it]Generating...:  66%|██████▌   | 46/70 [21:02<10:03, 25.15s/it]Generating...:  66%|██████▌   | 46/70 [21:02<10:03, 25.15s/it]Generating...:  66%|██████▌   | 46/70 [21:02<10:03, 25.15s/it]Generating...:  66%|██████▌   | 46/70 [21:02<10:03, 25.15s/it]Generating...:  66%|██████▌   | 46/70 [21:02<10:03, 25.15s/it]Generating...:  67%|██████▋   | 47/70 [21:27<09:36, 25.06s/it]Generating...:  67%|██████▋   | 47/70 [21:27<09:36, 25.06s/it]Generating...:  67%|██████▋   | 47/70 [21:27<09:36, 25.06s/it]Generating...:  67%|██████▋   | 47/70 [21:27<09:36, 25.06s/it]Generating...:  67%|██████▋   | 47/70 [21:27<09:36, 25.06s/it]Generating...:  67%|██████▋   | 47/70 [21:27<09:36, 25.06s/it]Generating...:  67%|██████▋   | 47/70 [21:27<09:36, 25.06s/it]Generating...:  67%|██████▋   | 47/70 [21:27<09:36, 25.06s/it]Generating...:  69%|██████▊   | 48/70 [21:52<09:11, 25.08s/it]Generating...:  69%|██████▊   | 48/70 [21:52<09:11, 25.08s/it]Generating...:  69%|██████▊   | 48/70 [21:52<09:11, 25.08s/it]Generating...:  69%|██████▊   | 48/70 [21:52<09:11, 25.08s/it]Generating...:  69%|██████▊   | 48/70 [21:52<09:11, 25.08s/it]Generating...:  69%|██████▊   | 48/70 [21:52<09:11, 25.08s/it]Generating...:  69%|██████▊   | 48/70 [21:52<09:11, 25.08s/it]Generating...:  69%|██████▊   | 48/70 [21:52<09:11, 25.08s/it]Generating...:  70%|███████   | 49/70 [22:17<08:45, 25.02s/it]Generating...:  70%|███████   | 49/70 [22:17<08:45, 25.02s/it]Generating...:  70%|███████   | 49/70 [22:17<08:45, 25.02s/it]Generating...:  70%|███████   | 49/70 [22:17<08:45, 25.02s/it]Generating...:  70%|███████   | 49/70 [22:17<08:45, 25.02s/it]Generating...:  70%|███████   | 49/70 [22:17<08:45, 25.02s/it]Generating...:  70%|███████   | 49/70 [22:17<08:45, 25.02s/it]Generating...:  70%|███████   | 49/70 [22:17<08:45, 25.02s/it]Generating...:  71%|███████▏  | 50/70 [22:41<08:17, 24.86s/it]Generating...:  71%|███████▏  | 50/70 [22:41<08:17, 24.86s/it]Generating...:  71%|███████▏  | 50/70 [22:41<08:17, 24.86s/it]Generating...:  71%|███████▏  | 50/70 [22:41<08:17, 24.86s/it]Generating...:  71%|███████▏  | 50/70 [22:41<08:17, 24.86s/it]Generating...:  71%|███████▏  | 50/70 [22:41<08:17, 24.86s/it]Generating...:  71%|███████▏  | 50/70 [22:41<08:17, 24.86s/it]Generating...:  71%|███████▏  | 50/70 [22:41<08:17, 24.86s/it]Generating...:  73%|███████▎  | 51/70 [23:08<08:04, 25.51s/it]Generating...:  73%|███████▎  | 51/70 [23:08<08:04, 25.51s/it]Generating...:  73%|███████▎  | 51/70 [23:08<08:04, 25.51s/it]Generating...:  73%|███████▎  | 51/70 [23:08<08:04, 25.51s/it]Generating...:  73%|███████▎  | 51/70 [23:08<08:04, 25.51s/it]Generating...:  73%|███████▎  | 51/70 [23:08<08:04, 25.51s/it]Generating...:  73%|███████▎  | 51/70 [23:08<08:04, 25.51s/it]Generating...:  73%|███████▎  | 51/70 [23:08<08:04, 25.51s/it]Generating...:  74%|███████▍  | 52/70 [23:35<07:44, 25.80s/it]Generating...:  74%|███████▍  | 52/70 [23:35<07:44, 25.80s/it]Generating...:  74%|███████▍  | 52/70 [23:35<07:44, 25.80s/it]Generating...:  74%|███████▍  | 52/70 [23:35<07:44, 25.80s/it]Generating...:  74%|███████▍  | 52/70 [23:35<07:44, 25.80s/it]Generating...:  74%|███████▍  | 52/70 [23:35<07:44, 25.80s/it]Generating...:  74%|███████▍  | 52/70 [23:35<07:44, 25.80s/it]Generating...:  74%|███████▍  | 52/70 [23:35<07:44, 25.80s/it]Generating...:  76%|███████▌  | 53/70 [24:18<08:47, 31.00s/it]Generating...:  76%|███████▌  | 53/70 [24:18<08:47, 31.00s/it]Generating...:  76%|███████▌  | 53/70 [24:18<08:47, 31.00s/it]Generating...:  76%|███████▌  | 53/70 [24:18<08:47, 31.00s/it]Generating...:  76%|███████▌  | 53/70 [24:18<08:47, 31.00s/it]Generating...:  76%|███████▌  | 53/70 [24:18<08:47, 31.00s/it]Generating...:  76%|███████▌  | 53/70 [24:18<08:47, 31.00s/it]Generating...:  76%|███████▌  | 53/70 [24:18<08:47, 31.00s/it]Generating...:  77%|███████▋  | 54/70 [24:48<08:11, 30.70s/it]Generating...:  77%|███████▋  | 54/70 [24:48<08:11, 30.70s/it]Generating...:  77%|███████▋  | 54/70 [24:48<08:11, 30.70s/it]Generating...:  77%|███████▋  | 54/70 [24:48<08:11, 30.70s/it]Generating...:  77%|███████▋  | 54/70 [24:48<08:11, 30.70s/it]Generating...:  77%|███████▋  | 54/70 [24:48<08:11, 30.70s/it]Generating...:  77%|███████▋  | 54/70 [24:48<08:11, 30.70s/it]Generating...:  77%|███████▋  | 54/70 [24:48<08:11, 30.70s/it]Generating...:  79%|███████▊  | 55/70 [25:12<07:11, 28.78s/it]Generating...:  79%|███████▊  | 55/70 [25:12<07:11, 28.78s/it]Generating...:  79%|███████▊  | 55/70 [25:12<07:11, 28.78s/it]Generating...:  79%|███████▊  | 55/70 [25:12<07:11, 28.78s/it]Generating...:  79%|███████▊  | 55/70 [25:12<07:11, 28.78s/it]Generating...:  79%|███████▊  | 55/70 [25:12<07:11, 28.78s/it]Generating...:  79%|███████▊  | 55/70 [25:12<07:11, 28.78s/it]Generating...:  79%|███████▊  | 55/70 [25:12<07:11, 28.78s/it]Generating...:  80%|████████  | 56/70 [25:38<06:30, 27.91s/it]Generating...:  80%|████████  | 56/70 [25:38<06:30, 27.91s/it]Generating...:  80%|████████  | 56/70 [25:38<06:30, 27.91s/it]Generating...:  80%|████████  | 56/70 [25:38<06:30, 27.91s/it]Generating...:  80%|████████  | 56/70 [25:38<06:30, 27.91s/it]Generating...:  80%|████████  | 56/70 [25:38<06:30, 27.91s/it]Generating...:  80%|████████  | 56/70 [25:38<06:30, 27.91s/it]Generating...:  80%|████████  | 56/70 [25:38<06:30, 27.91s/it]Generating...:  81%|████████▏ | 57/70 [26:04<05:55, 27.32s/it]Generating...:  81%|████████▏ | 57/70 [26:04<05:55, 27.32s/it]Generating...:  81%|████████▏ | 57/70 [26:04<05:55, 27.32s/it]Generating...:  81%|████████▏ | 57/70 [26:04<05:55, 27.32s/it]Generating...:  81%|████████▏ | 57/70 [26:04<05:55, 27.32s/it]Generating...:  81%|████████▏ | 57/70 [26:04<05:55, 27.32s/it]Generating...:  81%|████████▏ | 57/70 [26:04<05:55, 27.32s/it]Generating...:  81%|████████▏ | 57/70 [26:04<05:55, 27.32s/it]Generating...:  83%|████████▎ | 58/70 [26:30<05:21, 26.79s/it]Generating...:  83%|████████▎ | 58/70 [26:30<05:21, 26.79s/it]Generating...:  83%|████████▎ | 58/70 [26:30<05:21, 26.79s/it]Generating...:  83%|████████▎ | 58/70 [26:30<05:21, 26.79s/it]Generating...:  83%|████████▎ | 58/70 [26:30<05:21, 26.79s/it]Generating...:  83%|████████▎ | 58/70 [26:30<05:21, 26.79s/it]Generating...:  83%|████████▎ | 58/70 [26:30<05:21, 26.79s/it]Generating...:  83%|████████▎ | 58/70 [26:30<05:21, 26.79s/it]Generating...:  84%|████████▍ | 59/70 [26:56<04:53, 26.65s/it]Generating...:  84%|████████▍ | 59/70 [26:56<04:53, 26.65s/it]Generating...:  84%|████████▍ | 59/70 [26:56<04:53, 26.65s/it]Generating...:  84%|████████▍ | 59/70 [26:56<04:53, 26.65s/it]Generating...:  84%|████████▍ | 59/70 [26:56<04:53, 26.65s/it]Generating...:  84%|████████▍ | 59/70 [26:56<04:53, 26.65s/it]Generating...:  84%|████████▍ | 59/70 [26:56<04:53, 26.65s/it]Generating...:  84%|████████▍ | 59/70 [26:56<04:53, 26.65s/it]Generating...:  86%|████████▌ | 60/70 [27:21<04:22, 26.30s/it]Generating...:  86%|████████▌ | 60/70 [27:21<04:22, 26.30s/it]Generating...:  86%|████████▌ | 60/70 [27:21<04:22, 26.30s/it]Generating...:  86%|████████▌ | 60/70 [27:21<04:22, 26.30s/it]Generating...:  86%|████████▌ | 60/70 [27:21<04:22, 26.30s/it]Generating...:  86%|████████▌ | 60/70 [27:21<04:22, 26.30s/it]Generating...:  86%|████████▌ | 60/70 [27:21<04:22, 26.30s/it]Generating...:  86%|████████▌ | 60/70 [27:21<04:22, 26.30s/it]Generating...:  87%|████████▋ | 61/70 [27:51<04:05, 27.32s/it]Generating...:  87%|████████▋ | 61/70 [27:51<04:05, 27.32s/it]Generating...:  87%|████████▋ | 61/70 [27:51<04:05, 27.32s/it]Generating...:  87%|████████▋ | 61/70 [27:51<04:05, 27.32s/it]Generating...:  87%|████████▋ | 61/70 [27:51<04:05, 27.32s/it]Generating...:  87%|████████▋ | 61/70 [27:51<04:05, 27.32s/it]Generating...:  87%|████████▋ | 61/70 [27:51<04:05, 27.32s/it]Generating...:  87%|████████▋ | 61/70 [27:51<04:05, 27.32s/it]Generating...:  89%|████████▊ | 62/70 [28:16<03:33, 26.67s/it]Generating...:  89%|████████▊ | 62/70 [28:16<03:33, 26.67s/it]Generating...:  89%|████████▊ | 62/70 [28:16<03:33, 26.67s/it]Generating...:  89%|████████▊ | 62/70 [28:16<03:33, 26.67s/it]Generating...:  89%|████████▊ | 62/70 [28:16<03:33, 26.67s/it]Generating...:  89%|████████▊ | 62/70 [28:16<03:33, 26.67s/it]Generating...:  89%|████████▊ | 62/70 [28:16<03:33, 26.67s/it]Generating...:  89%|████████▊ | 62/70 [28:16<03:33, 26.67s/it]Generating...:  90%|█████████ | 63/70 [28:53<03:28, 29.79s/it]Generating...:  90%|█████████ | 63/70 [28:53<03:28, 29.79s/it]Generating...:  90%|█████████ | 63/70 [28:53<03:28, 29.79s/it]Generating...:  90%|█████████ | 63/70 [28:53<03:28, 29.79s/it]Generating...:  90%|█████████ | 63/70 [28:53<03:28, 29.79s/it]Generating...:  90%|█████████ | 63/70 [28:53<03:28, 29.79s/it]Generating...:  90%|█████████ | 63/70 [28:53<03:28, 29.79s/it]Generating...:  90%|█████████ | 63/70 [28:53<03:28, 29.79s/it]Generating...:  91%|█████████▏| 64/70 [29:19<02:50, 28.45s/it]Generating...:  91%|█████████▏| 64/70 [29:19<02:50, 28.45s/it]Generating...:  91%|█████████▏| 64/70 [29:19<02:50, 28.45s/it]Generating...:  91%|█████████▏| 64/70 [29:19<02:50, 28.45s/it]Generating...:  91%|█████████▏| 64/70 [29:19<02:50, 28.45s/it]Generating...:  91%|█████████▏| 64/70 [29:19<02:50, 28.45s/it]Generating...:  91%|█████████▏| 64/70 [29:19<02:50, 28.45s/it]Generating...:  91%|█████████▏| 64/70 [29:19<02:50, 28.45s/it]Generating...:  93%|█████████▎| 65/70 [29:44<02:17, 27.40s/it]Generating...:  93%|█████████▎| 65/70 [29:44<02:17, 27.40s/it]Generating...:  93%|█████████▎| 65/70 [29:44<02:17, 27.40s/it]Generating...:  93%|█████████▎| 65/70 [29:44<02:17, 27.40s/it]Generating...:  93%|█████████▎| 65/70 [29:44<02:17, 27.40s/it]Generating...:  93%|█████████▎| 65/70 [29:44<02:17, 27.40s/it]Generating...:  93%|█████████▎| 65/70 [29:44<02:17, 27.40s/it]Generating...:  93%|█████████▎| 65/70 [29:44<02:17, 27.40s/it]Generating...:  94%|█████████▍| 66/70 [30:08<01:46, 26.63s/it]Generating...:  94%|█████████▍| 66/70 [30:08<01:46, 26.63s/it]Generating...:  94%|█████████▍| 66/70 [30:08<01:46, 26.63s/it]Generating...:  94%|█████████▍| 66/70 [30:08<01:46, 26.63s/it]Generating...:  94%|█████████▍| 66/70 [30:08<01:46, 26.63s/it]Generating...:  94%|█████████▍| 66/70 [30:08<01:46, 26.63s/it]Generating...:  94%|█████████▍| 66/70 [30:08<01:46, 26.63s/it]Generating...:  94%|█████████▍| 66/70 [30:08<01:46, 26.63s/it]Generating...:  96%|█████████▌| 67/70 [30:35<01:20, 26.69s/it]Generating...:  96%|█████████▌| 67/70 [30:35<01:20, 26.69s/it]Generating...:  96%|█████████▌| 67/70 [30:35<01:20, 26.69s/it]Generating...:  96%|█████████▌| 67/70 [30:35<01:20, 26.69s/it]Generating...:  96%|█████████▌| 67/70 [30:35<01:20, 26.69s/it]Generating...:  96%|█████████▌| 67/70 [30:35<01:20, 26.69s/it]Generating...:  96%|█████████▌| 67/70 [30:35<01:20, 26.69s/it]Generating...:  96%|█████████▌| 67/70 [30:35<01:20, 26.69s/it]Generating...:  97%|█████████▋| 68/70 [31:04<00:54, 27.38s/it]Generating...:  97%|█████████▋| 68/70 [31:04<00:54, 27.38s/it]Generating...:  97%|█████████▋| 68/70 [31:04<00:54, 27.38s/it]Generating...:  97%|█████████▋| 68/70 [31:04<00:54, 27.38s/it]Generating...:  97%|█████████▋| 68/70 [31:04<00:54, 27.38s/it]Generating...:  97%|█████████▋| 68/70 [31:04<00:54, 27.38s/it]Generating...:  97%|█████████▋| 68/70 [31:04<00:54, 27.38s/it]Generating...:  97%|█████████▋| 68/70 [31:04<00:54, 27.38s/it]Generating...:  99%|█████████▊| 69/70 [31:29<00:26, 26.69s/it]Generating...:  99%|█████████▊| 69/70 [31:29<00:26, 26.69s/it]Generating...:  99%|█████████▊| 69/70 [31:29<00:26, 26.69s/it]Generating...:  99%|█████████▊| 69/70 [31:29<00:26, 26.69s/it]Generating...:  99%|█████████▊| 69/70 [31:29<00:26, 26.69s/it]Generating...:  99%|█████████▊| 69/70 [31:29<00:26, 26.69s/it]Generating...:  99%|█████████▊| 69/70 [31:29<00:26, 26.69s/it]Generating...:  99%|█████████▊| 69/70 [31:29<00:26, 26.69s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 26.77s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 26.77s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 26.77s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 26.77s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 26.77s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 26.77s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 26.77s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 26.77s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 27.38s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 27.38s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 27.38s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 27.38s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 27.38s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 27.38s/it]Generating...: 100%|██████████| 70/70 [31:56<00:00, 27.38s/it]
Generating...: 100%|██████████| 70/70 [31:56<00:00, 27.38s/it]






[rank6]:W1110 14:37:34.447000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38270 hash value: 13868923501273962646
[rank3]:W1110 14:37:34.571000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35722 hash value: 18292781590896004056
[rank7]:W1110 14:37:34.638000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34929 hash value: 15866393036518883065
[rank2]:W1110 14:37:34.744000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37288 hash value: 13277382368676024954
[rank4]:W1110 14:37:34.895000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36854 hash value: 1192754706739572767
[rank0]:W1110 14:37:34.913000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35367 hash value: 5696325798840719823
[rank1]:W1110 14:37:34.961000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34972 hash value: 15301070517019768441
[rank5]:W1110 14:37:35.021000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34169 hash value: 6526676310205701747
[rank0]:W1110 14:37:35.205000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38270 hash value: 9945101843112921632
[rank0]:W1110 14:37:35.207000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38270 hash value: 9945101843112921632
[rank0]:W1110 14:37:35.209000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38270 hash value: 9945101843112921632
[rank0]:W1110 14:37:35.211000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38270 hash value: 9945101843112921632
[rank0]:W1110 14:37:35.213000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38270 hash value: 9945101843112921632
[rank3]:W1110 14:37:35.214000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5232175015349135601
[rank7]:W1110 14:37:35.214000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 1960590360432897693
[rank5]:W1110 14:37:35.214000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank1]:W1110 14:37:35.214000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077296346813
[rank4]:W1110 14:37:35.215000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8350198465046513010
[rank6]:W1110 14:37:35.215000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank2]:W1110 14:37:35.215000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:37:35.215000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38270 hash value: 9945101843112921632
[rank0]:W1110 14:37:35.220000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38270 hash value: 9945101843112921632
[rank0]:W1110 14:37:35.221000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38270 hash value: 9945101843112921632
[rank0]:W1110 14:37:35.223000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank0]:W1110 14:37:35.227000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4863360836724877711
[rank6]:W1110 14:37:35.227000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank1]:W1110 14:37:35.227000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5476429134771033150
[rank3]:W1110 14:37:35.227000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 11150749849738415391
[rank4]:W1110 14:37:35.227000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5859782613744783699
[rank2]:W1110 14:37:35.227000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475570979164714397
[rank7]:W1110 14:37:35.227000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 11536048430561119105
[rank5]:W1110 14:37:35.227000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077296375758
[rank0]:W1110 14:37:35.229000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4863360836724877711
[rank0]:W1110 14:37:35.232000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4863360836724877711
[rank0]:W1110 14:37:35.233000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4863360836724877711
[rank0]:W1110 14:37:35.234000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4863360836724877711
[rank0]:W1110 14:37:35.235000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4863360836724877711
[rank0]:W1110 14:37:35.236000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4863360836724877711
[rank0]:W1110 14:37:35.237000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4863360836724877711
[rank0]:W1110 14:37:35.238000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5135116141060551229
[rank0]:W1110 14:37:35.242000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17171121977322579025
[rank5]:W1110 14:37:35.242000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 43387 hash value: 9133078883527603504
[rank3]:W1110 14:37:35.242000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40322 hash value: 2515546577283144162
[rank6]:W1110 14:37:35.242000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41464 hash value: 15068822954283614660
[rank7]:W1110 14:37:35.242000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39741 hash value: 9518552120410474835
[rank4]:W1110 14:37:35.242000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36165 hash value: 13131533491730942634
[rank2]:W1110 14:37:35.242000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 43169 hash value: 11006265033517898497
[rank1]:W1110 14:37:35.242000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 42964 hash value: 18007212352693127664
[rank0]:W1110 14:37:35.243000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17171121977322579025
[rank0]:W1110 14:37:35.246000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17171121977322579025
[rank0]:W1110 14:37:35.247000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17171121977322579025
[rank0]:W1110 14:37:35.248000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17171121977322579025
[rank0]:W1110 14:37:35.249000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17171121977322579025
[rank0]:W1110 14:37:35.250000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17171121977322579025
[rank0]:W1110 14:37:35.251000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17171121977322579025
[rank0]:W1110 14:37:35.252000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41471 hash value: 9061905625022873585
[rank5]:W1110 14:37:35.256000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:37:35.256000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank3]:W1110 14:37:35.256000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 107298487388897276
[rank4]:W1110 14:37:35.256000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17845255022493419918
[rank6]:W1110 14:37:35.256000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891809526
[rank1]:W1110 14:37:35.256000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank2]:W1110 14:37:35.256000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank0]:W1110 14:37:35.257000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43387 hash value: 12775572371972862910
[rank0]:W1110 14:37:35.261000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43387 hash value: 12775572371972862910
[rank0]:W1110 14:37:35.263000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43387 hash value: 12775572371972862910
[rank0]:W1110 14:37:35.265000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43387 hash value: 12775572371972862910
[rank0]:W1110 14:37:35.267000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43387 hash value: 12775572371972862910
[rank0]:W1110 14:37:35.268000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43387 hash value: 12775572371972862910
[rank0]:W1110 14:37:35.270000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43387 hash value: 12775572371972862910
[rank0]:W1110 14:37:35.272000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43387 hash value: 12775572371972862910
[rank0]:W1110 14:37:35.273000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank5]:W1110 14:37:35.277000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:37:35.277000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9330050807342533149
[rank3]:W1110 14:37:35.277000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 107298487388868077
[rank6]:W1110 14:37:35.277000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891809526
[rank1]:W1110 14:37:35.277000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank7]:W1110 14:37:35.277000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank4]:W1110 14:37:35.277000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17845255022493419918
[rank2]:W1110 14:37:35.277000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7824157749669262784
[rank0]:W1110 14:37:35.279000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9330050807342533149
[rank0]:W1110 14:37:35.282000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9330050807342533149
[rank0]:W1110 14:37:35.283000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9330050807342533149
[rank0]:W1110 14:37:35.284000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9330050807342533149
[rank0]:W1110 14:37:35.285000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9330050807342533149
[rank0]:W1110 14:37:35.286000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9330050807342533149
[rank0]:W1110 14:37:35.287000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9330050807342533149
[rank0]:W1110 14:37:35.287000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:37:35.291000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2424871885788252207
[rank5]:W1110 14:37:35.292000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 44506 hash value: 8346290306970802408
[rank6]:W1110 14:37:35.292000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 47206 hash value: 12552141924018256494
[rank3]:W1110 14:37:35.292000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 47267 hash value: 2716432033096640447
[rank0]:W1110 14:37:35.293000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2424871885788252207
[rank2]:W1110 14:37:35.292000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 45039 hash value: 10075793777639543009
[rank7]:W1110 14:37:35.292000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 45110 hash value: 1371246690319810367
[rank1]:W1110 14:37:35.292000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 43294 hash value: 4963795592385291502
[rank4]:W1110 14:37:35.292000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 47199 hash value: 16163390962032972890
[rank0]:W1110 14:37:35.294000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2424871885788252207
[rank0]:W1110 14:37:35.296000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2424871885788252207
[rank0]:W1110 14:37:35.297000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2424871885788252207
[rank0]:W1110 14:37:35.298000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2424871885788252207
[rank0]:W1110 14:37:35.299000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2424871885788252207
[rank0]:W1110 14:37:35.300000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2424871885788252207
[rank0]:W1110 14:37:35.301000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 46197 hash value: 13010169315544183329
[rank5]:W1110 14:37:35.305000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank4]:W1110 14:37:35.305000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:37:35.305000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank6]:W1110 14:37:35.305000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391363343754025562
[rank1]:W1110 14:37:35.305000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank7]:W1110 14:37:35.305000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank2]:W1110 14:37:35.305000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:37:35.306000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47267 hash value: 2553444735666441969
[rank0]:W1110 14:37:35.310000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47267 hash value: 2553444735666441969
[rank0]:W1110 14:37:35.312000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47267 hash value: 2553444735666441969
[rank0]:W1110 14:37:35.315000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47267 hash value: 2553444735666441969
[rank0]:W1110 14:37:35.317000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47267 hash value: 2553444735666441969
[rank0]:W1110 14:37:35.319000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47267 hash value: 2553444735666441969
[rank0]:W1110 14:37:35.320000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47267 hash value: 2553444735666441969
[rank0]:W1110 14:37:35.322000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 47267 hash value: 2553444735666441969
[rank0]:W1110 14:37:35.323000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank0]:W1110 14:37:35.328000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5134301135326112920
[rank6]:W1110 14:37:35.328000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391363343766734012
[rank5]:W1110 14:37:35.328000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank4]:W1110 14:37:35.328000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank3]:W1110 14:37:35.328000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12759702263565105956
[rank2]:W1110 14:37:35.328000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank7]:W1110 14:37:35.328000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank1]:W1110 14:37:35.328000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:37:35.329000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5134301135326112920
[rank0]:W1110 14:37:35.333000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5134301135326112920
[rank0]:W1110 14:37:35.334000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5134301135326112920
[rank0]:W1110 14:37:35.334000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5134301135326112920
[rank0]:W1110 14:37:35.335000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5134301135326112920
[rank0]:W1110 14:37:35.336000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5134301135326112920
[rank0]:W1110 14:37:35.337000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5134301135326112920
[rank0]:W1110 14:37:35.338000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank0]:W1110 14:37:35.342000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11168952168128631729
[rank5]:W1110 14:37:35.342000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39687 hash value: 1531617242691661895
[rank6]:W1110 14:37:35.342000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38217 hash value: 3173291130040521275
[rank4]:W1110 14:37:35.342000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40107 hash value: 14941279905745293452
[rank3]:W1110 14:37:35.342000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38345 hash value: 2066858278251607321
[rank1]:W1110 14:37:35.342000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41392 hash value: 2892557744509129602
[rank7]:W1110 14:37:35.343000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40406 hash value: 511328694515759844
[rank2]:W1110 14:37:35.343000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40464 hash value: 12400633929924215023
[rank0]:W1110 14:37:35.344000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11168952168128631729
[rank0]:W1110 14:37:35.347000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11168952168128631729
[rank0]:W1110 14:37:35.348000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11168952168128631729
[rank0]:W1110 14:37:35.349000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11168952168128631729
[rank0]:W1110 14:37:35.350000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11168952168128631729
[rank0]:W1110 14:37:35.351000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11168952168128631729
[rank0]:W1110 14:37:35.352000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11168952168128631729
[rank0]:W1110 14:37:35.353000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38413 hash value: 6783599556976285467
[rank5]:W1110 14:37:35.358000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655572756
[rank4]:W1110 14:37:35.358000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:37:35.358000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:37:35.358000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank2]:W1110 14:37:35.358000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:37:35.358000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811490035374021
[rank1]:W1110 14:37:35.358000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994949746626
[rank0]:W1110 14:37:35.358000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41392 hash value: 7298347500943428846
[rank0]:W1110 14:37:35.363000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41392 hash value: 7298347500943428846
[rank0]:W1110 14:37:35.365000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41392 hash value: 7298347500943428846
[rank0]:W1110 14:37:35.366000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41392 hash value: 7298347500943428846
[rank0]:W1110 14:37:35.368000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41392 hash value: 7298347500943428846
[rank0]:W1110 14:37:35.370000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41392 hash value: 7298347500943428846
[rank0]:W1110 14:37:35.372000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41392 hash value: 7298347500943428846
[rank0]:W1110 14:37:35.374000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41392 hash value: 7298347500943428846
[rank0]:W1110 14:37:35.375000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank0]:W1110 14:37:35.379000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6991543802753954187
[rank2]:W1110 14:37:35.379000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:37:35.379000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank5]:W1110 14:37:35.379000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655572756
[rank4]:W1110 14:37:35.379000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank1]:W1110 14:37:35.379000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118207575638993
[rank7]:W1110 14:37:35.379000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811490035374021
[rank6]:W1110 14:37:35.379000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:37:35.381000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6991543802753954187
[rank0]:W1110 14:37:35.384000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6991543802753954187
[rank0]:W1110 14:37:35.385000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6991543802753954187
[rank0]:W1110 14:37:35.386000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6991543802753954187
[rank0]:W1110 14:37:35.386000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6991543802753954187
[rank0]:W1110 14:37:35.387000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6991543802753954187
[rank0]:W1110 14:37:35.388000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6991543802753954187
[rank0]:W1110 14:37:35.389000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404890844
[rank0]:W1110 14:37:35.393000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16738852721569095404
[rank3]:W1110 14:37:35.393000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36679 hash value: 10398392249696353988
[rank5]:W1110 14:37:35.393000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38145 hash value: 4505070271326355018
[rank4]:W1110 14:37:35.393000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38289 hash value: 13535638059227783615
[rank1]:W1110 14:37:35.393000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37177 hash value: 16074511238568342790
[rank6]:W1110 14:37:35.393000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37649 hash value: 4895646020939464103
[rank7]:W1110 14:37:35.393000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38209 hash value: 1789859472447779858
[rank2]:W1110 14:37:35.393000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40427 hash value: 9386743239078293521
[rank0]:W1110 14:37:35.394000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16738852721569095404
[rank0]:W1110 14:37:35.398000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16738852721569095404
[rank0]:W1110 14:37:35.399000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16738852721569095404
[rank0]:W1110 14:37:35.400000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16738852721569095404
[rank0]:W1110 14:37:35.401000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16738852721569095404
[rank0]:W1110 14:37:35.401000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16738852721569095404
[rank0]:W1110 14:37:35.402000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16738852721569095404
[rank0]:W1110 14:37:35.404000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37879 hash value: 15800421924738194133
[rank5]:W1110 14:37:35.407000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379136566
[rank2]:W1110 14:37:35.407000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank4]:W1110 14:37:35.407000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank3]:W1110 14:37:35.407000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank6]:W1110 14:37:35.407000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank1]:W1110 14:37:35.407000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank7]:W1110 14:37:35.407000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank0]:W1110 14:37:35.408000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40427 hash value: 12983833646524166978
[rank0]:W1110 14:37:35.412000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40427 hash value: 12983833646524166978
[rank0]:W1110 14:37:35.414000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40427 hash value: 12983833646524166978
[rank0]:W1110 14:37:35.416000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40427 hash value: 12983833646524166978
[rank0]:W1110 14:37:35.418000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40427 hash value: 12983833646524166978
[rank0]:W1110 14:37:35.419000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40427 hash value: 12983833646524166978
[rank0]:W1110 14:37:35.421000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40427 hash value: 12983833646524166978
[rank0]:W1110 14:37:35.423000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40427 hash value: 12983833646524166978
[rank0]:W1110 14:37:35.424000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17845255026049041173
[rank3]:W1110 14:37:35.428000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9707684007058040015
[rank0]:W1110 14:37:35.428000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14617408576457436229
[rank4]:W1110 14:37:35.428000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank5]:W1110 14:37:35.428000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379136566
[rank7]:W1110 14:37:35.428000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank6]:W1110 14:37:35.428000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank2]:W1110 14:37:35.428000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank1]:W1110 14:37:35.428000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank0]:W1110 14:37:35.430000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14617408576457436229
[rank0]:W1110 14:37:35.434000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14617408576457436229
[rank0]:W1110 14:37:35.435000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14617408576457436229
[rank0]:W1110 14:37:35.436000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14617408576457436229
[rank0]:W1110 14:37:35.436000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14617408576457436229
[rank0]:W1110 14:37:35.437000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14617408576457436229
[rank0]:W1110 14:37:35.438000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14617408576457436229
[rank0]:W1110 14:37:35.439000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 13620018799285264222
[rank0]:W1110 14:37:35.443000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7297225550819847349
[rank7]:W1110 14:37:35.443000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36024 hash value: 1862928556417091464
[rank3]:W1110 14:37:35.443000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39219 hash value: 4033509037019698786
[rank6]:W1110 14:37:35.443000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39505 hash value: 8092005373605275963
[rank5]:W1110 14:37:35.443000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39172 hash value: 6236775634549487924
[rank2]:W1110 14:37:35.443000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35931 hash value: 10694384917940230274
[rank1]:W1110 14:37:35.443000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37825 hash value: 1954153315457578342
[rank4]:W1110 14:37:35.443000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37390 hash value: 16477690359984257353
[rank0]:W1110 14:37:35.444000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7297225550819847349
[rank0]:W1110 14:37:35.448000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7297225550819847349
[rank0]:W1110 14:37:35.449000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7297225550819847349
[rank0]:W1110 14:37:35.450000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7297225550819847349
[rank0]:W1110 14:37:35.451000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7297225550819847349
[rank0]:W1110 14:37:35.452000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7297225550819847349
[rank0]:W1110 14:37:35.453000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7297225550819847349
[rank0]:W1110 14:37:35.454000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39922 hash value: 6270074321569949902
[rank4]:W1110 14:37:35.458000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475570979164714397
[rank3]:W1110 14:37:35.458000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank6]:W1110 14:37:35.458000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9223450630421535561
[rank5]:W1110 14:37:35.458000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 262382661159710228
[rank7]:W1110 14:37:35.458000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8422921591603276527
[rank2]:W1110 14:37:35.458000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811488333850520
[rank1]:W1110 14:37:35.458000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 10978510447437217317
[rank0]:W1110 14:37:35.458000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39922 hash value: 1106402395455384689
[rank0]:W1110 14:37:35.463000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39922 hash value: 1106402395455384689
[rank0]:W1110 14:37:35.464000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39922 hash value: 1106402395455384689
[rank0]:W1110 14:37:35.466000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39922 hash value: 1106402395455384689
[rank0]:W1110 14:37:35.468000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39922 hash value: 1106402395455384689
[rank0]:W1110 14:37:35.470000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39922 hash value: 1106402395455384689
[rank0]:W1110 14:37:35.471000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39922 hash value: 1106402395455384689
[rank0]:W1110 14:37:35.473000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39922 hash value: 1106402395455384689
[rank0]:W1110 14:37:35.474000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14873316662210576836
[rank0]:W1110 14:37:35.478000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 3959972894041184683
[rank5]:W1110 14:37:35.478000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8425032917572256019
[rank3]:W1110 14:37:35.478000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9799981658433655582
[rank7]:W1110 14:37:35.478000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 13116726536427929440
[rank6]:W1110 14:37:35.478000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8163775372912462361
[rank4]:W1110 14:37:35.478000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2511766171611886414
[rank1]:W1110 14:37:35.478000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8617183975846398200
[rank2]:W1110 14:37:35.478000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9848831685589267288
[rank0]:W1110 14:37:35.479000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 3959972894041184683
[rank0]:W1110 14:37:35.482000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 3959972894041184683
[rank0]:W1110 14:37:35.483000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 3959972894041184683
[rank0]:W1110 14:37:35.484000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 3959972894041184683
[rank0]:W1110 14:37:35.485000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 3959972894041184683
[rank0]:W1110 14:37:35.485000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 3959972894041184683
[rank0]:W1110 14:37:35.486000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 3959972894041184683
[rank0]:W1110 14:37:35.487000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6462082886655956549
[rank0]:W1110 14:37:35.491000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7469916567021584828
[rank5]:W1110 14:37:35.491000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 42098 hash value: 561695599243763680
[rank4]:W1110 14:37:35.491000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 45801 hash value: 14301457204786696098
[rank7]:W1110 14:37:35.491000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 44003 hash value: 13137082040750009833
[rank3]:W1110 14:37:35.491000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 42211 hash value: 17038607683076138301
[rank6]:W1110 14:37:35.491000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40296 hash value: 3954671735563624886
[rank2]:W1110 14:37:35.491000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40730 hash value: 16800089695751554291
[rank1]:W1110 14:37:35.491000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 46474 hash value: 12242762694482609253
[rank0]:W1110 14:37:35.492000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7469916567021584828
[rank0]:W1110 14:37:35.495000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7469916567021584828
[rank0]:W1110 14:37:35.496000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7469916567021584828
[rank0]:W1110 14:37:35.497000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7469916567021584828
[rank0]:W1110 14:37:35.498000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7469916567021584828
[rank0]:W1110 14:37:35.499000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7469916567021584828
[rank0]:W1110 14:37:35.500000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7469916567021584828
[rank0]:W1110 14:37:35.501000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 45370 hash value: 14595677729699228028
[rank5]:W1110 14:37:35.505000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank4]:W1110 14:37:35.505000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:37:35.505000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:37:35.505000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:37:35.505000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209005957337
[rank2]:W1110 14:37:35.505000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank1]:W1110 14:37:35.505000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:37:35.506000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 46474 hash value: 8789982662015266788
[rank0]:W1110 14:37:35.510000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 46474 hash value: 8789982662015266788
[rank0]:W1110 14:37:35.512000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 46474 hash value: 8789982662015266788
[rank0]:W1110 14:37:35.513000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 46474 hash value: 8789982662015266788
[rank0]:W1110 14:37:35.515000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 46474 hash value: 8789982662015266788
[rank0]:W1110 14:37:35.517000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 46474 hash value: 8789982662015266788
[rank0]:W1110 14:37:35.519000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 46474 hash value: 8789982662015266788
[rank0]:W1110 14:37:35.521000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 46474 hash value: 8789982662015266788
[rank0]:W1110 14:37:35.522000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:37:35.525000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4005361936278120340
[rank1]:W1110 14:37:35.526000 49621 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank7]:W1110 14:37:35.526000 49629 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209005957337
[rank6]:W1110 14:37:35.526000 49628 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12826790799051801796
[rank2]:W1110 14:37:35.526000 49622 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank5]:W1110 14:37:35.526000 49627 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:37:35.526000 49624 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994949746626
[rank4]:W1110 14:37:35.526000 49625 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:37:35.527000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4005361936278120340
[rank0]:W1110 14:37:35.530000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4005361936278120340
[rank0]:W1110 14:37:35.532000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4005361936278120340
[rank0]:W1110 14:37:35.533000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4005361936278120340
[rank0]:W1110 14:37:35.534000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4005361936278120340
[rank0]:W1110 14:37:35.535000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4005361936278120340
[rank0]:W1110 14:37:35.536000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4005361936278120340
[rank0]:W1110 14:37:35.537000 49618 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634553868251725038
[rank0]:W1110 14:37:35.540000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16064409087253448056
[rank0]:W1110 14:37:35.541000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16064409087253448056
[rank0]:W1110 14:37:35.542000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16064409087253448056
[rank0]:W1110 14:37:35.543000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16064409087253448056
[rank0]:W1110 14:37:35.544000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16064409087253448056
[rank0]:W1110 14:37:35.545000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16064409087253448056
[rank0]:W1110 14:37:35.546000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16064409087253448056
[rank0]:W1110 14:37:35.547000 49618 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16064409087253448056
2025-11-10:14:37:42 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
2025-11-10:14:37:42 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_algebra
2025-11-10:14:37:42 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_counting_and_prob
2025-11-10:14:37:43 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_geometry
2025-11-10:14:37:43 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_intermediate_algebra
2025-11-10:14:37:43 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_num_theory
2025-11-10:14:37:43 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_prealgebra
2025-11-10:14:37:43 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_precalc
[rank0]:[W1110 14:37:44.070850707 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
