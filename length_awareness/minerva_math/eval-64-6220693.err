The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2025-11-10:13:55:54 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:54 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:54 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:54 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:54 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:54 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:54 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:54 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 64, 'steps': 64, 'block_length': 64, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:13:55:54 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:54 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:54 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 64, 'steps': 64, 'block_length': 64, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:13:55:54 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 64, 'steps': 64, 'block_length': 64, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
[W1110 13:55:54.637797759 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 13:55:54.637796319 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 13:55:54.637796124 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 64, 'steps': 64, 'block_length': 64, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 64, 'steps': 64, 'block_length': 64, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
[W1110 13:55:55.087542202 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 13:55:55.088795459 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 64, 'steps': 64, 'block_length': 64, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
[W1110 13:55:55.103615052 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 64, 'steps': 64, 'block_length': 64, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
[W1110 13:55:55.109353531 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 64, 'steps': 64, 'block_length': 64, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
[W1110 13:55:55.237517960 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 WARNING  [accelerate.utils.other:441] Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.23s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.28s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:11,  2.32s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:10,  2.55s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:11,  2.76s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:11,  2.76s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:11,  2.76s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:11,  2.77s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:11,  2.76s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:11,  2.76s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:05<00:11,  2.77s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.41s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.49s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.51s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.51s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.51s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.51s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.51s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.57s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:04,  2.47s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:04,  2.49s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.52s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.52s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.54s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.52s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.55s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:10<00:05,  2.52s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:12<00:02,  2.57s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.73s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.72s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.73s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.72s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.72s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.74s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:13<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.45s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.41s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.37s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.37s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.37s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.38s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.38s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.37s/it]

Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]

Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]

[rank6]:[W1110 13:56:14.771558209 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank4]:[W1110 13:56:14.771897131 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank3]:[W1110 13:56:14.771967747 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank1]:[W1110 13:56:14.771983182 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank2]:[W1110 13:56:14.771985779 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank7]:[W1110 13:56:14.772314779 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank0]:[W1110 13:56:14.772347405 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank5]:[W1110 13:56:14.785714481 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:56:30 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:30 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:30 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:30 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:30 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:30 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:30 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:30 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:30 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:31 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 363.14it/s]
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:31 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:31 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 7...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 349.28it/s]
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:31 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:31 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:31 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:31 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 4...
100%|██████████| 10/10 [00:00<00:00, 354.61it/s]
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 359.95it/s]
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:31 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:31 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 365.45it/s]
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:31 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:31 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 3...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 357.27it/s]
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:31 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:31 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:31 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:31 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 5...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 365.59it/s]
2025-11-10:13:56:32 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:32 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:32 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:32 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:32 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:32 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:32 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:32 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:32 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 2...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 361.03it/s]
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 2...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 3...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 5...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 0...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 1...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 7...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 4...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 412.33it/s]100%|██████████| 10/10 [00:00<00:00, 417.32it/s]

100%|██████████| 10/10 [00:00<00:00, 408.09it/s]
100%|██████████| 10/10 [00:00<00:00, 396.86it/s]100%|██████████| 10/10 [00:00<00:00, 388.70it/s]100%|██████████| 10/10 [00:00<00:00, 392.99it/s]
100%|██████████| 10/10 [00:00<00:00, 388.52it/s]
100%|██████████| 10/10 [00:00<00:00, 385.23it/s]


2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 3...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 5...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 4...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 2...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 6...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 1...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 7...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 411.86it/s]
100%|██████████| 10/10 [00:00<00:00, 414.72it/s]100%|██████████| 10/10 [00:00<00:00, 399.30it/s]
100%|██████████| 10/10 [00:00<00:00, 404.39it/s]
100%|██████████| 10/10 [00:00<00:00, 402.05it/s]
100%|██████████| 10/10 [00:00<00:00, 393.21it/s]
100%|██████████| 10/10 [00:00<00:00, 387.56it/s]
100%|██████████| 10/10 [00:00<00:00, 373.42it/s]

2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 2...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 3...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 0...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 1...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 7...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 4...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 5...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 416.36it/s]100%|██████████| 10/10 [00:00<00:00, 407.13it/s]

100%|██████████| 10/10 [00:00<00:00, 403.61it/s]100%|██████████| 10/10 [00:00<00:00, 407.59it/s]100%|██████████| 10/10 [00:00<00:00, 385.24it/s]

100%|██████████| 10/10 [00:00<00:00, 395.80it/s]100%|██████████| 10/10 [00:00<00:00, 400.18it/s]
100%|██████████| 10/10 [00:00<00:00, 373.58it/s]


2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 3...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 0...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 1...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 2...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 4...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 7...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 5...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 414.21it/s]
100%|██████████| 10/10 [00:00<00:00, 397.24it/s]
100%|██████████| 10/10 [00:00<00:00, 394.66it/s]100%|██████████| 10/10 [00:00<00:00, 398.49it/s]100%|██████████| 10/10 [00:00<00:00, 402.15it/s]100%|██████████| 10/10 [00:00<00:00, 404.74it/s]
100%|██████████| 10/10 [00:00<00:00, 390.26it/s]

100%|██████████| 10/10 [00:00<00:00, 388.48it/s]


2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 1...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 0...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 2...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 3...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 4...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 5...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 7...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 418.37it/s]100%|██████████| 10/10 [00:00<00:00, 421.16it/s]
100%|██████████| 10/10 [00:00<00:00, 399.17it/s]
100%|██████████| 10/10 [00:00<00:00, 401.97it/s]
100%|██████████| 10/10 [00:00<00:00, 399.50it/s]100%|██████████| 10/10 [00:00<00:00, 397.41it/s]100%|██████████| 10/10 [00:00<00:00, 401.11it/s]
100%|██████████| 10/10 [00:00<00:00, 398.53it/s]



2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 2...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 3...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 1...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 0...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 4...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 7...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 6...
2025-11-10:13:56:32 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 5...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 417.82it/s]
100%|██████████| 10/10 [00:00<00:00, 419.87it/s]100%|██████████| 10/10 [00:00<00:00, 404.25it/s]
100%|██████████| 10/10 [00:00<00:00, 407.19it/s]
100%|██████████| 10/10 [00:00<00:00, 405.17it/s]100%|██████████| 10/10 [00:00<00:00, 369.02it/s]100%|██████████| 10/10 [00:00<00:00, 401.23it/s]100%|██████████| 10/10 [00:00<00:00, 404.95it/s]




2025-11-10:13:56:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:32 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:32 INFO     [evaluator:574] Running generate_until requests
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f87b1d23400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f87b1d23400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f406c0b3400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:13:56:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f406c0b3400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f077016b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f077016b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f57801270a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:13:56:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f57801270a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f41d40cf400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f41d40cf400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fa9001db400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:13:56:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fa9001db400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fbabc15b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fbabc15b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f304da8b490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:13:56:35 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f304da8b490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 691.05 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 680.26 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 705.23 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 681.86 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 669.98 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 698.50 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 686.50 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 668.70 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 687.93 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 658.66 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 675.19 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 670.33 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 670.06 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 658.10 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 659.11 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Generating...:   1%|▏         | 1/70 [00:05<06:20,  5.51s/it]Generating...:   1%|▏         | 1/70 [00:05<06:20,  5.52s/it]Generating...:   1%|▏         | 1/70 [00:05<06:20,  5.51s/it]Generating...:   1%|▏         | 1/70 [00:05<06:20,  5.52s/it]Generating...:   1%|▏         | 1/70 [00:05<06:19,  5.51s/it]Generating...:   1%|▏         | 1/70 [00:05<06:19,  5.50s/it]Generating...:   1%|▏         | 1/70 [00:05<06:20,  5.51s/it]Generating...:   1%|▏         | 1/70 [00:05<06:19,  5.50s/it]Generating...:   3%|▎         | 2/70 [00:11<06:33,  5.79s/it]Generating...:   3%|▎         | 2/70 [00:11<06:34,  5.80s/it]Generating...:   3%|▎         | 2/70 [00:11<06:34,  5.80s/it]Generating...:   3%|▎         | 2/70 [00:11<06:33,  5.79s/it]Generating...:   3%|▎         | 2/70 [00:11<06:34,  5.79s/it]Generating...:   3%|▎         | 2/70 [00:11<06:33,  5.79s/it]Generating...:   3%|▎         | 2/70 [00:11<06:33,  5.79s/it]Generating...:   3%|▎         | 2/70 [00:11<06:33,  5.79s/it]Generating...:   4%|▍         | 3/70 [00:15<05:48,  5.20s/it]Generating...:   4%|▍         | 3/70 [00:15<05:48,  5.20s/it]Generating...:   4%|▍         | 3/70 [00:15<05:48,  5.20s/it]Generating...:   4%|▍         | 3/70 [00:15<05:48,  5.20s/it]Generating...:   4%|▍         | 3/70 [00:15<05:48,  5.20s/it]Generating...:   4%|▍         | 3/70 [00:15<05:48,  5.20s/it]Generating...:   4%|▍         | 3/70 [00:15<05:48,  5.20s/it]Generating...:   4%|▍         | 3/70 [00:15<05:48,  5.20s/it]Generating...:   6%|▌         | 4/70 [00:20<05:24,  4.92s/it]Generating...:   6%|▌         | 4/70 [00:20<05:24,  4.92s/it]Generating...:   6%|▌         | 4/70 [00:20<05:24,  4.92s/it]Generating...:   6%|▌         | 4/70 [00:20<05:24,  4.92s/it]Generating...:   6%|▌         | 4/70 [00:20<05:24,  4.92s/it]Generating...:   6%|▌         | 4/70 [00:20<05:24,  4.92s/it]Generating...:   6%|▌         | 4/70 [00:20<05:24,  4.92s/it]Generating...:   6%|▌         | 4/70 [00:20<05:24,  4.92s/it]Generating...:   7%|▋         | 5/70 [00:25<05:31,  5.11s/it]Generating...:   7%|▋         | 5/70 [00:25<05:31,  5.11s/it]Generating...:   7%|▋         | 5/70 [00:25<05:31,  5.11s/it]Generating...:   7%|▋         | 5/70 [00:25<05:31,  5.11s/it]Generating...:   7%|▋         | 5/70 [00:25<05:31,  5.11s/it]Generating...:   7%|▋         | 5/70 [00:25<05:31,  5.11s/it]Generating...:   7%|▋         | 5/70 [00:25<05:31,  5.11s/it]Generating...:   7%|▋         | 5/70 [00:25<05:31,  5.11s/it]Generating...:   9%|▊         | 6/70 [00:30<05:13,  4.90s/it]Generating...:   9%|▊         | 6/70 [00:30<05:13,  4.90s/it]Generating...:   9%|▊         | 6/70 [00:30<05:13,  4.90s/it]Generating...:   9%|▊         | 6/70 [00:30<05:13,  4.90s/it]Generating...:   9%|▊         | 6/70 [00:30<05:13,  4.90s/it]Generating...:   9%|▊         | 6/70 [00:30<05:13,  4.90s/it]Generating...:   9%|▊         | 6/70 [00:30<05:13,  4.90s/it]Generating...:   9%|▊         | 6/70 [00:30<05:13,  4.90s/it]Generating...:  10%|█         | 7/70 [00:37<05:45,  5.49s/it]Generating...:  10%|█         | 7/70 [00:37<05:45,  5.49s/it]Generating...:  10%|█         | 7/70 [00:37<05:45,  5.49s/it]Generating...:  10%|█         | 7/70 [00:37<05:45,  5.49s/it]Generating...:  10%|█         | 7/70 [00:37<05:45,  5.49s/it]Generating...:  10%|█         | 7/70 [00:37<05:45,  5.49s/it]Generating...:  10%|█         | 7/70 [00:37<05:45,  5.49s/it]Generating...:  10%|█         | 7/70 [00:37<05:45,  5.49s/it]Generating...:  11%|█▏        | 8/70 [00:41<05:21,  5.18s/it]Generating...:  11%|█▏        | 8/70 [00:41<05:21,  5.18s/it]Generating...:  11%|█▏        | 8/70 [00:41<05:21,  5.18s/it]Generating...:  11%|█▏        | 8/70 [00:41<05:21,  5.18s/it]Generating...:  11%|█▏        | 8/70 [00:41<05:21,  5.18s/it]Generating...:  11%|█▏        | 8/70 [00:41<05:21,  5.18s/it]Generating...:  11%|█▏        | 8/70 [00:41<05:21,  5.18s/it]Generating...:  11%|█▏        | 8/70 [00:41<05:21,  5.18s/it]Generating...:  13%|█▎        | 9/70 [00:47<05:36,  5.52s/it]Generating...:  13%|█▎        | 9/70 [00:47<05:36,  5.52s/it]Generating...:  13%|█▎        | 9/70 [00:47<05:36,  5.52s/it]Generating...:  13%|█▎        | 9/70 [00:47<05:36,  5.52s/it]Generating...:  13%|█▎        | 9/70 [00:47<05:36,  5.52s/it]Generating...:  13%|█▎        | 9/70 [00:47<05:36,  5.52s/it]Generating...:  13%|█▎        | 9/70 [00:47<05:36,  5.52s/it]Generating...:  13%|█▎        | 9/70 [00:47<05:36,  5.52s/it]Generating...:  14%|█▍        | 10/70 [00:53<05:30,  5.50s/it]Generating...:  14%|█▍        | 10/70 [00:53<05:30,  5.50s/it]Generating...:  14%|█▍        | 10/70 [00:53<05:30,  5.50s/it]Generating...:  14%|█▍        | 10/70 [00:53<05:30,  5.50s/it]Generating...:  14%|█▍        | 10/70 [00:53<05:30,  5.50s/it]Generating...:  14%|█▍        | 10/70 [00:53<05:30,  5.50s/it]Generating...:  14%|█▍        | 10/70 [00:53<05:30,  5.50s/it]Generating...:  14%|█▍        | 10/70 [00:53<05:30,  5.50s/it]Generating...:  16%|█▌        | 11/70 [00:59<05:29,  5.59s/it]Generating...:  16%|█▌        | 11/70 [00:59<05:29,  5.59s/it]Generating...:  16%|█▌        | 11/70 [00:59<05:29,  5.59s/it]Generating...:  16%|█▌        | 11/70 [00:59<05:29,  5.59s/it]Generating...:  16%|█▌        | 11/70 [00:59<05:29,  5.59s/it]Generating...:  16%|█▌        | 11/70 [00:59<05:29,  5.59s/it]Generating...:  16%|█▌        | 11/70 [00:59<05:29,  5.59s/it]Generating...:  16%|█▌        | 11/70 [00:59<05:29,  5.59s/it]Generating...:  17%|█▋        | 12/70 [01:03<05:06,  5.28s/it]Generating...:  17%|█▋        | 12/70 [01:03<05:06,  5.28s/it]Generating...:  17%|█▋        | 12/70 [01:03<05:06,  5.28s/it]Generating...:  17%|█▋        | 12/70 [01:03<05:06,  5.28s/it]Generating...:  17%|█▋        | 12/70 [01:03<05:06,  5.28s/it]Generating...:  17%|█▋        | 12/70 [01:03<05:06,  5.28s/it]Generating...:  17%|█▋        | 12/70 [01:03<05:06,  5.28s/it]Generating...:  17%|█▋        | 12/70 [01:03<05:06,  5.28s/it]Generating...:  19%|█▊        | 13/70 [01:08<04:48,  5.06s/it]Generating...:  19%|█▊        | 13/70 [01:08<04:48,  5.06s/it]Generating...:  19%|█▊        | 13/70 [01:08<04:48,  5.06s/it]Generating...:  19%|█▊        | 13/70 [01:08<04:48,  5.06s/it]Generating...:  19%|█▊        | 13/70 [01:08<04:48,  5.06s/it]Generating...:  19%|█▊        | 13/70 [01:08<04:48,  5.06s/it]Generating...:  19%|█▊        | 13/70 [01:08<04:48,  5.06s/it]Generating...:  19%|█▊        | 13/70 [01:08<04:48,  5.06s/it]Generating...:  20%|██        | 14/70 [01:14<04:55,  5.27s/it]Generating...:  20%|██        | 14/70 [01:14<04:55,  5.27s/it]Generating...:  20%|██        | 14/70 [01:14<04:55,  5.27s/it]Generating...:  20%|██        | 14/70 [01:14<04:55,  5.27s/it]Generating...:  20%|██        | 14/70 [01:14<04:55,  5.27s/it]Generating...:  20%|██        | 14/70 [01:14<04:55,  5.27s/it]Generating...:  20%|██        | 14/70 [01:14<04:55,  5.27s/it]Generating...:  20%|██        | 14/70 [01:14<04:55,  5.27s/it]Generating...:  21%|██▏       | 15/70 [01:19<04:55,  5.38s/it]Generating...:  21%|██▏       | 15/70 [01:19<04:55,  5.38s/it]Generating...:  21%|██▏       | 15/70 [01:19<04:55,  5.38s/it]Generating...:  21%|██▏       | 15/70 [01:19<04:55,  5.38s/it]Generating...:  21%|██▏       | 15/70 [01:19<04:55,  5.38s/it]Generating...:  21%|██▏       | 15/70 [01:19<04:55,  5.38s/it]Generating...:  21%|██▏       | 15/70 [01:19<04:55,  5.38s/it]Generating...:  21%|██▏       | 15/70 [01:19<04:55,  5.38s/it]Generating...:  23%|██▎       | 16/70 [01:26<05:09,  5.73s/it]Generating...:  23%|██▎       | 16/70 [01:26<05:09,  5.73s/it]Generating...:  23%|██▎       | 16/70 [01:26<05:09,  5.73s/it]Generating...:  23%|██▎       | 16/70 [01:26<05:09,  5.73s/it]Generating...:  23%|██▎       | 16/70 [01:26<05:09,  5.73s/it]Generating...:  23%|██▎       | 16/70 [01:26<05:09,  5.73s/it]Generating...:  23%|██▎       | 16/70 [01:26<05:09,  5.73s/it]Generating...:  23%|██▎       | 16/70 [01:26<05:09,  5.73s/it]Generating...:  24%|██▍       | 17/70 [01:32<05:10,  5.86s/it]Generating...:  24%|██▍       | 17/70 [01:32<05:10,  5.86s/it]Generating...:  24%|██▍       | 17/70 [01:32<05:10,  5.86s/it]Generating...:  24%|██▍       | 17/70 [01:32<05:10,  5.86s/it]Generating...:  24%|██▍       | 17/70 [01:32<05:10,  5.86s/it]Generating...:  24%|██▍       | 17/70 [01:32<05:10,  5.86s/it]Generating...:  24%|██▍       | 17/70 [01:32<05:10,  5.86s/it]Generating...:  24%|██▍       | 17/70 [01:32<05:10,  5.86s/it]Generating...:  26%|██▌       | 18/70 [01:38<05:03,  5.83s/it]Generating...:  26%|██▌       | 18/70 [01:38<05:03,  5.83s/it]Generating...:  26%|██▌       | 18/70 [01:38<05:03,  5.83s/it]Generating...:  26%|██▌       | 18/70 [01:38<05:03,  5.83s/it]Generating...:  26%|██▌       | 18/70 [01:38<05:03,  5.83s/it]Generating...:  26%|██▌       | 18/70 [01:38<05:03,  5.83s/it]Generating...:  26%|██▌       | 18/70 [01:38<05:03,  5.83s/it]Generating...:  26%|██▌       | 18/70 [01:38<05:03,  5.83s/it]Generating...:  27%|██▋       | 19/70 [01:44<05:11,  6.10s/it]Generating...:  27%|██▋       | 19/70 [01:44<05:11,  6.10s/it]Generating...:  27%|██▋       | 19/70 [01:44<05:11,  6.10s/it]Generating...:  27%|██▋       | 19/70 [01:44<05:11,  6.10s/it]Generating...:  27%|██▋       | 19/70 [01:44<05:11,  6.10s/it]Generating...:  27%|██▋       | 19/70 [01:44<05:11,  6.10s/it]Generating...:  27%|██▋       | 19/70 [01:44<05:11,  6.10s/it]Generating...:  27%|██▋       | 19/70 [01:44<05:11,  6.10s/it]Generating...:  29%|██▊       | 20/70 [01:51<05:12,  6.24s/it]Generating...:  29%|██▊       | 20/70 [01:51<05:12,  6.24s/it]Generating...:  29%|██▊       | 20/70 [01:51<05:12,  6.24s/it]Generating...:  29%|██▊       | 20/70 [01:51<05:12,  6.24s/it]Generating...:  29%|██▊       | 20/70 [01:51<05:12,  6.24s/it]Generating...:  29%|██▊       | 20/70 [01:51<05:12,  6.24s/it]Generating...:  29%|██▊       | 20/70 [01:51<05:12,  6.24s/it]Generating...:  29%|██▊       | 20/70 [01:51<05:12,  6.24s/it]Generating...:  30%|███       | 21/70 [01:58<05:11,  6.35s/it]Generating...:  30%|███       | 21/70 [01:58<05:11,  6.35s/it]Generating...:  30%|███       | 21/70 [01:58<05:11,  6.35s/it]Generating...:  30%|███       | 21/70 [01:58<05:11,  6.35s/it]Generating...:  30%|███       | 21/70 [01:58<05:11,  6.35s/it]Generating...:  30%|███       | 21/70 [01:58<05:11,  6.35s/it]Generating...:  30%|███       | 21/70 [01:58<05:11,  6.35s/it]Generating...:  30%|███       | 21/70 [01:58<05:11,  6.35s/it]Generating...:  31%|███▏      | 22/70 [02:05<05:22,  6.72s/it]Generating...:  31%|███▏      | 22/70 [02:05<05:22,  6.72s/it]Generating...:  31%|███▏      | 22/70 [02:05<05:22,  6.72s/it]Generating...:  31%|███▏      | 22/70 [02:05<05:22,  6.72s/it]Generating...:  31%|███▏      | 22/70 [02:05<05:22,  6.72s/it]Generating...:  31%|███▏      | 22/70 [02:05<05:22,  6.72s/it]Generating...:  31%|███▏      | 22/70 [02:05<05:22,  6.72s/it]Generating...:  31%|███▏      | 22/70 [02:05<05:22,  6.72s/it]Generating...:  33%|███▎      | 23/70 [02:12<05:16,  6.74s/it]Generating...:  33%|███▎      | 23/70 [02:12<05:16,  6.74s/it]Generating...:  33%|███▎      | 23/70 [02:12<05:16,  6.74s/it]Generating...:  33%|███▎      | 23/70 [02:12<05:16,  6.74s/it]Generating...:  33%|███▎      | 23/70 [02:12<05:16,  6.74s/it]Generating...:  33%|███▎      | 23/70 [02:12<05:16,  6.74s/it]Generating...:  33%|███▎      | 23/70 [02:12<05:16,  6.74s/it]Generating...:  33%|███▎      | 23/70 [02:12<05:16,  6.74s/it]Generating...:  34%|███▍      | 24/70 [02:18<05:03,  6.60s/it]Generating...:  34%|███▍      | 24/70 [02:18<05:03,  6.60s/it]Generating...:  34%|███▍      | 24/70 [02:18<05:03,  6.60s/it]Generating...:  34%|███▍      | 24/70 [02:18<05:03,  6.60s/it]Generating...:  34%|███▍      | 24/70 [02:18<05:03,  6.60s/it]Generating...:  34%|███▍      | 24/70 [02:18<05:03,  6.60s/it]Generating...:  34%|███▍      | 24/70 [02:18<05:03,  6.60s/it]Generating...:  34%|███▍      | 24/70 [02:18<05:03,  6.60s/it]Generating...:  36%|███▌      | 25/70 [02:24<04:51,  6.48s/it]Generating...:  36%|███▌      | 25/70 [02:24<04:51,  6.48s/it]Generating...:  36%|███▌      | 25/70 [02:24<04:51,  6.48s/it]Generating...:  36%|███▌      | 25/70 [02:24<04:51,  6.48s/it]Generating...:  36%|███▌      | 25/70 [02:24<04:51,  6.48s/it]Generating...:  36%|███▌      | 25/70 [02:24<04:51,  6.48s/it]Generating...:  36%|███▌      | 25/70 [02:24<04:51,  6.48s/it]Generating...:  36%|███▌      | 25/70 [02:24<04:51,  6.48s/it]Generating...:  37%|███▋      | 26/70 [02:31<04:41,  6.39s/it]Generating...:  37%|███▋      | 26/70 [02:31<04:41,  6.39s/it]Generating...:  37%|███▋      | 26/70 [02:31<04:41,  6.39s/it]Generating...:  37%|███▋      | 26/70 [02:31<04:41,  6.39s/it]Generating...:  37%|███▋      | 26/70 [02:31<04:41,  6.39s/it]Generating...:  37%|███▋      | 26/70 [02:31<04:41,  6.39s/it]Generating...:  37%|███▋      | 26/70 [02:31<04:41,  6.39s/it]Generating...:  37%|███▋      | 26/70 [02:31<04:41,  6.39s/it]Generating...:  39%|███▊      | 27/70 [02:37<04:29,  6.27s/it]Generating...:  39%|███▊      | 27/70 [02:37<04:29,  6.27s/it]Generating...:  39%|███▊      | 27/70 [02:37<04:29,  6.27s/it]Generating...:  39%|███▊      | 27/70 [02:37<04:29,  6.27s/it]Generating...:  39%|███▊      | 27/70 [02:37<04:29,  6.27s/it]Generating...:  39%|███▊      | 27/70 [02:37<04:29,  6.27s/it]Generating...:  39%|███▊      | 27/70 [02:37<04:29,  6.27s/it]Generating...:  39%|███▊      | 27/70 [02:37<04:29,  6.27s/it]Generating...:  40%|████      | 28/70 [02:43<04:27,  6.37s/it]Generating...:  40%|████      | 28/70 [02:43<04:27,  6.37s/it]Generating...:  40%|████      | 28/70 [02:43<04:27,  6.37s/it]Generating...:  40%|████      | 28/70 [02:43<04:27,  6.37s/it]Generating...:  40%|████      | 28/70 [02:43<04:27,  6.37s/it]Generating...:  40%|████      | 28/70 [02:43<04:27,  6.37s/it]Generating...:  40%|████      | 28/70 [02:43<04:27,  6.37s/it]Generating...:  40%|████      | 28/70 [02:43<04:27,  6.37s/it]Generating...:  41%|████▏     | 29/70 [02:49<04:18,  6.31s/it]Generating...:  41%|████▏     | 29/70 [02:49<04:18,  6.31s/it]Generating...:  41%|████▏     | 29/70 [02:49<04:18,  6.31s/it]Generating...:  41%|████▏     | 29/70 [02:49<04:18,  6.31s/it]Generating...:  41%|████▏     | 29/70 [02:49<04:18,  6.31s/it]Generating...:  41%|████▏     | 29/70 [02:49<04:18,  6.31s/it]Generating...:  41%|████▏     | 29/70 [02:49<04:18,  6.31s/it]Generating...:  41%|████▏     | 29/70 [02:49<04:18,  6.31s/it]Generating...:  43%|████▎     | 30/70 [02:56<04:11,  6.28s/it]Generating...:  43%|████▎     | 30/70 [02:56<04:11,  6.28s/it]Generating...:  43%|████▎     | 30/70 [02:56<04:11,  6.28s/it]Generating...:  43%|████▎     | 30/70 [02:56<04:11,  6.28s/it]Generating...:  43%|████▎     | 30/70 [02:56<04:11,  6.28s/it]Generating...:  43%|████▎     | 30/70 [02:56<04:11,  6.28s/it]Generating...:  43%|████▎     | 30/70 [02:56<04:11,  6.28s/it]Generating...:  43%|████▎     | 30/70 [02:56<04:11,  6.28s/it]Generating...:  44%|████▍     | 31/70 [03:02<04:01,  6.20s/it]Generating...:  44%|████▍     | 31/70 [03:02<04:01,  6.20s/it]Generating...:  44%|████▍     | 31/70 [03:02<04:01,  6.20s/it]Generating...:  44%|████▍     | 31/70 [03:02<04:01,  6.20s/it]Generating...:  44%|████▍     | 31/70 [03:02<04:01,  6.20s/it]Generating...:  44%|████▍     | 31/70 [03:02<04:01,  6.20s/it]Generating...:  44%|████▍     | 31/70 [03:02<04:01,  6.20s/it]Generating...:  44%|████▍     | 31/70 [03:02<04:01,  6.20s/it]Generating...:  46%|████▌     | 32/70 [03:07<03:47,  6.00s/it]Generating...:  46%|████▌     | 32/70 [03:07<03:47,  6.00s/it]Generating...:  46%|████▌     | 32/70 [03:07<03:47,  6.00s/it]Generating...:  46%|████▌     | 32/70 [03:07<03:47,  6.00s/it]Generating...:  46%|████▌     | 32/70 [03:07<03:47,  6.00s/it]Generating...:  46%|████▌     | 32/70 [03:07<03:47,  6.00s/it]Generating...:  46%|████▌     | 32/70 [03:07<03:47,  6.00s/it]Generating...:  46%|████▌     | 32/70 [03:07<03:47,  6.00s/it]Generating...:  47%|████▋     | 33/70 [03:18<04:36,  7.47s/it]Generating...:  47%|████▋     | 33/70 [03:18<04:36,  7.47s/it]Generating...:  47%|████▋     | 33/70 [03:18<04:36,  7.47s/it]Generating...:  47%|████▋     | 33/70 [03:18<04:36,  7.47s/it]Generating...:  47%|████▋     | 33/70 [03:18<04:36,  7.47s/it]Generating...:  47%|████▋     | 33/70 [03:18<04:36,  7.47s/it]Generating...:  47%|████▋     | 33/70 [03:18<04:36,  7.47s/it]Generating...:  47%|████▋     | 33/70 [03:18<04:36,  7.47s/it]Generating...:  49%|████▊     | 34/70 [03:24<04:13,  7.04s/it]Generating...:  49%|████▊     | 34/70 [03:24<04:13,  7.04s/it]Generating...:  49%|████▊     | 34/70 [03:24<04:13,  7.04s/it]Generating...:  49%|████▊     | 34/70 [03:24<04:13,  7.04s/it]Generating...:  49%|████▊     | 34/70 [03:24<04:13,  7.04s/it]Generating...:  49%|████▊     | 34/70 [03:24<04:13,  7.04s/it]Generating...:  49%|████▊     | 34/70 [03:24<04:13,  7.04s/it]Generating...:  49%|████▊     | 34/70 [03:24<04:13,  7.04s/it]Generating...:  50%|█████     | 35/70 [03:30<03:51,  6.62s/it]Generating...:  50%|█████     | 35/70 [03:30<03:51,  6.62s/it]Generating...:  50%|█████     | 35/70 [03:30<03:51,  6.62s/it]Generating...:  50%|█████     | 35/70 [03:30<03:51,  6.62s/it]Generating...:  50%|█████     | 35/70 [03:30<03:51,  6.62s/it]Generating...:  50%|█████     | 35/70 [03:30<03:51,  6.62s/it]Generating...:  50%|█████     | 35/70 [03:30<03:51,  6.62s/it]Generating...:  50%|█████     | 35/70 [03:30<03:51,  6.62s/it]Generating...:  51%|█████▏    | 36/70 [03:35<03:32,  6.26s/it]Generating...:  51%|█████▏    | 36/70 [03:35<03:32,  6.26s/it]Generating...:  51%|█████▏    | 36/70 [03:35<03:32,  6.26s/it]Generating...:  51%|█████▏    | 36/70 [03:35<03:32,  6.26s/it]Generating...:  51%|█████▏    | 36/70 [03:35<03:32,  6.26s/it]Generating...:  51%|█████▏    | 36/70 [03:35<03:32,  6.26s/it]Generating...:  51%|█████▏    | 36/70 [03:35<03:32,  6.26s/it]Generating...:  51%|█████▏    | 36/70 [03:35<03:32,  6.26s/it]Generating...:  53%|█████▎    | 37/70 [03:41<03:22,  6.14s/it]Generating...:  53%|█████▎    | 37/70 [03:41<03:22,  6.14s/it]Generating...:  53%|█████▎    | 37/70 [03:41<03:22,  6.14s/it]Generating...:  53%|█████▎    | 37/70 [03:41<03:22,  6.14s/it]Generating...:  53%|█████▎    | 37/70 [03:41<03:22,  6.14s/it]Generating...:  53%|█████▎    | 37/70 [03:41<03:22,  6.14s/it]Generating...:  53%|█████▎    | 37/70 [03:41<03:22,  6.14s/it]Generating...:  53%|█████▎    | 37/70 [03:41<03:22,  6.14s/it]Generating...:  54%|█████▍    | 38/70 [03:46<03:10,  5.97s/it]Generating...:  54%|█████▍    | 38/70 [03:46<03:10,  5.97s/it]Generating...:  54%|█████▍    | 38/70 [03:46<03:10,  5.97s/it]Generating...:  54%|█████▍    | 38/70 [03:46<03:10,  5.97s/it]Generating...:  54%|█████▍    | 38/70 [03:46<03:10,  5.97s/it]Generating...:  54%|█████▍    | 38/70 [03:46<03:10,  5.97s/it]Generating...:  54%|█████▍    | 38/70 [03:46<03:10,  5.97s/it]Generating...:  54%|█████▍    | 38/70 [03:46<03:10,  5.97s/it]Generating...:  56%|█████▌    | 39/70 [03:52<03:02,  5.90s/it]Generating...:  56%|█████▌    | 39/70 [03:52<03:02,  5.90s/it]Generating...:  56%|█████▌    | 39/70 [03:52<03:02,  5.90s/it]Generating...:  56%|█████▌    | 39/70 [03:52<03:02,  5.90s/it]Generating...:  56%|█████▌    | 39/70 [03:52<03:02,  5.90s/it]Generating...:  56%|█████▌    | 39/70 [03:52<03:02,  5.90s/it]Generating...:  56%|█████▌    | 39/70 [03:52<03:02,  5.90s/it]Generating...:  56%|█████▌    | 39/70 [03:52<03:02,  5.90s/it]Generating...:  57%|█████▋    | 40/70 [03:58<02:52,  5.75s/it]Generating...:  57%|█████▋    | 40/70 [03:58<02:52,  5.75s/it]Generating...:  57%|█████▋    | 40/70 [03:58<02:52,  5.75s/it]Generating...:  57%|█████▋    | 40/70 [03:58<02:52,  5.75s/it]Generating...:  57%|█████▋    | 40/70 [03:58<02:52,  5.75s/it]Generating...:  57%|█████▋    | 40/70 [03:58<02:52,  5.75s/it]Generating...:  57%|█████▋    | 40/70 [03:58<02:52,  5.75s/it]Generating...:  57%|█████▋    | 40/70 [03:58<02:52,  5.75s/it]Generating...:  59%|█████▊    | 41/70 [04:02<02:36,  5.40s/it]Generating...:  59%|█████▊    | 41/70 [04:02<02:36,  5.40s/it]Generating...:  59%|█████▊    | 41/70 [04:02<02:36,  5.40s/it]Generating...:  59%|█████▊    | 41/70 [04:02<02:36,  5.40s/it]Generating...:  59%|█████▊    | 41/70 [04:02<02:36,  5.40s/it]Generating...:  59%|█████▊    | 41/70 [04:02<02:36,  5.40s/it]Generating...:  59%|█████▊    | 41/70 [04:02<02:36,  5.40s/it]Generating...:  59%|█████▊    | 41/70 [04:02<02:36,  5.40s/it]Generating...:  60%|██████    | 42/70 [04:08<02:33,  5.48s/it]Generating...:  60%|██████    | 42/70 [04:08<02:33,  5.48s/it]Generating...:  60%|██████    | 42/70 [04:08<02:33,  5.48s/it]Generating...:  60%|██████    | 42/70 [04:08<02:33,  5.48s/it]Generating...:  60%|██████    | 42/70 [04:08<02:33,  5.48s/it]Generating...:  60%|██████    | 42/70 [04:08<02:33,  5.48s/it]Generating...:  60%|██████    | 42/70 [04:08<02:33,  5.48s/it]Generating...:  60%|██████    | 42/70 [04:08<02:33,  5.48s/it]Generating...:  61%|██████▏   | 43/70 [04:13<02:27,  5.45s/it]Generating...:  61%|██████▏   | 43/70 [04:13<02:27,  5.45s/it]Generating...:  61%|██████▏   | 43/70 [04:13<02:27,  5.45s/it]Generating...:  61%|██████▏   | 43/70 [04:13<02:27,  5.45s/it]Generating...:  61%|██████▏   | 43/70 [04:13<02:27,  5.45s/it]Generating...:  61%|██████▏   | 43/70 [04:13<02:27,  5.45s/it]Generating...:  61%|██████▏   | 43/70 [04:13<02:27,  5.45s/it]Generating...:  61%|██████▏   | 43/70 [04:13<02:27,  5.45s/it]Generating...:  63%|██████▎   | 44/70 [04:19<02:22,  5.46s/it]Generating...:  63%|██████▎   | 44/70 [04:19<02:22,  5.46s/it]Generating...:  63%|██████▎   | 44/70 [04:19<02:22,  5.46s/it]Generating...:  63%|██████▎   | 44/70 [04:19<02:22,  5.46s/it]Generating...:  63%|██████▎   | 44/70 [04:19<02:22,  5.46s/it]Generating...:  63%|██████▎   | 44/70 [04:19<02:22,  5.46s/it]Generating...:  63%|██████▎   | 44/70 [04:19<02:22,  5.46s/it]Generating...:  63%|██████▎   | 44/70 [04:19<02:22,  5.46s/it]Generating...:  64%|██████▍   | 45/70 [04:23<02:09,  5.19s/it]Generating...:  64%|██████▍   | 45/70 [04:23<02:09,  5.19s/it]Generating...:  64%|██████▍   | 45/70 [04:23<02:09,  5.19s/it]Generating...:  64%|██████▍   | 45/70 [04:23<02:09,  5.19s/it]Generating...:  64%|██████▍   | 45/70 [04:23<02:09,  5.19s/it]Generating...:  64%|██████▍   | 45/70 [04:23<02:09,  5.19s/it]Generating...:  64%|██████▍   | 45/70 [04:23<02:09,  5.19s/it]Generating...:  64%|██████▍   | 45/70 [04:23<02:09,  5.19s/it]Generating...:  66%|██████▌   | 46/70 [04:29<02:09,  5.41s/it]Generating...:  66%|██████▌   | 46/70 [04:29<02:09,  5.41s/it]Generating...:  66%|██████▌   | 46/70 [04:29<02:09,  5.41s/it]Generating...:  66%|██████▌   | 46/70 [04:29<02:09,  5.41s/it]Generating...:  66%|██████▌   | 46/70 [04:29<02:09,  5.41s/it]Generating...:  66%|██████▌   | 46/70 [04:29<02:09,  5.41s/it]Generating...:  66%|██████▌   | 46/70 [04:29<02:09,  5.41s/it]Generating...:  66%|██████▌   | 46/70 [04:29<02:09,  5.41s/it]Generating...:  67%|██████▋   | 47/70 [04:35<02:05,  5.46s/it]Generating...:  67%|██████▋   | 47/70 [04:35<02:05,  5.46s/it]Generating...:  67%|██████▋   | 47/70 [04:35<02:05,  5.46s/it]Generating...:  67%|██████▋   | 47/70 [04:35<02:05,  5.46s/it]Generating...:  67%|██████▋   | 47/70 [04:35<02:05,  5.46s/it]Generating...:  67%|██████▋   | 47/70 [04:35<02:05,  5.46s/it]Generating...:  67%|██████▋   | 47/70 [04:35<02:05,  5.46s/it]Generating...:  67%|██████▋   | 47/70 [04:35<02:05,  5.46s/it]Generating...:  69%|██████▊   | 48/70 [04:40<02:00,  5.48s/it]Generating...:  69%|██████▊   | 48/70 [04:40<02:00,  5.48s/it]Generating...:  69%|██████▊   | 48/70 [04:40<02:00,  5.48s/it]Generating...:  69%|██████▊   | 48/70 [04:40<02:00,  5.48s/it]Generating...:  69%|██████▊   | 48/70 [04:40<02:00,  5.48s/it]Generating...:  69%|██████▊   | 48/70 [04:40<02:00,  5.48s/it]Generating...:  69%|██████▊   | 48/70 [04:40<02:00,  5.48s/it]Generating...:  69%|██████▊   | 48/70 [04:40<02:00,  5.48s/it]Generating...:  70%|███████   | 49/70 [04:46<01:55,  5.50s/it]Generating...:  70%|███████   | 49/70 [04:46<01:55,  5.50s/it]Generating...:  70%|███████   | 49/70 [04:46<01:55,  5.50s/it]Generating...:  70%|███████   | 49/70 [04:46<01:55,  5.50s/it]Generating...:  70%|███████   | 49/70 [04:46<01:55,  5.50s/it]Generating...:  70%|███████   | 49/70 [04:46<01:55,  5.50s/it]Generating...:  70%|███████   | 49/70 [04:46<01:55,  5.50s/it]Generating...:  70%|███████   | 49/70 [04:46<01:55,  5.50s/it]Generating...:  71%|███████▏  | 50/70 [04:50<01:44,  5.23s/it]Generating...:  71%|███████▏  | 50/70 [04:50<01:44,  5.23s/it]Generating...:  71%|███████▏  | 50/70 [04:50<01:44,  5.23s/it]Generating...:  71%|███████▏  | 50/70 [04:50<01:44,  5.23s/it]Generating...:  71%|███████▏  | 50/70 [04:50<01:44,  5.23s/it]Generating...:  71%|███████▏  | 50/70 [04:50<01:44,  5.23s/it]Generating...:  71%|███████▏  | 50/70 [04:50<01:44,  5.23s/it]Generating...:  71%|███████▏  | 50/70 [04:50<01:44,  5.23s/it]Generating...:  73%|███████▎  | 51/70 [04:56<01:43,  5.47s/it]Generating...:  73%|███████▎  | 51/70 [04:56<01:43,  5.47s/it]Generating...:  73%|███████▎  | 51/70 [04:56<01:43,  5.47s/it]Generating...:  73%|███████▎  | 51/70 [04:56<01:43,  5.47s/it]Generating...:  73%|███████▎  | 51/70 [04:56<01:43,  5.47s/it]Generating...:  73%|███████▎  | 51/70 [04:57<01:43,  5.47s/it]Generating...:  73%|███████▎  | 51/70 [04:56<01:43,  5.47s/it]Generating...:  73%|███████▎  | 51/70 [04:56<01:43,  5.47s/it]Generating...:  74%|███████▍  | 52/70 [05:02<01:41,  5.63s/it]Generating...:  74%|███████▍  | 52/70 [05:02<01:41,  5.63s/it]Generating...:  74%|███████▍  | 52/70 [05:02<01:41,  5.63s/it]Generating...:  74%|███████▍  | 52/70 [05:02<01:41,  5.63s/it]Generating...:  74%|███████▍  | 52/70 [05:02<01:41,  5.63s/it]Generating...:  74%|███████▍  | 52/70 [05:02<01:41,  5.63s/it]Generating...:  74%|███████▍  | 52/70 [05:02<01:41,  5.63s/it]Generating...:  74%|███████▍  | 52/70 [05:02<01:41,  5.63s/it]Generating...:  76%|███████▌  | 53/70 [05:11<01:52,  6.64s/it]Generating...:  76%|███████▌  | 53/70 [05:11<01:52,  6.64s/it]Generating...:  76%|███████▌  | 53/70 [05:11<01:52,  6.64s/it]Generating...:  76%|███████▌  | 53/70 [05:11<01:52,  6.64s/it]Generating...:  76%|███████▌  | 53/70 [05:11<01:52,  6.64s/it]Generating...:  76%|███████▌  | 53/70 [05:11<01:52,  6.64s/it]Generating...:  76%|███████▌  | 53/70 [05:11<01:52,  6.64s/it]Generating...:  76%|███████▌  | 53/70 [05:11<01:52,  6.64s/it]Generating...:  77%|███████▋  | 54/70 [05:18<01:44,  6.54s/it]Generating...:  77%|███████▋  | 54/70 [05:18<01:44,  6.54s/it]Generating...:  77%|███████▋  | 54/70 [05:18<01:44,  6.54s/it]Generating...:  77%|███████▋  | 54/70 [05:18<01:44,  6.54s/it]Generating...:  77%|███████▋  | 54/70 [05:18<01:44,  6.54s/it]Generating...:  77%|███████▋  | 54/70 [05:18<01:44,  6.54s/it]Generating...:  77%|███████▋  | 54/70 [05:18<01:44,  6.54s/it]Generating...:  77%|███████▋  | 54/70 [05:18<01:44,  6.54s/it]Generating...:  79%|███████▊  | 55/70 [05:22<01:28,  5.92s/it]Generating...:  79%|███████▊  | 55/70 [05:22<01:28,  5.92s/it]Generating...:  79%|███████▊  | 55/70 [05:22<01:28,  5.92s/it]Generating...:  79%|███████▊  | 55/70 [05:22<01:28,  5.92s/it]Generating...:  79%|███████▊  | 55/70 [05:22<01:28,  5.92s/it]Generating...:  79%|███████▊  | 55/70 [05:22<01:28,  5.92s/it]Generating...:  79%|███████▊  | 55/70 [05:22<01:28,  5.92s/it]Generating...:  79%|███████▊  | 55/70 [05:22<01:28,  5.92s/it]Generating...:  80%|████████  | 56/70 [05:28<01:22,  5.87s/it]Generating...:  80%|████████  | 56/70 [05:28<01:22,  5.87s/it]Generating...:  80%|████████  | 56/70 [05:28<01:22,  5.87s/it]Generating...:  80%|████████  | 56/70 [05:28<01:22,  5.87s/it]Generating...:  80%|████████  | 56/70 [05:28<01:22,  5.87s/it]Generating...:  80%|████████  | 56/70 [05:28<01:22,  5.87s/it]Generating...:  80%|████████  | 56/70 [05:28<01:22,  5.87s/it]Generating...:  80%|████████  | 56/70 [05:28<01:22,  5.87s/it]Generating...:  81%|████████▏ | 57/70 [05:34<01:15,  5.84s/it]Generating...:  81%|████████▏ | 57/70 [05:34<01:15,  5.84s/it]Generating...:  81%|████████▏ | 57/70 [05:34<01:15,  5.84s/it]Generating...:  81%|████████▏ | 57/70 [05:34<01:15,  5.84s/it]Generating...:  81%|████████▏ | 57/70 [05:34<01:15,  5.84s/it]Generating...:  81%|████████▏ | 57/70 [05:34<01:15,  5.84s/it]Generating...:  81%|████████▏ | 57/70 [05:34<01:15,  5.84s/it]Generating...:  81%|████████▏ | 57/70 [05:34<01:15,  5.84s/it]Generating...:  83%|████████▎ | 58/70 [05:40<01:09,  5.80s/it]Generating...:  83%|████████▎ | 58/70 [05:39<01:09,  5.80s/it]Generating...:  83%|████████▎ | 58/70 [05:40<01:09,  5.80s/it]Generating...:  83%|████████▎ | 58/70 [05:39<01:09,  5.80s/it]Generating...:  83%|████████▎ | 58/70 [05:39<01:09,  5.80s/it]Generating...:  83%|████████▎ | 58/70 [05:39<01:09,  5.80s/it]Generating...:  83%|████████▎ | 58/70 [05:39<01:09,  5.80s/it]Generating...:  83%|████████▎ | 58/70 [05:40<01:09,  5.80s/it]Generating...:  84%|████████▍ | 59/70 [05:46<01:04,  5.86s/it]Generating...:  84%|████████▍ | 59/70 [05:46<01:04,  5.86s/it]Generating...:  84%|████████▍ | 59/70 [05:46<01:04,  5.86s/it]Generating...:  84%|████████▍ | 59/70 [05:45<01:04,  5.86s/it]Generating...:  84%|████████▍ | 59/70 [05:45<01:04,  5.86s/it]Generating...:  84%|████████▍ | 59/70 [05:45<01:04,  5.86s/it]Generating...:  84%|████████▍ | 59/70 [05:45<01:04,  5.86s/it]Generating...:  84%|████████▍ | 59/70 [05:45<01:04,  5.86s/it]Generating...:  86%|████████▌ | 60/70 [05:51<00:58,  5.82s/it]Generating...:  86%|████████▌ | 60/70 [05:51<00:58,  5.82s/it]Generating...:  86%|████████▌ | 60/70 [05:51<00:58,  5.82s/it]Generating...:  86%|████████▌ | 60/70 [05:51<00:58,  5.82s/it]Generating...:  86%|████████▌ | 60/70 [05:51<00:58,  5.82s/it]Generating...:  86%|████████▌ | 60/70 [05:51<00:58,  5.82s/it]Generating...:  86%|████████▌ | 60/70 [05:51<00:58,  5.82s/it]Generating...:  86%|████████▌ | 60/70 [05:51<00:58,  5.82s/it]Generating...:  87%|████████▋ | 61/70 [05:58<00:53,  5.98s/it]Generating...:  87%|████████▋ | 61/70 [05:58<00:53,  5.98s/it]Generating...:  87%|████████▋ | 61/70 [05:58<00:53,  5.98s/it]Generating...:  87%|████████▋ | 61/70 [05:58<00:53,  5.98s/it]Generating...:  87%|████████▋ | 61/70 [05:58<00:53,  5.98s/it]Generating...:  87%|████████▋ | 61/70 [05:58<00:53,  5.98s/it]Generating...:  87%|████████▋ | 61/70 [05:58<00:53,  5.98s/it]Generating...:  87%|████████▋ | 61/70 [05:58<00:53,  5.98s/it]Generating...:  89%|████████▊ | 62/70 [06:03<00:47,  5.90s/it]Generating...:  89%|████████▊ | 62/70 [06:03<00:47,  5.90s/it]Generating...:  89%|████████▊ | 62/70 [06:03<00:47,  5.90s/it]Generating...:  89%|████████▊ | 62/70 [06:03<00:47,  5.90s/it]Generating...:  89%|████████▊ | 62/70 [06:03<00:47,  5.90s/it]Generating...:  89%|████████▊ | 62/70 [06:03<00:47,  5.90s/it]Generating...:  89%|████████▊ | 62/70 [06:03<00:47,  5.90s/it]Generating...:  89%|████████▊ | 62/70 [06:03<00:47,  5.90s/it]Generating...:  90%|█████████ | 63/70 [06:11<00:46,  6.59s/it]Generating...:  90%|█████████ | 63/70 [06:11<00:46,  6.59s/it]Generating...:  90%|█████████ | 63/70 [06:11<00:46,  6.59s/it]Generating...:  90%|█████████ | 63/70 [06:11<00:46,  6.59s/it]Generating...:  90%|█████████ | 63/70 [06:11<00:46,  6.59s/it]Generating...:  90%|█████████ | 63/70 [06:11<00:46,  6.59s/it]Generating...:  90%|█████████ | 63/70 [06:11<00:46,  6.59s/it]Generating...:  90%|█████████ | 63/70 [06:11<00:46,  6.59s/it]Generating...:  91%|█████████▏| 64/70 [06:17<00:38,  6.34s/it]Generating...:  91%|█████████▏| 64/70 [06:17<00:38,  6.34s/it]Generating...:  91%|█████████▏| 64/70 [06:17<00:38,  6.34s/it]Generating...:  91%|█████████▏| 64/70 [06:17<00:38,  6.34s/it]Generating...:  91%|█████████▏| 64/70 [06:17<00:38,  6.34s/it]Generating...:  91%|█████████▏| 64/70 [06:17<00:38,  6.34s/it]Generating...:  91%|█████████▏| 64/70 [06:17<00:38,  6.34s/it]Generating...:  91%|█████████▏| 64/70 [06:17<00:38,  6.34s/it]Generating...:  93%|█████████▎| 65/70 [06:23<00:30,  6.14s/it]Generating...:  93%|█████████▎| 65/70 [06:23<00:30,  6.14s/it]Generating...:  93%|█████████▎| 65/70 [06:23<00:30,  6.14s/it]Generating...:  93%|█████████▎| 65/70 [06:23<00:30,  6.14s/it]Generating...:  93%|█████████▎| 65/70 [06:23<00:30,  6.14s/it]Generating...:  93%|█████████▎| 65/70 [06:23<00:30,  6.14s/it]Generating...:  93%|█████████▎| 65/70 [06:23<00:30,  6.14s/it]Generating...:  93%|█████████▎| 65/70 [06:23<00:30,  6.14s/it]Generating...:  94%|█████████▍| 66/70 [06:28<00:23,  5.97s/it]Generating...:  94%|█████████▍| 66/70 [06:28<00:23,  5.97s/it]Generating...:  94%|█████████▍| 66/70 [06:28<00:23,  5.97s/it]Generating...:  94%|█████████▍| 66/70 [06:28<00:23,  5.97s/it]Generating...:  94%|█████████▍| 66/70 [06:28<00:23,  5.97s/it]Generating...:  94%|█████████▍| 66/70 [06:28<00:23,  5.97s/it]Generating...:  94%|█████████▍| 66/70 [06:28<00:23,  5.97s/it]Generating...:  94%|█████████▍| 66/70 [06:28<00:23,  5.97s/it]Generating...:  96%|█████████▌| 67/70 [06:35<00:18,  6.01s/it]Generating...:  96%|█████████▌| 67/70 [06:35<00:18,  6.01s/it]Generating...:  96%|█████████▌| 67/70 [06:35<00:18,  6.01s/it]Generating...:  96%|█████████▌| 67/70 [06:35<00:18,  6.01s/it]Generating...:  96%|█████████▌| 67/70 [06:35<00:18,  6.01s/it]Generating...:  96%|█████████▌| 67/70 [06:35<00:18,  6.01s/it]Generating...:  96%|█████████▌| 67/70 [06:35<00:18,  6.01s/it]Generating...:  96%|█████████▌| 67/70 [06:35<00:18,  6.01s/it]Generating...:  97%|█████████▋| 68/70 [06:41<00:12,  6.04s/it]Generating...:  97%|█████████▋| 68/70 [06:41<00:12,  6.04s/it]Generating...:  97%|█████████▋| 68/70 [06:41<00:12,  6.04s/it]Generating...:  97%|█████████▋| 68/70 [06:41<00:12,  6.04s/it]Generating...:  97%|█████████▋| 68/70 [06:41<00:12,  6.04s/it]Generating...:  97%|█████████▋| 68/70 [06:41<00:12,  6.04s/it]Generating...:  97%|█████████▋| 68/70 [06:41<00:12,  6.04s/it]Generating...:  97%|█████████▋| 68/70 [06:41<00:12,  6.04s/it]Generating...:  99%|█████████▊| 69/70 [06:46<00:05,  5.89s/it]Generating...:  99%|█████████▊| 69/70 [06:46<00:05,  5.89s/it]Generating...:  99%|█████████▊| 69/70 [06:46<00:05,  5.89s/it]Generating...:  99%|█████████▊| 69/70 [06:46<00:05,  5.89s/it]Generating...:  99%|█████████▊| 69/70 [06:46<00:05,  5.89s/it]Generating...:  99%|█████████▊| 69/70 [06:46<00:05,  5.89s/it]Generating...:  99%|█████████▊| 69/70 [06:46<00:05,  5.89s/it]Generating...:  99%|█████████▊| 69/70 [06:46<00:05,  5.89s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.94s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.94s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.94s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.94s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.94s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.94s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.94s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.94s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.90s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.90s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.90s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.90s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.90s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.90s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.90s/it]Generating...: 100%|██████████| 70/70 [06:52<00:00,  5.90s/it]







[rank2]:W1110 14:03:30.539000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32487 hash value: 15104469249514413043
[rank1]:W1110 14:03:30.790000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30568 hash value: 14797392468415571705
[rank6]:W1110 14:03:30.825000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33496 hash value: 15511007578064890072
[rank3]:W1110 14:03:30.928000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30914 hash value: 11478918493941737605
[rank7]:W1110 14:03:30.949000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30391 hash value: 1108409386564680723
[rank4]:W1110 14:03:31.028000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32194 hash value: 14336811140513763565
[rank5]:W1110 14:03:31.251000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 29499 hash value: 8154024824765000153
[rank0]:W1110 14:03:31.298000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30328 hash value: 15211534118302100040
[rank0]:W1110 14:03:31.501000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33496 hash value: 5376666327516177835
[rank0]:W1110 14:03:31.503000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33496 hash value: 5376666327516177835
[rank0]:W1110 14:03:31.505000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33496 hash value: 5376666327516177835
[rank0]:W1110 14:03:31.507000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33496 hash value: 5376666327516177835
[rank2]:W1110 14:03:31.507000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475570979164714397
[rank3]:W1110 14:03:31.507000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17719595283208190917
[rank6]:W1110 14:03:31.507000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank4]:W1110 14:03:31.507000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5859782613744783699
[rank5]:W1110 14:03:31.507000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391363343766722197
[rank1]:W1110 14:03:31.507000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank7]:W1110 14:03:31.507000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 3192744725797834877
[rank0]:W1110 14:03:31.509000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33496 hash value: 5376666327516177835
[rank0]:W1110 14:03:31.512000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33496 hash value: 5376666327516177835
[rank0]:W1110 14:03:31.514000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33496 hash value: 5376666327516177835
[rank0]:W1110 14:03:31.516000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33496 hash value: 5376666327516177835
[rank0]:W1110 14:03:31.517000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634553868251696383
[rank0]:W1110 14:03:31.522000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6056960306392145430
[rank3]:W1110 14:03:31.522000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17719595283208190917
[rank4]:W1110 14:03:31.522000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5859782613744783699
[rank2]:W1110 14:03:31.522000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475570979164714397
[rank1]:W1110 14:03:31.522000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 13800512212344007879
[rank6]:W1110 14:03:31.522000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634553868251725038
[rank7]:W1110 14:03:31.522000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 3192744726619719037
[rank5]:W1110 14:03:31.522000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391363343766722197
[rank0]:W1110 14:03:31.523000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6056960306392145430
[rank0]:W1110 14:03:31.527000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6056960306392145430
[rank0]:W1110 14:03:31.528000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6056960306392145430
[rank0]:W1110 14:03:31.529000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6056960306392145430
[rank0]:W1110 14:03:31.530000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6056960306392145430
[rank0]:W1110 14:03:31.531000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6056960306392145430
[rank0]:W1110 14:03:31.532000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6056960306392145430
[rank0]:W1110 14:03:31.533000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634553868251696383
[rank0]:W1110 14:03:31.537000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12146358517213821584
[rank3]:W1110 14:03:31.537000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34206 hash value: 9901997056244844973
[rank4]:W1110 14:03:31.537000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30552 hash value: 3780521203149604297
[rank5]:W1110 14:03:31.537000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37057 hash value: 7222167552598130298
[rank6]:W1110 14:03:31.537000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35330 hash value: 13195989775167500427
[rank7]:W1110 14:03:31.537000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33942 hash value: 7173949115332510184
[rank1]:W1110 14:03:31.537000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36828 hash value: 8147415514246336617
[rank0]:W1110 14:03:31.538000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12146358517213821584
[rank2]:W1110 14:03:31.537000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37143 hash value: 4617574634389415828
[rank0]:W1110 14:03:31.541000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12146358517213821584
[rank0]:W1110 14:03:31.542000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12146358517213821584
[rank0]:W1110 14:03:31.543000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12146358517213821584
[rank0]:W1110 14:03:31.544000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12146358517213821584
[rank0]:W1110 14:03:31.545000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12146358517213821584
[rank0]:W1110 14:03:31.546000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12146358517213821584
[rank0]:W1110 14:03:31.547000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35229 hash value: 8930848891412409551
[rank4]:W1110 14:03:31.551000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891809526
[rank5]:W1110 14:03:31.551000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:03:31.551000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank2]:W1110 14:03:31.551000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811488333850520
[rank1]:W1110 14:03:31.551000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank3]:W1110 14:03:31.551000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 13800512212344086518
[rank7]:W1110 14:03:31.551000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank0]:W1110 14:03:31.552000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37143 hash value: 14859517187427668385
[rank0]:W1110 14:03:31.557000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37143 hash value: 14859517187427668385
[rank0]:W1110 14:03:31.558000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37143 hash value: 14859517187427668385
[rank0]:W1110 14:03:31.560000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37143 hash value: 14859517187427668385
[rank0]:W1110 14:03:31.562000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37143 hash value: 14859517187427668385
[rank0]:W1110 14:03:31.564000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37143 hash value: 14859517187427668385
[rank0]:W1110 14:03:31.565000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37143 hash value: 14859517187427668385
[rank0]:W1110 14:03:31.567000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37143 hash value: 14859517187427668385
[rank0]:W1110 14:03:31.568000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:03:31.572000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5661879677963056418
[rank2]:W1110 14:03:31.572000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811488333850520
[rank1]:W1110 14:03:31.572000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank4]:W1110 14:03:31.572000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891809526
[rank7]:W1110 14:03:31.572000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank5]:W1110 14:03:31.572000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:03:31.572000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475570979164714397
[rank3]:W1110 14:03:31.573000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 13800508094187669914
[rank0]:W1110 14:03:31.574000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5661879677963056418
[rank0]:W1110 14:03:31.577000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5661879677963056418
[rank0]:W1110 14:03:31.578000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5661879677963056418
[rank0]:W1110 14:03:31.579000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5661879677963056418
[rank0]:W1110 14:03:31.580000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5661879677963056418
[rank0]:W1110 14:03:31.581000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5661879677963056418
[rank0]:W1110 14:03:31.582000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5661879677963056418
[rank0]:W1110 14:03:31.583000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:03:31.587000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 593296950299370991
[rank6]:W1110 14:03:31.587000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41667 hash value: 1330973226257868365
[rank3]:W1110 14:03:31.587000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41594 hash value: 8779730226886843120
[rank1]:W1110 14:03:31.587000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38026 hash value: 10294223784411686126
[rank4]:W1110 14:03:31.587000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41629 hash value: 15309593988073760109
[rank5]:W1110 14:03:31.587000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39029 hash value: 2407272062916806576
[rank2]:W1110 14:03:31.588000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39752 hash value: 12929634603675392992
[rank7]:W1110 14:03:31.588000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38658 hash value: 3170691568674405947
[rank0]:W1110 14:03:31.588000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 593296950299370991
[rank0]:W1110 14:03:31.592000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 593296950299370991
[rank0]:W1110 14:03:31.593000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 593296950299370991
[rank0]:W1110 14:03:31.594000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 593296950299370991
[rank0]:W1110 14:03:31.595000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 593296950299370991
[rank0]:W1110 14:03:31.595000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 593296950299370991
[rank0]:W1110 14:03:31.596000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 593296950299370991
[rank0]:W1110 14:03:31.598000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40095 hash value: 16766804586144085621
[rank5]:W1110 14:03:31.602000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank4]:W1110 14:03:31.602000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379136566
[rank3]:W1110 14:03:31.602000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12759702263565105956
[rank2]:W1110 14:03:31.602000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank6]:W1110 14:03:31.602000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391363343754025562
[rank7]:W1110 14:03:31.602000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank1]:W1110 14:03:31.602000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:03:31.603000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41667 hash value: 17822702627395402944
[rank0]:W1110 14:03:31.607000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41667 hash value: 17822702627395402944
[rank0]:W1110 14:03:31.609000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41667 hash value: 17822702627395402944
[rank0]:W1110 14:03:31.611000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41667 hash value: 17822702627395402944
[rank0]:W1110 14:03:31.613000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41667 hash value: 17822702627395402944
[rank0]:W1110 14:03:31.615000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41667 hash value: 17822702627395402944
[rank0]:W1110 14:03:31.617000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41667 hash value: 17822702627395402944
[rank0]:W1110 14:03:31.618000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 41667 hash value: 17822702627395402944
[rank0]:W1110 14:03:31.620000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:03:31.624000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18172503583832137153
[rank3]:W1110 14:03:31.624000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12759702263565105956
[rank4]:W1110 14:03:31.624000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379136566
[rank5]:W1110 14:03:31.624000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank6]:W1110 14:03:31.624000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7824158009281929990
[rank2]:W1110 14:03:31.624000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank1]:W1110 14:03:31.624000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:03:31.624000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:03:31.625000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18172503583832137153
[rank0]:W1110 14:03:31.628000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18172503583832137153
[rank0]:W1110 14:03:31.629000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18172503583832137153
[rank0]:W1110 14:03:31.630000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18172503583832137153
[rank0]:W1110 14:03:31.631000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18172503583832137153
[rank0]:W1110 14:03:31.632000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18172503583832137153
[rank0]:W1110 14:03:31.633000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18172503583832137153
[rank0]:W1110 14:03:31.634000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:03:31.638000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10184427204032626629
[rank3]:W1110 14:03:31.638000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33184 hash value: 1468778403975238146
[rank4]:W1110 14:03:31.638000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35192 hash value: 377378527438990123
[rank6]:W1110 14:03:31.638000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33569 hash value: 1379072343724650896
[rank1]:W1110 14:03:31.638000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36622 hash value: 4328770347211013375
[rank5]:W1110 14:03:31.638000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35464 hash value: 3666236703635868240
[rank2]:W1110 14:03:31.638000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36006 hash value: 10532747982533342994
[rank7]:W1110 14:03:31.638000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35992 hash value: 16867493230408681809
[rank0]:W1110 14:03:31.639000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10184427204032626629
[rank0]:W1110 14:03:31.643000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10184427204032626629
[rank0]:W1110 14:03:31.644000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10184427204032626629
[rank0]:W1110 14:03:31.645000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10184427204032626629
[rank0]:W1110 14:03:31.646000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10184427204032626629
[rank0]:W1110 14:03:31.647000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10184427204032626629
[rank0]:W1110 14:03:31.648000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10184427204032626629
[rank0]:W1110 14:03:31.649000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33734 hash value: 5513166738480391712
[rank4]:W1110 14:03:31.653000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank5]:W1110 14:03:31.653000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank1]:W1110 14:03:31.653000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118207575642852
[rank2]:W1110 14:03:31.653000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:03:31.653000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank6]:W1110 14:03:31.653000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank7]:W1110 14:03:31.653000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077296346813
[rank0]:W1110 14:03:31.653000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36622 hash value: 7964946860246716624
[rank0]:W1110 14:03:31.658000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36622 hash value: 7964946860246716624
[rank0]:W1110 14:03:31.660000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36622 hash value: 7964946860246716624
[rank0]:W1110 14:03:31.661000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36622 hash value: 7964946860246716624
[rank0]:W1110 14:03:31.663000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36622 hash value: 7964946860246716624
[rank0]:W1110 14:03:31.665000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36622 hash value: 7964946860246716624
[rank0]:W1110 14:03:31.667000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36622 hash value: 7964946860246716624
[rank0]:W1110 14:03:31.669000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36622 hash value: 7964946860246716624
[rank0]:W1110 14:03:31.670000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404890844
[rank0]:W1110 14:03:31.674000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13828723152858493136
[rank4]:W1110 14:03:31.674000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank5]:W1110 14:03:31.674000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:03:31.674000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank1]:W1110 14:03:31.674000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118207575638993
[rank2]:W1110 14:03:31.674000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:03:31.674000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077296346813
[rank6]:W1110 14:03:31.674000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank0]:W1110 14:03:31.676000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13828723152858493136
[rank0]:W1110 14:03:31.679000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13828723152858493136
[rank0]:W1110 14:03:31.680000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13828723152858493136
[rank0]:W1110 14:03:31.681000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13828723152858493136
[rank0]:W1110 14:03:31.682000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13828723152858493136
[rank0]:W1110 14:03:31.683000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13828723152858493136
[rank0]:W1110 14:03:31.684000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13828723152858493136
[rank0]:W1110 14:03:31.685000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404890844
[rank0]:W1110 14:03:31.689000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14666226227653765408
[rank4]:W1110 14:03:31.689000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33238 hash value: 9834101928382989368
[rank2]:W1110 14:03:31.689000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35350 hash value: 16896561472962177127
[rank5]:W1110 14:03:31.689000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33119 hash value: 8682346692079320499
[rank6]:W1110 14:03:31.689000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32559 hash value: 5062945054354981368
[rank3]:W1110 14:03:31.689000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32128 hash value: 12168274224951296516
[rank1]:W1110 14:03:31.689000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32029 hash value: 8330205942108016241
[rank7]:W1110 14:03:31.689000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33687 hash value: 12297474246727331279
[rank0]:W1110 14:03:31.690000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14666226227653765408
[rank0]:W1110 14:03:31.693000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14666226227653765408
[rank0]:W1110 14:03:31.694000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14666226227653765408
[rank0]:W1110 14:03:31.695000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14666226227653765408
[rank0]:W1110 14:03:31.696000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14666226227653765408
[rank0]:W1110 14:03:31.697000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14666226227653765408
[rank0]:W1110 14:03:31.698000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14666226227653765408
[rank0]:W1110 14:03:31.699000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32832 hash value: 4951176573319446408
[rank5]:W1110 14:03:31.704000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379136566
[rank4]:W1110 14:03:31.704000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 107298487631453806
[rank7]:W1110 14:03:31.704000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 13855304788125529212
[rank3]:W1110 14:03:31.704000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9707684007058040015
[rank6]:W1110 14:03:31.704000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank1]:W1110 14:03:31.704000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank2]:W1110 14:03:31.704000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank0]:W1110 14:03:31.704000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35350 hash value: 4046929870457998053
[rank0]:W1110 14:03:31.709000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35350 hash value: 4046929870457998053
[rank0]:W1110 14:03:31.711000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35350 hash value: 4046929870457998053
[rank0]:W1110 14:03:31.712000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35350 hash value: 4046929870457998053
[rank0]:W1110 14:03:31.714000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35350 hash value: 4046929870457998053
[rank0]:W1110 14:03:31.716000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35350 hash value: 4046929870457998053
[rank0]:W1110 14:03:31.718000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35350 hash value: 4046929870457998053
[rank0]:W1110 14:03:31.720000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35350 hash value: 4046929870457998053
[rank0]:W1110 14:03:31.721000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8163468435338816897
[rank0]:W1110 14:03:31.725000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank4]:W1110 14:03:31.725000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 107298487631453806
[rank5]:W1110 14:03:31.725000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379136566
[rank1]:W1110 14:03:31.725000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank3]:W1110 14:03:31.725000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9707684007058040015
[rank2]:W1110 14:03:31.725000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank6]:W1110 14:03:31.725000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank7]:W1110 14:03:31.725000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 13855304788125529212
[rank0]:W1110 14:03:31.728000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.731000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.732000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.733000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.734000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.735000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.736000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.737000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8163468435338816897
[rank0]:W1110 14:03:31.741000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank4]:W1110 14:03:31.741000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 31952 hash value: 9963755974817713269
[rank5]:W1110 14:03:31.741000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34069 hash value: 1549433370091640103
[rank6]:W1110 14:03:31.741000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33662 hash value: 14826834127455908054
[rank3]:W1110 14:03:31.741000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33388 hash value: 10612317737786087909
[rank1]:W1110 14:03:31.741000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32075 hash value: 5076093362827977265
[rank2]:W1110 14:03:31.741000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30407 hash value: 12565361454328048739
[rank7]:W1110 14:03:31.741000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30949 hash value: 17465265007038297673
[rank0]:W1110 14:03:31.742000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.745000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.746000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.747000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.748000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.749000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.750000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5240040100559307583
[rank0]:W1110 14:03:31.751000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34237 hash value: 8102086129592121248
[rank6]:W1110 14:03:31.755000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 10080721684387828572
[rank3]:W1110 14:03:31.755000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9799981658433655582
[rank5]:W1110 14:03:31.755000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8627674158715579790
[rank4]:W1110 14:03:31.755000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8425032917572256019
[rank2]:W1110 14:03:31.755000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8617185166860039471
[rank1]:W1110 14:03:31.755000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8617183975846398200
[rank7]:W1110 14:03:31.755000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17424610758715225626
[rank0]:W1110 14:03:31.756000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34237 hash value: 1550161966193369830
[rank0]:W1110 14:03:31.760000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34237 hash value: 1550161966193369830
[rank0]:W1110 14:03:31.762000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34237 hash value: 1550161966193369830
[rank0]:W1110 14:03:31.764000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34237 hash value: 1550161966193369830
[rank0]:W1110 14:03:31.765000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34237 hash value: 1550161966193369830
[rank0]:W1110 14:03:31.767000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34237 hash value: 1550161966193369830
[rank0]:W1110 14:03:31.768000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34237 hash value: 1550161966193369830
[rank0]:W1110 14:03:31.770000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34237 hash value: 1550161966193369830
[rank0]:W1110 14:03:31.771000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6462084732983894855
[rank0]:W1110 14:03:31.775000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17933670653463195177
[rank6]:W1110 14:03:31.775000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 10080721684387828572
[rank3]:W1110 14:03:31.775000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9799981658433655582
[rank4]:W1110 14:03:31.775000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2511766165364530694
[rank2]:W1110 14:03:31.775000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8617183972813603573
[rank5]:W1110 14:03:31.775000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8627674158715579790
[rank7]:W1110 14:03:31.776000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17424610758715225626
[rank1]:W1110 14:03:31.776000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8617183975846398200
[rank0]:W1110 14:03:31.777000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17933670653463195177
[rank0]:W1110 14:03:31.780000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17933670653463195177
[rank0]:W1110 14:03:31.781000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17933670653463195177
[rank0]:W1110 14:03:31.782000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17933670653463195177
[rank0]:W1110 14:03:31.783000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17933670653463195177
[rank0]:W1110 14:03:31.784000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17933670653463195177
[rank0]:W1110 14:03:31.785000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17933670653463195177
[rank0]:W1110 14:03:31.786000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6462084732983894855
[rank0]:W1110 14:03:31.790000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12516976903669173846
[rank4]:W1110 14:03:31.790000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40986 hash value: 16183743733796175728
[rank2]:W1110 14:03:31.790000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35953 hash value: 17525238657535625523
[rank5]:W1110 14:03:31.790000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36645 hash value: 13526447181542399490
[rank6]:W1110 14:03:31.790000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36083 hash value: 2572592413382398392
[rank3]:W1110 14:03:31.790000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36875 hash value: 12945244548728583951
[rank1]:W1110 14:03:31.790000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40823 hash value: 16521255273003882500
[rank7]:W1110 14:03:31.790000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38064 hash value: 7265423022463742057
[rank0]:W1110 14:03:31.791000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12516976903669173846
[rank0]:W1110 14:03:31.794000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12516976903669173846
[rank0]:W1110 14:03:31.795000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12516976903669173846
[rank0]:W1110 14:03:31.796000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12516976903669173846
[rank0]:W1110 14:03:31.797000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12516976903669173846
[rank0]:W1110 14:03:31.798000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12516976903669173846
[rank0]:W1110 14:03:31.799000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 12516976903669173846
[rank0]:W1110 14:03:31.800000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39970 hash value: 15181751803664133745
[rank4]:W1110 14:03:31.804000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank3]:W1110 14:03:31.804000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994949746626
[rank5]:W1110 14:03:31.804000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank1]:W1110 14:03:31.804000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank6]:W1110 14:03:31.804000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank2]:W1110 14:03:31.804000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank7]:W1110 14:03:31.804000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209005957337
[rank0]:W1110 14:03:31.805000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40986 hash value: 5926328461490905582
[rank0]:W1110 14:03:31.810000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40986 hash value: 5926328461490905582
[rank0]:W1110 14:03:31.811000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40986 hash value: 5926328461490905582
[rank0]:W1110 14:03:31.813000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40986 hash value: 5926328461490905582
[rank0]:W1110 14:03:31.815000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40986 hash value: 5926328461490905582
[rank0]:W1110 14:03:31.817000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40986 hash value: 5926328461490905582
[rank0]:W1110 14:03:31.818000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40986 hash value: 5926328461490905582
[rank0]:W1110 14:03:31.820000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40986 hash value: 5926328461490905582
[rank0]:W1110 14:03:31.821000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:03:31.825000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2533157970084646509
[rank4]:W1110 14:03:31.825000 124781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank5]:W1110 14:03:31.825000 124782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9707684007058040015
[rank2]:W1110 14:03:31.826000 124779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank1]:W1110 14:03:31.826000 124778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284946882
[rank6]:W1110 14:03:31.825000 124783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank3]:W1110 14:03:31.826000 124780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994949746626
[rank7]:W1110 14:03:31.826000 124784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209005957337
[rank0]:W1110 14:03:31.827000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2533157970084646509
[rank0]:W1110 14:03:31.830000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2533157970084646509
[rank0]:W1110 14:03:31.831000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2533157970084646509
[rank0]:W1110 14:03:31.832000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2533157970084646509
[rank0]:W1110 14:03:31.833000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2533157970084646509
[rank0]:W1110 14:03:31.834000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2533157970084646509
[rank0]:W1110 14:03:31.835000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2533157970084646509
[rank0]:W1110 14:03:31.836000 124777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:03:31.840000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11891354401556753850
[rank0]:W1110 14:03:31.841000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11891354401556753850
[rank0]:W1110 14:03:31.842000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11891354401556753850
[rank0]:W1110 14:03:31.843000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11891354401556753850
[rank0]:W1110 14:03:31.844000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11891354401556753850
[rank0]:W1110 14:03:31.845000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11891354401556753850
[rank0]:W1110 14:03:31.845000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11891354401556753850
[rank0]:W1110 14:03:31.846000 124777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11891354401556753850
2025-11-10:14:03:39 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
2025-11-10:14:03:39 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_algebra
2025-11-10:14:03:39 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_counting_and_prob
2025-11-10:14:03:39 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_geometry
2025-11-10:14:03:39 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_intermediate_algebra
2025-11-10:14:03:39 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_num_theory
2025-11-10:14:03:39 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_prealgebra
2025-11-10:14:03:40 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_precalc
[rank0]:[W1110 14:03:40.034230297 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
