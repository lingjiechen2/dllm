The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2025-11-10:13:55:54 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:54 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:54 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:54 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:54 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:54 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 128, 'steps': 128, 'block_length': 128, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:13:55:54 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:54 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 128, 'steps': 128, 'block_length': 128, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 13:55:54.418553235 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 13:55:54.418552814 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 128, 'steps': 128, 'block_length': 128, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 13:55:55.773096887 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 128, 'steps': 128, 'block_length': 128, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 13:55:55.865429607 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:13:55:55 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 128, 'steps': 128, 'block_length': 128, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 128, 'steps': 128, 'block_length': 128, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:13:55:55 INFO     [__main__:450] Selected Tasks: ['minerva_math']
[W1110 13:55:55.910565269 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 13:55:55.911986891 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 128, 'steps': 128, 'block_length': 128, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-10:13:55:55 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
[W1110 13:55:55.919619200 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 128, 'steps': 128, 'block_length': 128, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1110 13:55:55.925232355 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:55:55 WARNING  [accelerate.utils.other:441] Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.14it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.13it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.14it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.08it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.13it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.09it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.07it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.05it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.08s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.08s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.09s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.09s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.11s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.08s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.17s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.16s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.16s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.20s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.28s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:04,  1.34s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.16s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.20s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.20s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.22s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:05<00:02,  1.33s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:05<00:02,  1.31s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.19s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.17s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.23s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.21s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.22s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.29s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.31s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.11s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.13s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.14s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.13s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]
[rank4]:[W1110 13:56:07.636396072 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank2]:[W1110 13:56:07.636878229 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank5]:[W1110 13:56:07.637005005 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank7]:[W1110 13:56:07.637010050 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank6]:[W1110 13:56:07.637016319 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank0]:[W1110 13:56:07.637275662 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank3]:[W1110 13:56:07.637526330 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank1]:[W1110 13:56:07.639365899 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:23 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:23 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 369.33it/s]
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:23 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:23 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
100%|██████████| 10/10 [00:00<00:00, 359.59it/s]2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}

2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:23 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:23 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 2...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 364.88it/s]
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:23 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:23 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 3...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 356.62it/s]
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:23 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:23 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 365.08it/s]
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:23 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:23 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:23 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:23 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 5...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 364.10it/s]
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:13:56:24 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:13:56:24 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:13:56:24 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:13:56:24 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 7...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 4...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 366.91it/s]
100%|██████████| 10/10 [00:00<00:00, 356.20it/s]
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 4...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 7...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 5...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 3...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 6...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 0...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 2...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 409.19it/s]100%|██████████| 10/10 [00:00<00:00, 412.44it/s]

100%|██████████| 10/10 [00:00<00:00, 402.96it/s]100%|██████████| 10/10 [00:00<00:00, 394.65it/s]
100%|██████████| 10/10 [00:00<00:00, 392.45it/s]100%|██████████| 10/10 [00:00<00:00, 403.22it/s]


100%|██████████| 10/10 [00:00<00:00, 244.05it/s]
100%|██████████| 10/10 [00:00<00:00, 244.74it/s]
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 7...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 1...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 0...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 2...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 6...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 4...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 3...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 5...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 413.67it/s]
100%|██████████| 10/10 [00:00<00:00, 409.97it/s]100%|██████████| 10/10 [00:00<00:00, 413.58it/s]

100%|██████████| 10/10 [00:00<00:00, 398.85it/s]100%|██████████| 10/10 [00:00<00:00, 402.98it/s]100%|██████████| 10/10 [00:00<00:00, 400.14it/s]


100%|██████████| 10/10 [00:00<00:00, 243.20it/s]
100%|██████████| 10/10 [00:00<00:00, 239.64it/s]
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 2...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 7...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 3...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 6...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 4...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 5...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 1...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 419.89it/s]
100%|██████████| 10/10 [00:00<00:00, 409.36it/s]100%|██████████| 10/10 [00:00<00:00, 412.74it/s]
100%|██████████| 10/10 [00:00<00:00, 414.26it/s]100%|██████████| 10/10 [00:00<00:00, 405.77it/s]
100%|██████████| 10/10 [00:00<00:00, 404.37it/s]


100%|██████████| 10/10 [00:00<00:00, 243.48it/s]
100%|██████████| 10/10 [00:00<00:00, 248.61it/s]
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 4...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 5...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 3...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 6...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 2...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 7...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 0...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 412.18it/s]
100%|██████████| 10/10 [00:00<00:00, 408.47it/s]100%|██████████| 10/10 [00:00<00:00, 406.95it/s]

100%|██████████| 10/10 [00:00<00:00, 411.36it/s]100%|██████████| 10/10 [00:00<00:00, 396.67it/s]100%|██████████| 10/10 [00:00<00:00, 401.36it/s]


100%|██████████| 10/10 [00:00<00:00, 396.89it/s]100%|██████████| 10/10 [00:00<00:00, 393.58it/s]

2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 4...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 5...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 7...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 2...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 6...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 0...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 3...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 413.75it/s]
100%|██████████| 10/10 [00:00<00:00, 410.50it/s]100%|██████████| 10/10 [00:00<00:00, 408.20it/s]
100%|██████████| 10/10 [00:00<00:00, 405.72it/s]100%|██████████| 10/10 [00:00<00:00, 410.39it/s]
100%|██████████| 10/10 [00:00<00:00, 408.08it/s]


100%|██████████| 10/10 [00:00<00:00, 400.13it/s]
100%|██████████| 10/10 [00:00<00:00, 414.08it/s]
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 3...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 6...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 2...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 5...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 7...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 1...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 4...
2025-11-10:13:56:24 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 416.74it/s]100%|██████████| 10/10 [00:00<00:00, 420.97it/s]

100%|██████████| 10/10 [00:00<00:00, 407.11it/s]100%|██████████| 10/10 [00:00<00:00, 417.39it/s]100%|██████████| 10/10 [00:00<00:00, 402.37it/s]100%|██████████| 10/10 [00:00<00:00, 412.68it/s]100%|██████████| 10/10 [00:00<00:00, 416.86it/s]




100%|██████████| 10/10 [00:00<00:00, 391.18it/s]
2025-11-10:13:56:24 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:24 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:24 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:24 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:24 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:24 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:24 INFO     [evaluator:574] Running generate_until requests
2025-11-10:13:56:24 INFO     [evaluator:574] Running generate_until requests
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fa4500ef400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:27 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fa4500ef400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f7f1c1cf0a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:27 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f7f1c1cf0a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fe2f00d3400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:27 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fe2f00d3400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fecb599b490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:13:56:27 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fecb599b490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f44b00fb400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:27 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f44b00fb400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fbccee2f400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:13:56:27 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fbccee2f400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fce2c173400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:13:56:27 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fce2c173400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f102012b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:13:56:27 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f102012b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 676.47 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 665.92 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 706.58 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 670.98 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 661.00 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 669.35 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 656.63 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 683.99 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 673.38 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 694.06 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 642.90 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 663.87 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 633.76 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 652.23 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Generating...:   1%|▏         | 1/70 [00:12<14:03, 12.22s/it]Generating...:   1%|▏         | 1/70 [00:12<14:03, 12.22s/it]Generating...:   1%|▏         | 1/70 [00:12<14:02, 12.20s/it]Generating...:   1%|▏         | 1/70 [00:12<14:03, 12.22s/it]Generating...:   1%|▏         | 1/70 [00:12<14:02, 12.21s/it]Generating...:   1%|▏         | 1/70 [00:12<14:02, 12.21s/it]Generating...:   1%|▏         | 1/70 [00:12<14:01, 12.20s/it]Generating...:   1%|▏         | 1/70 [00:12<14:02, 12.21s/it]Generating...:   3%|▎         | 2/70 [00:25<14:14, 12.57s/it]Generating...:   3%|▎         | 2/70 [00:25<14:14, 12.57s/it]Generating...:   3%|▎         | 2/70 [00:25<14:14, 12.57s/it]Generating...:   3%|▎         | 2/70 [00:25<14:14, 12.56s/it]Generating...:   3%|▎         | 2/70 [00:25<14:14, 12.57s/it]Generating...:   3%|▎         | 2/70 [00:25<14:14, 12.56s/it]Generating...:   3%|▎         | 2/70 [00:25<14:14, 12.56s/it]Generating...:   3%|▎         | 2/70 [00:25<14:14, 12.56s/it]Generating...:   4%|▍         | 3/70 [00:36<13:25, 12.03s/it]Generating...:   4%|▍         | 3/70 [00:36<13:25, 12.03s/it]Generating...:   4%|▍         | 3/70 [00:36<13:25, 12.02s/it]Generating...:   4%|▍         | 3/70 [00:36<13:25, 12.02s/it]Generating...:   4%|▍         | 3/70 [00:36<13:25, 12.03s/it]Generating...:   4%|▍         | 3/70 [00:36<13:25, 12.03s/it]Generating...:   4%|▍         | 3/70 [00:36<13:25, 12.03s/it]Generating...:   4%|▍         | 3/70 [00:36<13:25, 12.03s/it]Generating...:   6%|▌         | 4/70 [00:47<12:51, 11.68s/it]Generating...:   6%|▌         | 4/70 [00:47<12:50, 11.68s/it]Generating...:   6%|▌         | 4/70 [00:47<12:50, 11.68s/it]Generating...:   6%|▌         | 4/70 [00:47<12:50, 11.68s/it]Generating...:   6%|▌         | 4/70 [00:47<12:50, 11.68s/it]Generating...:   6%|▌         | 4/70 [00:47<12:51, 11.68s/it]Generating...:   6%|▌         | 4/70 [00:47<12:50, 11.68s/it]Generating...:   6%|▌         | 4/70 [00:47<12:50, 11.68s/it]Generating...:   7%|▋         | 5/70 [00:59<12:34, 11.61s/it]Generating...:   7%|▋         | 5/70 [00:59<12:34, 11.61s/it]Generating...:   7%|▋         | 5/70 [00:59<12:34, 11.61s/it]Generating...:   7%|▋         | 5/70 [00:59<12:34, 11.61s/it]Generating...:   7%|▋         | 5/70 [00:59<12:34, 11.61s/it]Generating...:   7%|▋         | 5/70 [00:59<12:34, 11.61s/it]Generating...:   7%|▋         | 5/70 [00:59<12:34, 11.61s/it]Generating...:   7%|▋         | 5/70 [00:59<12:34, 11.61s/it]Generating...:   9%|▊         | 6/70 [01:10<12:23, 11.61s/it]Generating...:   9%|▊         | 6/70 [01:10<12:23, 11.61s/it]Generating...:   9%|▊         | 6/70 [01:10<12:23, 11.61s/it]Generating...:   9%|▊         | 6/70 [01:10<12:23, 11.61s/it]Generating...:   9%|▊         | 6/70 [01:10<12:23, 11.61s/it]Generating...:   9%|▊         | 6/70 [01:10<12:23, 11.61s/it]Generating...:   9%|▊         | 6/70 [01:10<12:23, 11.61s/it]Generating...:   9%|▊         | 6/70 [01:10<12:23, 11.61s/it]Generating...:  10%|█         | 7/70 [01:25<13:13, 12.59s/it]Generating...:  10%|█         | 7/70 [01:25<13:13, 12.59s/it]Generating...:  10%|█         | 7/70 [01:25<13:13, 12.59s/it]Generating...:  10%|█         | 7/70 [01:25<13:13, 12.59s/it]Generating...:  10%|█         | 7/70 [01:25<13:13, 12.59s/it]Generating...:  10%|█         | 7/70 [01:25<13:13, 12.59s/it]Generating...:  10%|█         | 7/70 [01:25<13:13, 12.59s/it]Generating...:  10%|█         | 7/70 [01:25<13:13, 12.59s/it]Generating...:  11%|█▏        | 8/70 [01:36<12:35, 12.19s/it]Generating...:  11%|█▏        | 8/70 [01:36<12:35, 12.19s/it]Generating...:  11%|█▏        | 8/70 [01:36<12:35, 12.19s/it]Generating...:  11%|█▏        | 8/70 [01:36<12:35, 12.19s/it]Generating...:  11%|█▏        | 8/70 [01:36<12:35, 12.19s/it]Generating...:  11%|█▏        | 8/70 [01:36<12:35, 12.19s/it]Generating...:  11%|█▏        | 8/70 [01:36<12:35, 12.19s/it]Generating...:  11%|█▏        | 8/70 [01:36<12:35, 12.19s/it]Generating...:  13%|█▎        | 9/70 [01:49<12:38, 12.43s/it]Generating...:  13%|█▎        | 9/70 [01:49<12:38, 12.43s/it]Generating...:  13%|█▎        | 9/70 [01:49<12:38, 12.43s/it]Generating...:  13%|█▎        | 9/70 [01:49<12:38, 12.43s/it]Generating...:  13%|█▎        | 9/70 [01:49<12:38, 12.43s/it]Generating...:  13%|█▎        | 9/70 [01:49<12:38, 12.43s/it]Generating...:  13%|█▎        | 9/70 [01:49<12:38, 12.43s/it]Generating...:  13%|█▎        | 9/70 [01:49<12:38, 12.43s/it]Generating...:  14%|█▍        | 10/70 [02:01<12:09, 12.16s/it]Generating...:  14%|█▍        | 10/70 [02:01<12:09, 12.16s/it]Generating...:  14%|█▍        | 10/70 [02:01<12:09, 12.16s/it]Generating...:  14%|█▍        | 10/70 [02:01<12:09, 12.16s/it]Generating...:  14%|█▍        | 10/70 [02:01<12:09, 12.16s/it]Generating...:  14%|█▍        | 10/70 [02:01<12:09, 12.16s/it]Generating...:  14%|█▍        | 10/70 [02:01<12:09, 12.16s/it]Generating...:  14%|█▍        | 10/70 [02:01<12:09, 12.16s/it]Generating...:  16%|█▌        | 11/70 [02:13<11:58, 12.18s/it]Generating...:  16%|█▌        | 11/70 [02:13<11:58, 12.18s/it]Generating...:  16%|█▌        | 11/70 [02:13<11:58, 12.18s/it]Generating...:  16%|█▌        | 11/70 [02:13<11:58, 12.18s/it]Generating...:  16%|█▌        | 11/70 [02:13<11:58, 12.18s/it]Generating...:  16%|█▌        | 11/70 [02:13<11:58, 12.18s/it]Generating...:  16%|█▌        | 11/70 [02:13<11:58, 12.18s/it]Generating...:  16%|█▌        | 11/70 [02:13<11:58, 12.18s/it]Generating...:  17%|█▋        | 12/70 [02:24<11:34, 11.97s/it]Generating...:  17%|█▋        | 12/70 [02:24<11:34, 11.97s/it]Generating...:  17%|█▋        | 12/70 [02:24<11:34, 11.97s/it]Generating...:  17%|█▋        | 12/70 [02:24<11:34, 11.97s/it]Generating...:  17%|█▋        | 12/70 [02:24<11:34, 11.97s/it]Generating...:  17%|█▋        | 12/70 [02:24<11:34, 11.97s/it]Generating...:  17%|█▋        | 12/70 [02:24<11:34, 11.97s/it]Generating...:  17%|█▋        | 12/70 [02:24<11:34, 11.97s/it]Generating...:  19%|█▊        | 13/70 [02:36<11:14, 11.84s/it]Generating...:  19%|█▊        | 13/70 [02:36<11:14, 11.84s/it]Generating...:  19%|█▊        | 13/70 [02:36<11:14, 11.84s/it]Generating...:  19%|█▊        | 13/70 [02:36<11:14, 11.84s/it]Generating...:  19%|█▊        | 13/70 [02:36<11:14, 11.84s/it]Generating...:  19%|█▊        | 13/70 [02:36<11:14, 11.84s/it]Generating...:  19%|█▊        | 13/70 [02:36<11:14, 11.84s/it]Generating...:  19%|█▊        | 13/70 [02:36<11:14, 11.84s/it]Generating...:  20%|██        | 14/70 [02:48<11:03, 11.85s/it]Generating...:  20%|██        | 14/70 [02:48<11:03, 11.85s/it]Generating...:  20%|██        | 14/70 [02:48<11:03, 11.85s/it]Generating...:  20%|██        | 14/70 [02:48<11:03, 11.85s/it]Generating...:  20%|██        | 14/70 [02:48<11:03, 11.85s/it]Generating...:  20%|██        | 14/70 [02:48<11:03, 11.85s/it]Generating...:  20%|██        | 14/70 [02:48<11:03, 11.85s/it]Generating...:  20%|██        | 14/70 [02:48<11:03, 11.85s/it]Generating...:  21%|██▏       | 15/70 [02:59<10:47, 11.77s/it]Generating...:  21%|██▏       | 15/70 [02:59<10:47, 11.77s/it]Generating...:  21%|██▏       | 15/70 [02:59<10:47, 11.77s/it]Generating...:  21%|██▏       | 15/70 [02:59<10:47, 11.77s/it]Generating...:  21%|██▏       | 15/70 [02:59<10:47, 11.77s/it]Generating...:  21%|██▏       | 15/70 [02:59<10:47, 11.77s/it]Generating...:  21%|██▏       | 15/70 [02:59<10:47, 11.77s/it]Generating...:  21%|██▏       | 15/70 [02:59<10:47, 11.77s/it]Generating...:  23%|██▎       | 16/70 [03:13<11:01, 12.25s/it]Generating...:  23%|██▎       | 16/70 [03:13<11:01, 12.25s/it]Generating...:  23%|██▎       | 16/70 [03:13<11:01, 12.25s/it]Generating...:  23%|██▎       | 16/70 [03:13<11:01, 12.25s/it]Generating...:  23%|██▎       | 16/70 [03:13<11:01, 12.25s/it]Generating...:  23%|██▎       | 16/70 [03:13<11:01, 12.25s/it]Generating...:  23%|██▎       | 16/70 [03:13<11:01, 12.25s/it]Generating...:  23%|██▎       | 16/70 [03:13<11:01, 12.25s/it]Generating...:  24%|██▍       | 17/70 [03:26<10:59, 12.45s/it]Generating...:  24%|██▍       | 17/70 [03:26<10:59, 12.45s/it]Generating...:  24%|██▍       | 17/70 [03:26<10:59, 12.45s/it]Generating...:  24%|██▍       | 17/70 [03:26<10:59, 12.45s/it]Generating...:  24%|██▍       | 17/70 [03:26<10:59, 12.45s/it]Generating...:  24%|██▍       | 17/70 [03:26<10:59, 12.45s/it]Generating...:  24%|██▍       | 17/70 [03:26<10:59, 12.45s/it]Generating...:  24%|██▍       | 17/70 [03:26<10:59, 12.45s/it]Generating...:  26%|██▌       | 18/70 [03:38<10:40, 12.32s/it]Generating...:  26%|██▌       | 18/70 [03:38<10:40, 12.32s/it]Generating...:  26%|██▌       | 18/70 [03:38<10:40, 12.32s/it]Generating...:  26%|██▌       | 18/70 [03:38<10:40, 12.32s/it]Generating...:  26%|██▌       | 18/70 [03:38<10:40, 12.32s/it]Generating...:  26%|██▌       | 18/70 [03:38<10:40, 12.32s/it]Generating...:  26%|██▌       | 18/70 [03:38<10:40, 12.32s/it]Generating...:  26%|██▌       | 18/70 [03:38<10:40, 12.32s/it]Generating...:  27%|██▋       | 19/70 [03:52<11:04, 13.03s/it]Generating...:  27%|██▋       | 19/70 [03:52<11:04, 13.03s/it]Generating...:  27%|██▋       | 19/70 [03:52<11:04, 13.03s/it]Generating...:  27%|██▋       | 19/70 [03:52<11:04, 13.03s/it]Generating...:  27%|██▋       | 19/70 [03:52<11:04, 13.03s/it]Generating...:  27%|██▋       | 19/70 [03:52<11:04, 13.03s/it]Generating...:  27%|██▋       | 19/70 [03:52<11:04, 13.03s/it]Generating...:  27%|██▋       | 19/70 [03:52<11:04, 13.03s/it]Generating...:  29%|██▊       | 20/70 [04:06<10:57, 13.14s/it]Generating...:  29%|██▊       | 20/70 [04:06<10:57, 13.14s/it]Generating...:  29%|██▊       | 20/70 [04:06<10:57, 13.14s/it]Generating...:  29%|██▊       | 20/70 [04:06<10:57, 13.14s/it]Generating...:  29%|██▊       | 20/70 [04:06<10:57, 13.14s/it]Generating...:  29%|██▊       | 20/70 [04:06<10:57, 13.14s/it]Generating...:  29%|██▊       | 20/70 [04:06<10:57, 13.14s/it]Generating...:  29%|██▊       | 20/70 [04:06<10:57, 13.14s/it]Generating...:  30%|███       | 21/70 [04:20<11:05, 13.57s/it]Generating...:  30%|███       | 21/70 [04:20<11:05, 13.57s/it]Generating...:  30%|███       | 21/70 [04:20<11:05, 13.57s/it]Generating...:  30%|███       | 21/70 [04:20<11:05, 13.57s/it]Generating...:  30%|███       | 21/70 [04:20<11:05, 13.57s/it]Generating...:  30%|███       | 21/70 [04:20<11:05, 13.57s/it]Generating...:  30%|███       | 21/70 [04:20<11:05, 13.57s/it]Generating...:  30%|███       | 21/70 [04:20<11:05, 13.57s/it]Generating...:  31%|███▏      | 22/70 [04:37<11:35, 14.48s/it]Generating...:  31%|███▏      | 22/70 [04:37<11:35, 14.48s/it]Generating...:  31%|███▏      | 22/70 [04:37<11:35, 14.48s/it]Generating...:  31%|███▏      | 22/70 [04:37<11:35, 14.48s/it]Generating...:  31%|███▏      | 22/70 [04:37<11:35, 14.48s/it]Generating...:  31%|███▏      | 22/70 [04:37<11:35, 14.48s/it]Generating...:  31%|███▏      | 22/70 [04:37<11:35, 14.48s/it]Generating...:  31%|███▏      | 22/70 [04:37<11:35, 14.48s/it]Generating...:  33%|███▎      | 23/70 [04:51<11:22, 14.52s/it]Generating...:  33%|███▎      | 23/70 [04:51<11:22, 14.52s/it]Generating...:  33%|███▎      | 23/70 [04:51<11:22, 14.52s/it]Generating...:  33%|███▎      | 23/70 [04:51<11:22, 14.52s/it]Generating...:  33%|███▎      | 23/70 [04:51<11:22, 14.52s/it]Generating...:  33%|███▎      | 23/70 [04:51<11:22, 14.52s/it]Generating...:  33%|███▎      | 23/70 [04:51<11:22, 14.52s/it]Generating...:  33%|███▎      | 23/70 [04:51<11:22, 14.52s/it]Generating...:  34%|███▍      | 24/70 [05:05<10:50, 14.14s/it]Generating...:  34%|███▍      | 24/70 [05:05<10:50, 14.14s/it]Generating...:  34%|███▍      | 24/70 [05:05<10:50, 14.14s/it]Generating...:  34%|███▍      | 24/70 [05:05<10:50, 14.14s/it]Generating...:  34%|███▍      | 24/70 [05:05<10:50, 14.14s/it]Generating...:  34%|███▍      | 24/70 [05:05<10:50, 14.14s/it]Generating...:  34%|███▍      | 24/70 [05:05<10:50, 14.14s/it]Generating...:  34%|███▍      | 24/70 [05:05<10:50, 14.14s/it]Generating...:  36%|███▌      | 25/70 [05:18<10:21, 13.80s/it]Generating...:  36%|███▌      | 25/70 [05:18<10:21, 13.80s/it]Generating...:  36%|███▌      | 25/70 [05:18<10:21, 13.80s/it]Generating...:  36%|███▌      | 25/70 [05:18<10:21, 13.80s/it]Generating...:  36%|███▌      | 25/70 [05:18<10:21, 13.80s/it]Generating...:  36%|███▌      | 25/70 [05:18<10:21, 13.80s/it]Generating...:  36%|███▌      | 25/70 [05:18<10:21, 13.80s/it]Generating...:  36%|███▌      | 25/70 [05:18<10:21, 13.80s/it]Generating...:  37%|███▋      | 26/70 [05:31<09:59, 13.62s/it]Generating...:  37%|███▋      | 26/70 [05:31<09:59, 13.62s/it]Generating...:  37%|███▋      | 26/70 [05:31<09:59, 13.62s/it]Generating...:  37%|███▋      | 26/70 [05:31<09:59, 13.62s/it]Generating...:  37%|███▋      | 26/70 [05:31<09:59, 13.62s/it]Generating...:  37%|███▋      | 26/70 [05:31<09:59, 13.62s/it]Generating...:  37%|███▋      | 26/70 [05:31<09:59, 13.62s/it]Generating...:  37%|███▋      | 26/70 [05:31<09:59, 13.62s/it]Generating...:  39%|███▊      | 27/70 [05:43<09:29, 13.25s/it]Generating...:  39%|███▊      | 27/70 [05:43<09:29, 13.25s/it]Generating...:  39%|███▊      | 27/70 [05:43<09:29, 13.25s/it]Generating...:  39%|███▊      | 27/70 [05:43<09:29, 13.25s/it]Generating...:  39%|███▊      | 27/70 [05:43<09:29, 13.25s/it]Generating...:  39%|███▊      | 27/70 [05:43<09:29, 13.25s/it]Generating...:  39%|███▊      | 27/70 [05:43<09:29, 13.25s/it]Generating...:  39%|███▊      | 27/70 [05:43<09:29, 13.25s/it]Generating...:  40%|████      | 28/70 [05:57<09:20, 13.34s/it]Generating...:  40%|████      | 28/70 [05:57<09:20, 13.34s/it]Generating...:  40%|████      | 28/70 [05:57<09:20, 13.34s/it]Generating...:  40%|████      | 28/70 [05:57<09:20, 13.34s/it]Generating...:  40%|████      | 28/70 [05:57<09:20, 13.34s/it]Generating...:  40%|████      | 28/70 [05:57<09:20, 13.34s/it]Generating...:  40%|████      | 28/70 [05:57<09:20, 13.34s/it]Generating...:  40%|████      | 28/70 [05:57<09:20, 13.34s/it]Generating...:  41%|████▏     | 29/70 [06:10<09:03, 13.26s/it]Generating...:  41%|████▏     | 29/70 [06:10<09:03, 13.26s/it]Generating...:  41%|████▏     | 29/70 [06:10<09:03, 13.26s/it]Generating...:  41%|████▏     | 29/70 [06:10<09:03, 13.26s/it]Generating...:  41%|████▏     | 29/70 [06:10<09:03, 13.26s/it]Generating...:  41%|████▏     | 29/70 [06:10<09:03, 13.26s/it]Generating...:  41%|████▏     | 29/70 [06:10<09:03, 13.26s/it]Generating...:  41%|████▏     | 29/70 [06:10<09:03, 13.26s/it]Generating...:  43%|████▎     | 30/70 [06:23<08:50, 13.25s/it]Generating...:  43%|████▎     | 30/70 [06:23<08:50, 13.25s/it]Generating...:  43%|████▎     | 30/70 [06:23<08:50, 13.25s/it]Generating...:  43%|████▎     | 30/70 [06:23<08:50, 13.25s/it]Generating...:  43%|████▎     | 30/70 [06:23<08:50, 13.25s/it]Generating...:  43%|████▎     | 30/70 [06:23<08:50, 13.25s/it]Generating...:  43%|████▎     | 30/70 [06:23<08:50, 13.25s/it]Generating...:  43%|████▎     | 30/70 [06:23<08:50, 13.25s/it]Generating...:  44%|████▍     | 31/70 [06:36<08:26, 12.99s/it]Generating...:  44%|████▍     | 31/70 [06:36<08:26, 12.99s/it]Generating...:  44%|████▍     | 31/70 [06:36<08:26, 12.99s/it]Generating...:  44%|████▍     | 31/70 [06:36<08:26, 12.99s/it]Generating...:  44%|████▍     | 31/70 [06:36<08:26, 12.99s/it]Generating...:  44%|████▍     | 31/70 [06:36<08:26, 12.99s/it]Generating...:  44%|████▍     | 31/70 [06:36<08:26, 12.99s/it]Generating...:  44%|████▍     | 31/70 [06:36<08:26, 12.99s/it]Generating...:  46%|████▌     | 32/70 [06:47<07:57, 12.57s/it]Generating...:  46%|████▌     | 32/70 [06:47<07:57, 12.57s/it]Generating...:  46%|████▌     | 32/70 [06:47<07:57, 12.57s/it]Generating...:  46%|████▌     | 32/70 [06:47<07:57, 12.57s/it]Generating...:  46%|████▌     | 32/70 [06:47<07:57, 12.57s/it]Generating...:  46%|████▌     | 32/70 [06:47<07:57, 12.57s/it]Generating...:  46%|████▌     | 32/70 [06:47<07:57, 12.57s/it]Generating...:  46%|████▌     | 32/70 [06:47<07:57, 12.57s/it]Generating...:  47%|████▋     | 33/70 [07:09<09:29, 15.40s/it]Generating...:  47%|████▋     | 33/70 [07:09<09:29, 15.40s/it]Generating...:  47%|████▋     | 33/70 [07:09<09:29, 15.40s/it]Generating...:  47%|████▋     | 33/70 [07:09<09:29, 15.40s/it]Generating...:  47%|████▋     | 33/70 [07:09<09:29, 15.40s/it]Generating...:  47%|████▋     | 33/70 [07:09<09:29, 15.40s/it]Generating...:  47%|████▋     | 33/70 [07:09<09:29, 15.40s/it]Generating...:  47%|████▋     | 33/70 [07:09<09:29, 15.40s/it]Generating...:  49%|████▊     | 34/70 [07:22<08:41, 14.49s/it]Generating...:  49%|████▊     | 34/70 [07:22<08:41, 14.49s/it]Generating...:  49%|████▊     | 34/70 [07:22<08:41, 14.49s/it]Generating...:  49%|████▊     | 34/70 [07:22<08:41, 14.49s/it]Generating...:  49%|████▊     | 34/70 [07:22<08:41, 14.49s/it]Generating...:  49%|████▊     | 34/70 [07:22<08:41, 14.49s/it]Generating...:  49%|████▊     | 34/70 [07:22<08:41, 14.49s/it]Generating...:  49%|████▊     | 34/70 [07:22<08:41, 14.49s/it]Generating...:  50%|█████     | 35/70 [07:33<07:57, 13.64s/it]Generating...:  50%|█████     | 35/70 [07:33<07:57, 13.64s/it]Generating...:  50%|█████     | 35/70 [07:33<07:57, 13.64s/it]Generating...:  50%|█████     | 35/70 [07:33<07:57, 13.64s/it]Generating...:  50%|█████     | 35/70 [07:33<07:57, 13.64s/it]Generating...:  50%|█████     | 35/70 [07:33<07:57, 13.64s/it]Generating...:  50%|█████     | 35/70 [07:33<07:57, 13.64s/it]Generating...:  50%|█████     | 35/70 [07:33<07:57, 13.64s/it]Generating...:  51%|█████▏    | 36/70 [07:45<07:23, 13.04s/it]Generating...:  51%|█████▏    | 36/70 [07:45<07:23, 13.04s/it]Generating...:  51%|█████▏    | 36/70 [07:45<07:23, 13.04s/it]Generating...:  51%|█████▏    | 36/70 [07:45<07:23, 13.04s/it]Generating...:  51%|█████▏    | 36/70 [07:45<07:23, 13.04s/it]Generating...:  51%|█████▏    | 36/70 [07:45<07:23, 13.04s/it]Generating...:  51%|█████▏    | 36/70 [07:45<07:23, 13.04s/it]Generating...:  51%|█████▏    | 36/70 [07:45<07:23, 13.04s/it]Generating...:  53%|█████▎    | 37/70 [07:57<07:03, 12.83s/it]Generating...:  53%|█████▎    | 37/70 [07:57<07:03, 12.83s/it]Generating...:  53%|█████▎    | 37/70 [07:57<07:03, 12.83s/it]Generating...:  53%|█████▎    | 37/70 [07:57<07:03, 12.83s/it]Generating...:  53%|█████▎    | 37/70 [07:57<07:03, 12.83s/it]Generating...:  53%|█████▎    | 37/70 [07:57<07:03, 12.83s/it]Generating...:  53%|█████▎    | 37/70 [07:57<07:03, 12.83s/it]Generating...:  53%|█████▎    | 37/70 [07:57<07:03, 12.83s/it]Generating...:  54%|█████▍    | 38/70 [08:09<06:41, 12.54s/it]Generating...:  54%|█████▍    | 38/70 [08:09<06:41, 12.54s/it]Generating...:  54%|█████▍    | 38/70 [08:09<06:41, 12.54s/it]Generating...:  54%|█████▍    | 38/70 [08:09<06:41, 12.54s/it]Generating...:  54%|█████▍    | 38/70 [08:09<06:41, 12.54s/it]Generating...:  54%|█████▍    | 38/70 [08:09<06:41, 12.54s/it]Generating...:  54%|█████▍    | 38/70 [08:09<06:41, 12.54s/it]Generating...:  54%|█████▍    | 38/70 [08:09<06:41, 12.54s/it]Generating...:  56%|█████▌    | 39/70 [08:21<06:22, 12.33s/it]Generating...:  56%|█████▌    | 39/70 [08:21<06:22, 12.33s/it]Generating...:  56%|█████▌    | 39/70 [08:21<06:22, 12.33s/it]Generating...:  56%|█████▌    | 39/70 [08:21<06:22, 12.33s/it]Generating...:  56%|█████▌    | 39/70 [08:21<06:22, 12.33s/it]Generating...:  56%|█████▌    | 39/70 [08:21<06:22, 12.33s/it]Generating...:  56%|█████▌    | 39/70 [08:21<06:22, 12.33s/it]Generating...:  56%|█████▌    | 39/70 [08:21<06:22, 12.33s/it]Generating...:  57%|█████▋    | 40/70 [08:32<06:02, 12.07s/it]Generating...:  57%|█████▋    | 40/70 [08:32<06:02, 12.07s/it]Generating...:  57%|█████▋    | 40/70 [08:32<06:02, 12.07s/it]Generating...:  57%|█████▋    | 40/70 [08:32<06:02, 12.07s/it]Generating...:  57%|█████▋    | 40/70 [08:32<06:02, 12.07s/it]Generating...:  57%|█████▋    | 40/70 [08:32<06:02, 12.07s/it]Generating...:  57%|█████▋    | 40/70 [08:32<06:02, 12.07s/it]Generating...:  57%|█████▋    | 40/70 [08:32<06:02, 12.07s/it]Generating...:  59%|█████▊    | 41/70 [08:44<05:43, 11.86s/it]Generating...:  59%|█████▊    | 41/70 [08:44<05:43, 11.86s/it]Generating...:  59%|█████▊    | 41/70 [08:44<05:43, 11.86s/it]Generating...:  59%|█████▊    | 41/70 [08:44<05:43, 11.86s/it]Generating...:  59%|█████▊    | 41/70 [08:44<05:43, 11.86s/it]Generating...:  59%|█████▊    | 41/70 [08:44<05:43, 11.86s/it]Generating...:  59%|█████▊    | 41/70 [08:44<05:43, 11.86s/it]Generating...:  59%|█████▊    | 41/70 [08:44<05:43, 11.86s/it]Generating...:  60%|██████    | 42/70 [08:55<05:29, 11.78s/it]Generating...:  60%|██████    | 42/70 [08:55<05:29, 11.78s/it]Generating...:  60%|██████    | 42/70 [08:55<05:29, 11.78s/it]Generating...:  60%|██████    | 42/70 [08:55<05:29, 11.78s/it]Generating...:  60%|██████    | 42/70 [08:55<05:29, 11.78s/it]Generating...:  60%|██████    | 42/70 [08:55<05:29, 11.78s/it]Generating...:  60%|██████    | 42/70 [08:55<05:29, 11.78s/it]Generating...:  60%|██████    | 42/70 [08:55<05:29, 11.78s/it]Generating...:  61%|██████▏   | 43/70 [09:07<05:14, 11.66s/it]Generating...:  61%|██████▏   | 43/70 [09:07<05:14, 11.66s/it]Generating...:  61%|██████▏   | 43/70 [09:07<05:14, 11.66s/it]Generating...:  61%|██████▏   | 43/70 [09:07<05:14, 11.66s/it]Generating...:  61%|██████▏   | 43/70 [09:07<05:14, 11.66s/it]Generating...:  61%|██████▏   | 43/70 [09:07<05:14, 11.66s/it]Generating...:  61%|██████▏   | 43/70 [09:07<05:14, 11.66s/it]Generating...:  61%|██████▏   | 43/70 [09:07<05:14, 11.66s/it]Generating...:  63%|██████▎   | 44/70 [09:18<05:02, 11.65s/it]Generating...:  63%|██████▎   | 44/70 [09:18<05:02, 11.65s/it]Generating...:  63%|██████▎   | 44/70 [09:18<05:02, 11.65s/it]Generating...:  63%|██████▎   | 44/70 [09:18<05:02, 11.65s/it]Generating...:  63%|██████▎   | 44/70 [09:18<05:02, 11.65s/it]Generating...:  63%|██████▎   | 44/70 [09:18<05:02, 11.65s/it]Generating...:  63%|██████▎   | 44/70 [09:18<05:02, 11.65s/it]Generating...:  63%|██████▎   | 44/70 [09:18<05:02, 11.65s/it]Generating...:  64%|██████▍   | 45/70 [09:30<04:49, 11.60s/it]Generating...:  64%|██████▍   | 45/70 [09:30<04:49, 11.60s/it]Generating...:  64%|██████▍   | 45/70 [09:30<04:49, 11.60s/it]Generating...:  64%|██████▍   | 45/70 [09:30<04:49, 11.60s/it]Generating...:  64%|██████▍   | 45/70 [09:30<04:49, 11.60s/it]Generating...:  64%|██████▍   | 45/70 [09:30<04:49, 11.60s/it]Generating...:  64%|██████▍   | 45/70 [09:30<04:49, 11.60s/it]Generating...:  64%|██████▍   | 45/70 [09:30<04:49, 11.60s/it]Generating...:  66%|██████▌   | 46/70 [09:42<04:42, 11.79s/it]Generating...:  66%|██████▌   | 46/70 [09:42<04:42, 11.79s/it]Generating...:  66%|██████▌   | 46/70 [09:42<04:42, 11.79s/it]Generating...:  66%|██████▌   | 46/70 [09:42<04:42, 11.79s/it]Generating...:  66%|██████▌   | 46/70 [09:42<04:42, 11.79s/it]Generating...:  66%|██████▌   | 46/70 [09:42<04:42, 11.79s/it]Generating...:  66%|██████▌   | 46/70 [09:42<04:42, 11.79s/it]Generating...:  66%|██████▌   | 46/70 [09:42<04:42, 11.79s/it]Generating...:  67%|██████▋   | 47/70 [09:54<04:29, 11.72s/it]Generating...:  67%|██████▋   | 47/70 [09:54<04:29, 11.72s/it]Generating...:  67%|██████▋   | 47/70 [09:54<04:29, 11.72s/it]Generating...:  67%|██████▋   | 47/70 [09:54<04:29, 11.72s/it]Generating...:  67%|██████▋   | 47/70 [09:54<04:29, 11.72s/it]Generating...:  67%|██████▋   | 47/70 [09:54<04:29, 11.72s/it]Generating...:  67%|██████▋   | 47/70 [09:54<04:29, 11.72s/it]Generating...:  67%|██████▋   | 47/70 [09:54<04:29, 11.72s/it]Generating...:  69%|██████▊   | 48/70 [10:05<04:18, 11.75s/it]Generating...:  69%|██████▊   | 48/70 [10:05<04:18, 11.75s/it]Generating...:  69%|██████▊   | 48/70 [10:05<04:18, 11.75s/it]Generating...:  69%|██████▊   | 48/70 [10:05<04:18, 11.75s/it]Generating...:  69%|██████▊   | 48/70 [10:05<04:18, 11.75s/it]Generating...:  69%|██████▊   | 48/70 [10:05<04:18, 11.75s/it]Generating...:  69%|██████▊   | 48/70 [10:05<04:18, 11.75s/it]Generating...:  69%|██████▊   | 48/70 [10:05<04:18, 11.75s/it]Generating...:  70%|███████   | 49/70 [10:17<04:06, 11.73s/it]Generating...:  70%|███████   | 49/70 [10:17<04:06, 11.73s/it]Generating...:  70%|███████   | 49/70 [10:17<04:06, 11.73s/it]Generating...:  70%|███████   | 49/70 [10:17<04:06, 11.73s/it]Generating...:  70%|███████   | 49/70 [10:17<04:06, 11.73s/it]Generating...:  70%|███████   | 49/70 [10:17<04:06, 11.73s/it]Generating...:  70%|███████   | 49/70 [10:17<04:06, 11.73s/it]Generating...:  70%|███████   | 49/70 [10:17<04:06, 11.73s/it]Generating...:  71%|███████▏  | 50/70 [10:29<03:52, 11.64s/it]Generating...:  71%|███████▏  | 50/70 [10:29<03:52, 11.64s/it]Generating...:  71%|███████▏  | 50/70 [10:29<03:52, 11.64s/it]Generating...:  71%|███████▏  | 50/70 [10:29<03:52, 11.64s/it]Generating...:  71%|███████▏  | 50/70 [10:29<03:52, 11.64s/it]Generating...:  71%|███████▏  | 50/70 [10:29<03:52, 11.64s/it]Generating...:  71%|███████▏  | 50/70 [10:29<03:52, 11.64s/it]Generating...:  71%|███████▏  | 50/70 [10:29<03:52, 11.64s/it]Generating...:  73%|███████▎  | 51/70 [10:41<03:46, 11.92s/it]Generating...:  73%|███████▎  | 51/70 [10:41<03:46, 11.92s/it]Generating...:  73%|███████▎  | 51/70 [10:41<03:46, 11.92s/it]Generating...:  73%|███████▎  | 51/70 [10:41<03:46, 11.92s/it]Generating...:  73%|███████▎  | 51/70 [10:41<03:46, 11.92s/it]Generating...:  73%|███████▎  | 51/70 [10:41<03:46, 11.92s/it]Generating...:  73%|███████▎  | 51/70 [10:41<03:46, 11.92s/it]Generating...:  73%|███████▎  | 51/70 [10:41<03:46, 11.92s/it]Generating...:  74%|███████▍  | 52/70 [10:53<03:36, 12.05s/it]Generating...:  74%|███████▍  | 52/70 [10:53<03:36, 12.05s/it]Generating...:  74%|███████▍  | 52/70 [10:53<03:36, 12.05s/it]Generating...:  74%|███████▍  | 52/70 [10:53<03:36, 12.05s/it]Generating...:  74%|███████▍  | 52/70 [10:53<03:36, 12.05s/it]Generating...:  74%|███████▍  | 52/70 [10:53<03:36, 12.05s/it]Generating...:  74%|███████▍  | 52/70 [10:53<03:36, 12.05s/it]Generating...:  74%|███████▍  | 52/70 [10:53<03:36, 12.05s/it]Generating...:  76%|███████▌  | 53/70 [11:12<03:58, 14.02s/it]Generating...:  76%|███████▌  | 53/70 [11:12<03:58, 14.02s/it]Generating...:  76%|███████▌  | 53/70 [11:12<03:58, 14.02s/it]Generating...:  76%|███████▌  | 53/70 [11:12<03:58, 14.02s/it]Generating...:  76%|███████▌  | 53/70 [11:12<03:58, 14.02s/it]Generating...:  76%|███████▌  | 53/70 [11:12<03:58, 14.02s/it]Generating...:  76%|███████▌  | 53/70 [11:12<03:58, 14.02s/it]Generating...:  76%|███████▌  | 53/70 [11:12<03:58, 14.02s/it]Generating...:  77%|███████▋  | 54/70 [11:25<03:41, 13.83s/it]Generating...:  77%|███████▋  | 54/70 [11:25<03:41, 13.83s/it]Generating...:  77%|███████▋  | 54/70 [11:25<03:41, 13.83s/it]Generating...:  77%|███████▋  | 54/70 [11:25<03:41, 13.83s/it]Generating...:  77%|███████▋  | 54/70 [11:25<03:41, 13.83s/it]Generating...:  77%|███████▋  | 54/70 [11:25<03:41, 13.83s/it]Generating...:  77%|███████▋  | 54/70 [11:25<03:41, 13.83s/it]Generating...:  77%|███████▋  | 54/70 [11:25<03:41, 13.83s/it]Generating...:  79%|███████▊  | 55/70 [11:37<03:16, 13.09s/it]Generating...:  79%|███████▊  | 55/70 [11:37<03:16, 13.09s/it]Generating...:  79%|███████▊  | 55/70 [11:37<03:16, 13.09s/it]Generating...:  79%|███████▊  | 55/70 [11:37<03:16, 13.09s/it]Generating...:  79%|███████▊  | 55/70 [11:37<03:16, 13.09s/it]Generating...:  79%|███████▊  | 55/70 [11:37<03:16, 13.09s/it]Generating...:  79%|███████▊  | 55/70 [11:37<03:16, 13.09s/it]Generating...:  79%|███████▊  | 55/70 [11:37<03:16, 13.09s/it]Generating...:  80%|████████  | 56/70 [11:49<02:58, 12.78s/it]Generating...:  80%|████████  | 56/70 [11:49<02:58, 12.78s/it]Generating...:  80%|████████  | 56/70 [11:49<02:58, 12.78s/it]Generating...:  80%|████████  | 56/70 [11:49<02:58, 12.78s/it]Generating...:  80%|████████  | 56/70 [11:49<02:58, 12.78s/it]Generating...:  80%|████████  | 56/70 [11:49<02:58, 12.78s/it]Generating...:  80%|████████  | 56/70 [11:49<02:58, 12.78s/it]Generating...:  80%|████████  | 56/70 [11:49<02:58, 12.78s/it]Generating...:  81%|████████▏ | 57/70 [12:01<02:42, 12.53s/it]Generating...:  81%|████████▏ | 57/70 [12:01<02:42, 12.53s/it]Generating...:  81%|████████▏ | 57/70 [12:01<02:42, 12.53s/it]Generating...:  81%|████████▏ | 57/70 [12:01<02:42, 12.53s/it]Generating...:  81%|████████▏ | 57/70 [12:01<02:42, 12.53s/it]Generating...:  81%|████████▏ | 57/70 [12:01<02:42, 12.53s/it]Generating...:  81%|████████▏ | 57/70 [12:01<02:42, 12.53s/it]Generating...:  81%|████████▏ | 57/70 [12:01<02:42, 12.53s/it]Generating...:  83%|████████▎ | 58/70 [12:13<02:27, 12.33s/it]Generating...:  83%|████████▎ | 58/70 [12:13<02:27, 12.33s/it]Generating...:  83%|████████▎ | 58/70 [12:13<02:27, 12.33s/it]Generating...:  83%|████████▎ | 58/70 [12:13<02:27, 12.33s/it]Generating...:  83%|████████▎ | 58/70 [12:13<02:27, 12.33s/it]Generating...:  83%|████████▎ | 58/70 [12:13<02:27, 12.33s/it]Generating...:  83%|████████▎ | 58/70 [12:13<02:27, 12.33s/it]Generating...:  83%|████████▎ | 58/70 [12:13<02:27, 12.33s/it]Generating...:  84%|████████▍ | 59/70 [12:25<02:15, 12.34s/it]Generating...:  84%|████████▍ | 59/70 [12:25<02:15, 12.34s/it]Generating...:  84%|████████▍ | 59/70 [12:25<02:15, 12.34s/it]Generating...:  84%|████████▍ | 59/70 [12:25<02:15, 12.34s/it]Generating...:  84%|████████▍ | 59/70 [12:25<02:15, 12.34s/it]Generating...:  84%|████████▍ | 59/70 [12:25<02:15, 12.34s/it]Generating...:  84%|████████▍ | 59/70 [12:25<02:15, 12.34s/it]Generating...:  84%|████████▍ | 59/70 [12:25<02:15, 12.34s/it]Generating...:  86%|████████▌ | 60/70 [12:37<02:02, 12.23s/it]Generating...:  86%|████████▌ | 60/70 [12:37<02:02, 12.23s/it]Generating...:  86%|████████▌ | 60/70 [12:37<02:02, 12.23s/it]Generating...:  86%|████████▌ | 60/70 [12:37<02:02, 12.23s/it]Generating...:  86%|████████▌ | 60/70 [12:37<02:02, 12.23s/it]Generating...:  86%|████████▌ | 60/70 [12:37<02:02, 12.23s/it]Generating...:  86%|████████▌ | 60/70 [12:37<02:02, 12.23s/it]Generating...:  86%|████████▌ | 60/70 [12:37<02:02, 12.23s/it]Generating...:  87%|████████▋ | 61/70 [12:50<01:52, 12.49s/it]Generating...:  87%|████████▋ | 61/70 [12:50<01:52, 12.49s/it]Generating...:  87%|████████▋ | 61/70 [12:50<01:52, 12.49s/it]Generating...:  87%|████████▋ | 61/70 [12:50<01:52, 12.49s/it]Generating...:  87%|████████▋ | 61/70 [12:50<01:52, 12.49s/it]Generating...:  87%|████████▋ | 61/70 [12:50<01:52, 12.49s/it]Generating...:  87%|████████▋ | 61/70 [12:50<01:52, 12.49s/it]Generating...:  87%|████████▋ | 61/70 [12:50<01:52, 12.49s/it]Generating...:  89%|████████▊ | 62/70 [13:02<01:38, 12.28s/it]Generating...:  89%|████████▊ | 62/70 [13:02<01:38, 12.28s/it]Generating...:  89%|████████▊ | 62/70 [13:02<01:38, 12.28s/it]Generating...:  89%|████████▊ | 62/70 [13:02<01:38, 12.28s/it]Generating...:  89%|████████▊ | 62/70 [13:02<01:38, 12.28s/it]Generating...:  89%|████████▊ | 62/70 [13:02<01:38, 12.28s/it]Generating...:  89%|████████▊ | 62/70 [13:02<01:38, 12.28s/it]Generating...:  89%|████████▊ | 62/70 [13:02<01:38, 12.28s/it]Generating...:  90%|█████████ | 63/70 [13:20<01:37, 13.88s/it]Generating...:  90%|█████████ | 63/70 [13:20<01:37, 13.88s/it]Generating...:  90%|█████████ | 63/70 [13:20<01:37, 13.88s/it]Generating...:  90%|█████████ | 63/70 [13:20<01:37, 13.88s/it]Generating...:  90%|█████████ | 63/70 [13:20<01:37, 13.88s/it]Generating...:  90%|█████████ | 63/70 [13:20<01:37, 13.88s/it]Generating...:  90%|█████████ | 63/70 [13:20<01:37, 13.88s/it]Generating...:  90%|█████████ | 63/70 [13:20<01:37, 13.88s/it]Generating...:  91%|█████████▏| 64/70 [13:32<01:19, 13.31s/it]Generating...:  91%|█████████▏| 64/70 [13:32<01:19, 13.31s/it]Generating...:  91%|█████████▏| 64/70 [13:32<01:19, 13.31s/it]Generating...:  91%|█████████▏| 64/70 [13:32<01:19, 13.31s/it]Generating...:  91%|█████████▏| 64/70 [13:31<01:19, 13.31s/it]Generating...:  91%|█████████▏| 64/70 [13:31<01:19, 13.31s/it]Generating...:  91%|█████████▏| 64/70 [13:31<01:19, 13.31s/it]Generating...:  91%|█████████▏| 64/70 [13:31<01:19, 13.31s/it]Generating...:  93%|█████████▎| 65/70 [13:43<01:04, 12.86s/it]Generating...:  93%|█████████▎| 65/70 [13:43<01:04, 12.86s/it]Generating...:  93%|█████████▎| 65/70 [13:43<01:04, 12.86s/it]Generating...:  93%|█████████▎| 65/70 [13:43<01:04, 12.86s/it]Generating...:  93%|█████████▎| 65/70 [13:43<01:04, 12.86s/it]Generating...:  93%|█████████▎| 65/70 [13:43<01:04, 12.86s/it]Generating...:  93%|█████████▎| 65/70 [13:43<01:04, 12.86s/it]Generating...:  93%|█████████▎| 65/70 [13:43<01:04, 12.86s/it]Generating...:  94%|█████████▍| 66/70 [13:55<00:49, 12.48s/it]Generating...:  94%|█████████▍| 66/70 [13:55<00:49, 12.48s/it]Generating...:  94%|█████████▍| 66/70 [13:55<00:49, 12.48s/it]Generating...:  94%|█████████▍| 66/70 [13:55<00:49, 12.48s/it]Generating...:  94%|█████████▍| 66/70 [13:55<00:49, 12.48s/it]Generating...:  94%|█████████▍| 66/70 [13:55<00:49, 12.48s/it]Generating...:  94%|█████████▍| 66/70 [13:55<00:49, 12.48s/it]Generating...:  94%|█████████▍| 66/70 [13:55<00:49, 12.48s/it]Generating...:  96%|█████████▌| 67/70 [14:07<00:37, 12.42s/it]Generating...:  96%|█████████▌| 67/70 [14:07<00:37, 12.42s/it]Generating...:  96%|█████████▌| 67/70 [14:07<00:37, 12.42s/it]Generating...:  96%|█████████▌| 67/70 [14:07<00:37, 12.42s/it]Generating...:  96%|█████████▌| 67/70 [14:07<00:37, 12.42s/it]Generating...:  96%|█████████▌| 67/70 [14:07<00:37, 12.42s/it]Generating...:  96%|█████████▌| 67/70 [14:07<00:37, 12.42s/it]Generating...:  96%|█████████▌| 67/70 [14:07<00:37, 12.42s/it]Generating...:  97%|█████████▋| 68/70 [14:20<00:25, 12.59s/it]Generating...:  97%|█████████▋| 68/70 [14:20<00:25, 12.59s/it]Generating...:  97%|█████████▋| 68/70 [14:20<00:25, 12.59s/it]Generating...:  97%|█████████▋| 68/70 [14:20<00:25, 12.59s/it]Generating...:  97%|█████████▋| 68/70 [14:20<00:25, 12.59s/it]Generating...:  97%|█████████▋| 68/70 [14:20<00:25, 12.59s/it]Generating...:  97%|█████████▋| 68/70 [14:20<00:25, 12.59s/it]Generating...:  97%|█████████▋| 68/70 [14:20<00:25, 12.59s/it]Generating...:  99%|█████████▊| 69/70 [14:32<00:12, 12.32s/it]Generating...:  99%|█████████▊| 69/70 [14:32<00:12, 12.32s/it]Generating...:  99%|█████████▊| 69/70 [14:32<00:12, 12.32s/it]Generating...:  99%|█████████▊| 69/70 [14:32<00:12, 12.32s/it]Generating...:  99%|█████████▊| 69/70 [14:32<00:12, 12.32s/it]Generating...:  99%|█████████▊| 69/70 [14:32<00:12, 12.32s/it]Generating...:  99%|█████████▊| 69/70 [14:32<00:12, 12.32s/it]Generating...:  99%|█████████▊| 69/70 [14:32<00:12, 12.32s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.33s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.33s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.33s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.33s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.33s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.33s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.33s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.33s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.64s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.64s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.64s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.64s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.64s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.64s/it]Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.64s/it]
Generating...: 100%|██████████| 70/70 [14:44<00:00, 12.64s/it]






[rank6]:W1110 14:11:14.253000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35181 hash value: 15550409356180813590
[rank2]:W1110 14:11:14.279000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34204 hash value: 8991817713922125662
[rank3]:W1110 14:11:14.285000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32656 hash value: 9738472113944845771
[rank1]:W1110 14:11:14.409000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32035 hash value: 12563910630289274150
[rank0]:W1110 14:11:14.498000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32052 hash value: 17943963696560334058
[rank7]:W1110 14:11:14.526000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 31924 hash value: 6580935905411829579
[rank4]:W1110 14:11:14.529000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34179 hash value: 11007133171494074380
[rank5]:W1110 14:11:14.634000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30979 hash value: 16735389522356568463
[rank0]:W1110 14:11:14.812000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35181 hash value: 12821498788729884252
[rank0]:W1110 14:11:14.814000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35181 hash value: 12821498788729884252
[rank0]:W1110 14:11:14.816000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35181 hash value: 12821498788729884252
[rank0]:W1110 14:11:14.818000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35181 hash value: 12821498788729884252
[rank1]:W1110 14:11:14.819000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16860987475405442556
[rank7]:W1110 14:11:14.819000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994577223373
[rank4]:W1110 14:11:14.819000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5859782613744783699
[rank5]:W1110 14:11:14.819000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12325176233415328270
[rank3]:W1110 14:11:14.819000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 15208313123359193069
[rank6]:W1110 14:11:14.819000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank2]:W1110 14:11:14.819000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank0]:W1110 14:11:14.820000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35181 hash value: 12821498788729884252
[rank0]:W1110 14:11:14.824000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35181 hash value: 12821498788729884252
[rank0]:W1110 14:11:14.826000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35181 hash value: 12821498788729884252
[rank0]:W1110 14:11:14.828000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35181 hash value: 12821498788729884252
[rank0]:W1110 14:11:14.829000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5098525478896684932
[rank0]:W1110 14:11:14.833000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13972737031406052820
[rank1]:W1110 14:11:14.833000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5476425603508604284
[rank7]:W1110 14:11:14.833000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994577223373
[rank3]:W1110 14:11:14.833000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 15208313123359193069
[rank0]:W1110 14:11:14.834000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13972737031406052820
[rank2]:W1110 14:11:14.833000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank5]:W1110 14:11:14.833000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12325176233415328270
[rank4]:W1110 14:11:14.833000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5859782613744783699
[rank6]:W1110 14:11:14.833000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank0]:W1110 14:11:14.836000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13972737031406052820
[rank0]:W1110 14:11:14.838000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13972737031406052820
[rank0]:W1110 14:11:14.839000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13972737031406052820
[rank0]:W1110 14:11:14.840000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13972737031406052820
[rank0]:W1110 14:11:14.841000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13972737031406052820
[rank0]:W1110 14:11:14.842000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 13972737031406052820
[rank0]:W1110 14:11:14.843000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5098525478896684932
[rank0]:W1110 14:11:14.847000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6031744289036192947
[rank1]:W1110 14:11:14.847000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38982 hash value: 2211236581511443106
[rank3]:W1110 14:11:14.847000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36158 hash value: 3064700348022851306
[rank7]:W1110 14:11:14.847000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35944 hash value: 4420179809523548056
[rank6]:W1110 14:11:14.847000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37168 hash value: 9440104335200030425
[rank4]:W1110 14:11:14.847000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32414 hash value: 6204707656441558080
[rank2]:W1110 14:11:14.847000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39297 hash value: 6516823403199283208
[rank5]:W1110 14:11:14.847000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39261 hash value: 12026335215537060220
[rank0]:W1110 14:11:14.848000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6031744289036192947
[rank0]:W1110 14:11:14.851000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6031744289036192947
[rank0]:W1110 14:11:14.852000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6031744289036192947
[rank0]:W1110 14:11:14.853000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6031744289036192947
[rank0]:W1110 14:11:14.854000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6031744289036192947
[rank0]:W1110 14:11:14.855000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6031744289036192947
[rank0]:W1110 14:11:14.856000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6031744289036192947
[rank0]:W1110 14:11:14.857000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37423 hash value: 10167308007247121262
[rank1]:W1110 14:11:14.861000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank3]:W1110 14:11:14.861000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 107298487388868077
[rank4]:W1110 14:11:14.861000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 1973457475026731593
[rank7]:W1110 14:11:14.861000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank5]:W1110 14:11:14.861000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank2]:W1110 14:11:14.861000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16860987534581191490
[rank6]:W1110 14:11:14.861000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12826790799051813943
[rank0]:W1110 14:11:14.861000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39297 hash value: 8724561534356335526
[rank0]:W1110 14:11:14.866000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39297 hash value: 8724561534356335526
[rank0]:W1110 14:11:14.868000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39297 hash value: 8724561534356335526
[rank0]:W1110 14:11:14.869000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39297 hash value: 8724561534356335526
[rank0]:W1110 14:11:14.871000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39297 hash value: 8724561534356335526
[rank0]:W1110 14:11:14.873000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39297 hash value: 8724561534356335526
[rank0]:W1110 14:11:14.875000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39297 hash value: 8724561534356335526
[rank0]:W1110 14:11:14.877000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 39297 hash value: 8724561534356335526
[rank0]:W1110 14:11:14.878000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:11:14.882000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18034065021873897012
[rank1]:W1110 14:11:14.882000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank3]:W1110 14:11:14.882000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 107298487388868077
[rank2]:W1110 14:11:14.882000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16860987534581191490
[rank4]:W1110 14:11:14.882000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 1973457475026731593
[rank6]:W1110 14:11:14.882000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12826790799051813943
[rank5]:W1110 14:11:14.882000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891809526
[rank7]:W1110 14:11:14.882000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:11:14.884000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18034065021873897012
[rank0]:W1110 14:11:14.887000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18034065021873897012
[rank0]:W1110 14:11:14.888000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18034065021873897012
[rank0]:W1110 14:11:14.889000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18034065021873897012
[rank0]:W1110 14:11:14.890000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18034065021873897012
[rank0]:W1110 14:11:14.891000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18034065021873897012
[rank0]:W1110 14:11:14.892000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 18034065021873897012
[rank0]:W1110 14:11:14.893000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:11:14.897000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7121786739065923328
[rank2]:W1110 14:11:14.897000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41572 hash value: 6277455022246345798
[rank1]:W1110 14:11:14.897000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39869 hash value: 13705443684881167683
[rank3]:W1110 14:11:14.897000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 43493 hash value: 84702009684431161
[rank7]:W1110 14:11:14.897000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40728 hash value: 2909006333299266678
[rank5]:W1110 14:11:14.897000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41014 hash value: 17528190025118968937
[rank6]:W1110 14:11:14.897000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 43666 hash value: 17407690344241118586
[rank4]:W1110 14:11:14.897000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 43539 hash value: 1665610639894698909
[rank0]:W1110 14:11:14.898000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7121786739065923328
[rank0]:W1110 14:11:14.901000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7121786739065923328
[rank0]:W1110 14:11:14.902000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7121786739065923328
[rank0]:W1110 14:11:14.903000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7121786739065923328
[rank0]:W1110 14:11:14.904000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7121786739065923328
[rank0]:W1110 14:11:14.905000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7121786739065923328
[rank0]:W1110 14:11:14.907000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 7121786739065923328
[rank0]:W1110 14:11:14.908000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 42197 hash value: 15437461376855662596
[rank1]:W1110 14:11:14.912000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank7]:W1110 14:11:14.912000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:11:14.912000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 10978510516749605773
[rank3]:W1110 14:11:14.912000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12826317197473525732
[rank2]:W1110 14:11:14.912000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank4]:W1110 14:11:14.912000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank5]:W1110 14:11:14.912000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank0]:W1110 14:11:14.912000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43666 hash value: 11023853550392341664
[rank0]:W1110 14:11:14.917000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43666 hash value: 11023853550392341664
[rank0]:W1110 14:11:14.919000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43666 hash value: 11023853550392341664
[rank0]:W1110 14:11:14.921000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43666 hash value: 11023853550392341664
[rank0]:W1110 14:11:14.923000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43666 hash value: 11023853550392341664
[rank0]:W1110 14:11:14.924000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43666 hash value: 11023853550392341664
[rank0]:W1110 14:11:14.926000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43666 hash value: 11023853550392341664
[rank0]:W1110 14:11:14.928000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 43666 hash value: 11023853550392341664
[rank0]:W1110 14:11:14.929000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank0]:W1110 14:11:14.933000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6009993627732198251
[rank1]:W1110 14:11:14.933000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank3]:W1110 14:11:14.933000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12826317197473525732
[rank7]:W1110 14:11:14.933000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:11:14.933000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8222296791873114534
[rank2]:W1110 14:11:14.933000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank4]:W1110 14:11:14.933000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank5]:W1110 14:11:14.933000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank0]:W1110 14:11:14.935000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6009993627732198251
[rank0]:W1110 14:11:14.938000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6009993627732198251
[rank0]:W1110 14:11:14.939000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6009993627732198251
[rank0]:W1110 14:11:14.940000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6009993627732198251
[rank0]:W1110 14:11:14.941000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6009993627732198251
[rank0]:W1110 14:11:14.942000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6009993627732198251
[rank0]:W1110 14:11:14.943000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6009993627732198251
[rank0]:W1110 14:11:14.944000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank0]:W1110 14:11:14.948000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11786356041834111771
[rank1]:W1110 14:11:14.948000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38116 hash value: 16108775464719112635
[rank3]:W1110 14:11:14.948000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34948 hash value: 8852215461374366017
[rank4]:W1110 14:11:14.948000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36858 hash value: 6658997724876053315
[rank2]:W1110 14:11:14.948000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37487 hash value: 9043894836083348350
[rank6]:W1110 14:11:14.948000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35139 hash value: 15114650173064149914
[rank7]:W1110 14:11:14.948000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37432 hash value: 557708143248667530
[rank5]:W1110 14:11:14.948000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36829 hash value: 5534262824253044860
[rank0]:W1110 14:11:14.949000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11786356041834111771
[rank0]:W1110 14:11:14.952000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11786356041834111771
[rank0]:W1110 14:11:14.953000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11786356041834111771
[rank0]:W1110 14:11:14.954000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11786356041834111771
[rank0]:W1110 14:11:14.955000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11786356041834111771
[rank0]:W1110 14:11:14.956000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11786356041834111771
[rank0]:W1110 14:11:14.957000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 11786356041834111771
[rank0]:W1110 14:11:14.958000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35305 hash value: 4004378433072804974
[rank1]:W1110 14:11:14.962000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 1973457474976079291
[rank5]:W1110 14:11:14.962000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank4]:W1110 14:11:14.962000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank2]:W1110 14:11:14.962000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 107298487631453806
[rank3]:W1110 14:11:14.962000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634552621021451245
[rank6]:W1110 14:11:14.962000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank7]:W1110 14:11:14.962000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811490035374021
[rank0]:W1110 14:11:14.963000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38116 hash value: 8006646140139715331
[rank0]:W1110 14:11:14.967000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38116 hash value: 8006646140139715331
[rank0]:W1110 14:11:14.969000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38116 hash value: 8006646140139715331
[rank0]:W1110 14:11:14.971000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38116 hash value: 8006646140139715331
[rank0]:W1110 14:11:14.972000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38116 hash value: 8006646140139715331
[rank0]:W1110 14:11:14.974000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38116 hash value: 8006646140139715331
[rank0]:W1110 14:11:14.976000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38116 hash value: 8006646140139715331
[rank0]:W1110 14:11:14.978000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 38116 hash value: 8006646140139715331
[rank0]:W1110 14:11:14.980000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404890844
[rank1]:W1110 14:11:14.984000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118207575638993
[rank0]:W1110 14:11:14.984000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4965242583996219754
[rank2]:W1110 14:11:14.984000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 107298487631453806
[rank3]:W1110 14:11:14.984000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634552621021451245
[rank4]:W1110 14:11:14.984000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank5]:W1110 14:11:14.984000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:11:14.984000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811490035374021
[rank6]:W1110 14:11:14.984000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank0]:W1110 14:11:14.986000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4965242583996219754
[rank0]:W1110 14:11:14.989000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4965242583996219754
[rank0]:W1110 14:11:14.990000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4965242583996219754
[rank0]:W1110 14:11:14.990000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4965242583996219754
[rank0]:W1110 14:11:14.991000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4965242583996219754
[rank0]:W1110 14:11:14.992000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4965242583996219754
[rank0]:W1110 14:11:14.993000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4965242583996219754
[rank0]:W1110 14:11:14.994000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404890844
[rank0]:W1110 14:11:14.998000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6437473199723606264
[rank1]:W1110 14:11:14.998000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33987 hash value: 3617597873318245990
[rank3]:W1110 14:11:14.998000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33784 hash value: 15204348699339733052
[rank2]:W1110 14:11:14.998000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37207 hash value: 6851976375232578861
[rank6]:W1110 14:11:14.998000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34132 hash value: 7625075772799058101
[rank4]:W1110 14:11:14.998000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35241 hash value: 18170704641679593775
[rank7]:W1110 14:11:14.998000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35490 hash value: 2881288083217956737
[rank5]:W1110 14:11:14.998000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34981 hash value: 11765900077259371228
[rank0]:W1110 14:11:14.999000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6437473199723606264
[rank0]:W1110 14:11:15.003000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6437473199723606264
[rank0]:W1110 14:11:15.004000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6437473199723606264
[rank0]:W1110 14:11:15.005000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6437473199723606264
[rank0]:W1110 14:11:15.006000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6437473199723606264
[rank0]:W1110 14:11:15.007000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6437473199723606264
[rank0]:W1110 14:11:15.008000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 6437473199723606264
[rank0]:W1110 14:11:15.009000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34695 hash value: 12973990286833005540
[rank1]:W1110 14:11:15.013000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12759981406545507419
[rank3]:W1110 14:11:15.013000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9707684007058040015
[rank2]:W1110 14:11:15.013000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614562582
[rank4]:W1110 14:11:15.013000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 10201639756674178380
[rank6]:W1110 14:11:15.013000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank5]:W1110 14:11:15.013000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379136566
[rank7]:W1110 14:11:15.013000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank0]:W1110 14:11:15.013000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37207 hash value: 1921262559928864243
[rank0]:W1110 14:11:15.018000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37207 hash value: 1921262559928864243
[rank0]:W1110 14:11:15.020000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37207 hash value: 1921262559928864243
[rank0]:W1110 14:11:15.022000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37207 hash value: 1921262559928864243
[rank0]:W1110 14:11:15.023000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37207 hash value: 1921262559928864243
[rank0]:W1110 14:11:15.025000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37207 hash value: 1921262559928864243
[rank0]:W1110 14:11:15.027000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37207 hash value: 1921262559928864243
[rank0]:W1110 14:11:15.028000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 37207 hash value: 1921262559928864243
[rank0]:W1110 14:11:15.030000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8163468435022774245
[rank2]:W1110 14:11:15.034000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614562582
[rank1]:W1110 14:11:15.034000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12759981406545507419
[rank7]:W1110 14:11:15.034000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank0]:W1110 14:11:15.033000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16724256119396358857
[rank4]:W1110 14:11:15.034000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9223450630421535561
[rank6]:W1110 14:11:15.034000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank5]:W1110 14:11:15.034000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379136566
[rank3]:W1110 14:11:15.034000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9707684007058040015
[rank0]:W1110 14:11:15.037000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16724256119396358857
[rank0]:W1110 14:11:15.039000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16724256119396358857
[rank0]:W1110 14:11:15.040000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16724256119396358857
[rank0]:W1110 14:11:15.041000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16724256119396358857
[rank0]:W1110 14:11:15.042000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16724256119396358857
[rank0]:W1110 14:11:15.043000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16724256119396358857
[rank0]:W1110 14:11:15.044000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 16724256119396358857
[rank0]:W1110 14:11:15.045000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8163468435022774245
[rank0]:W1110 14:11:15.049000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17577217879359038482
[rank1]:W1110 14:11:15.049000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33990 hash value: 13563152395490742557
[rank2]:W1110 14:11:15.049000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32240 hash value: 12516049060628403472
[rank3]:W1110 14:11:15.049000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35438 hash value: 482686446829855460
[rank7]:W1110 14:11:15.049000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32892 hash value: 17103037111138159548
[rank4]:W1110 14:11:15.049000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34010 hash value: 7159058119018246868
[rank6]:W1110 14:11:15.049000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35601 hash value: 5692461495400711798
[rank5]:W1110 14:11:15.049000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35761 hash value: 365440388689982627
[rank0]:W1110 14:11:15.050000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17577217879359038482
[rank0]:W1110 14:11:15.053000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17577217879359038482
[rank0]:W1110 14:11:15.055000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17577217879359038482
[rank0]:W1110 14:11:15.055000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17577217879359038482
[rank0]:W1110 14:11:15.056000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17577217879359038482
[rank0]:W1110 14:11:15.057000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17577217879359038482
[rank0]:W1110 14:11:15.058000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17577217879359038482
[rank0]:W1110 14:11:15.060000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35932 hash value: 3037239579942647649
[rank3]:W1110 14:11:15.065000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9799981658433655582
[rank7]:W1110 14:11:15.065000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6481602575237205167
[rank2]:W1110 14:11:15.065000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811289968875074
[rank1]:W1110 14:11:15.065000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8617183975846398200
[rank5]:W1110 14:11:15.065000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9856018407808497352
[rank6]:W1110 14:11:15.065000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8222296791873114534
[rank4]:W1110 14:11:15.065000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17719595283193545777
[rank0]:W1110 14:11:15.066000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35932 hash value: 10496681259603621533
[rank0]:W1110 14:11:15.070000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35932 hash value: 10496681259603621533
[rank0]:W1110 14:11:15.072000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35932 hash value: 10496681259603621533
[rank0]:W1110 14:11:15.074000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35932 hash value: 10496681259603621533
[rank0]:W1110 14:11:15.076000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35932 hash value: 10496681259603621533
[rank0]:W1110 14:11:15.077000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35932 hash value: 10496681259603621533
[rank0]:W1110 14:11:15.079000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35932 hash value: 10496681259603621533
[rank0]:W1110 14:11:15.081000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35932 hash value: 10496681259603621533
[rank0]:W1110 14:11:15.082000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12782271542579963825
[rank0]:W1110 14:11:15.086000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15711628505244301669
[rank1]:W1110 14:11:15.086000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8617183975846398200
[rank3]:W1110 14:11:15.086000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9799981658433655582
[rank5]:W1110 14:11:15.086000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9856018407808497352
[rank6]:W1110 14:11:15.086000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8222296791873114534
[rank7]:W1110 14:11:15.086000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17424610758715225626
[rank2]:W1110 14:11:15.086000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811289968875074
[rank4]:W1110 14:11:15.086000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 13619188328067639843
[rank0]:W1110 14:11:15.088000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15711628505244301669
[rank0]:W1110 14:11:15.091000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15711628505244301669
[rank0]:W1110 14:11:15.092000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15711628505244301669
[rank0]:W1110 14:11:15.093000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15711628505244301669
[rank0]:W1110 14:11:15.094000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15711628505244301669
[rank0]:W1110 14:11:15.095000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15711628505244301669
[rank0]:W1110 14:11:15.096000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15711628505244301669
[rank0]:W1110 14:11:15.097000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6462082886672662852
[rank0]:W1110 14:11:15.101000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5784420602906195958
[rank7]:W1110 14:11:15.101000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40000 hash value: 14869077934591870552
[rank6]:W1110 14:11:15.101000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37768 hash value: 17397935798995704695
[rank5]:W1110 14:11:15.101000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38392 hash value: 8875999591780876994
[rank1]:W1110 14:11:15.101000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 42838 hash value: 10459908715760245847
[rank3]:W1110 14:11:15.101000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38439 hash value: 2471287125212744858
[rank2]:W1110 14:11:15.101000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37782 hash value: 2903724275518165279
[rank4]:W1110 14:11:15.101000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 42698 hash value: 18137778036227742854
[rank0]:W1110 14:11:15.102000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5784420602906195958
[rank0]:W1110 14:11:15.105000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5784420602906195958
[rank0]:W1110 14:11:15.106000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5784420602906195958
[rank0]:W1110 14:11:15.107000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5784420602906195958
[rank0]:W1110 14:11:15.108000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5784420602906195958
[rank0]:W1110 14:11:15.109000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5784420602906195958
[rank0]:W1110 14:11:15.110000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5784420602906195958
[rank0]:W1110 14:11:15.111000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 41632 hash value: 7688808011048599402
[rank7]:W1110 14:11:15.115000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920318652581060708
[rank3]:W1110 14:11:15.115000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank6]:W1110 14:11:15.115000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6462084732983894855
[rank2]:W1110 14:11:15.115000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank1]:W1110 14:11:15.115000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank4]:W1110 14:11:15.115000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank5]:W1110 14:11:15.115000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:11:15.116000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 42838 hash value: 7936674395090881712
[rank0]:W1110 14:11:15.120000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 42838 hash value: 7936674395090881712
[rank0]:W1110 14:11:15.122000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 42838 hash value: 7936674395090881712
[rank0]:W1110 14:11:15.124000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 42838 hash value: 7936674395090881712
[rank0]:W1110 14:11:15.126000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 42838 hash value: 7936674395090881712
[rank0]:W1110 14:11:15.128000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 42838 hash value: 7936674395090881712
[rank0]:W1110 14:11:15.130000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 42838 hash value: 7936674395090881712
[rank0]:W1110 14:11:15.131000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 42838 hash value: 7936674395090881712
[rank0]:W1110 14:11:15.133000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:11:15.136000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17352316409934406524
[rank2]:W1110 14:11:15.136000 11779 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank7]:W1110 14:11:15.136000 11784 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920318652581060708
[rank1]:W1110 14:11:15.136000 11778 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank3]:W1110 14:11:15.136000 11780 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank6]:W1110 14:11:15.136000 11783 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9799981658433655582
[rank5]:W1110 14:11:15.136000 11782 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank4]:W1110 14:11:15.137000 11781 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank0]:W1110 14:11:15.138000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17352316409934406524
[rank0]:W1110 14:11:15.141000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17352316409934406524
[rank0]:W1110 14:11:15.142000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17352316409934406524
[rank0]:W1110 14:11:15.143000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17352316409934406524
[rank0]:W1110 14:11:15.144000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17352316409934406524
[rank0]:W1110 14:11:15.145000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17352316409934406524
[rank0]:W1110 14:11:15.146000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17352316409934406524
[rank0]:W1110 14:11:15.147000 11777 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:11:15.150000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17289482665219565302
[rank0]:W1110 14:11:15.151000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17289482665219565302
[rank0]:W1110 14:11:15.152000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17289482665219565302
[rank0]:W1110 14:11:15.153000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17289482665219565302
[rank0]:W1110 14:11:15.154000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17289482665219565302
[rank0]:W1110 14:11:15.157000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17289482665219565302
[rank0]:W1110 14:11:15.158000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17289482665219565302
[rank0]:W1110 14:11:15.159000 11777 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17289482665219565302
2025-11-10:14:11:22 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
2025-11-10:14:11:22 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_algebra
2025-11-10:14:11:22 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_counting_and_prob
2025-11-10:14:11:22 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_geometry
2025-11-10:14:11:22 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_intermediate_algebra
2025-11-10:14:11:23 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_num_theory
2025-11-10:14:11:23 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_prealgebra
2025-11-10:14:11:23 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_precalc
[rank0]:[W1110 14:11:24.826200222 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
