The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2025-11-13:03:11:15 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-13:03:11:15 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-13:03:11:15 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-13:03:11:15 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-13:03:11:15 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-13:03:11:15 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-13:03:11:15 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-13:03:11:15 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-13:03:11:15 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-13:03:11:15 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-13:03:11:15 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-13:03:11:15 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-13:03:11:15 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-13:03:11:15 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-13:03:11:15 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
2025-11-13:03:11:15 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 1024, 'steps': 1024, 'block_length': 1024, 'cfg': 0.0,
        'confidence_eos_eot_inf': True}
[W1113 03:11:15.193364927 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1113 03:11:15.193367370 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1113 03:11:15.193367463 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1113 03:11:15.193367057 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-13:03:11:15 WARNING  [accelerate.utils.other:441] Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.19it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.17it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.12it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.11it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:05,  1.31s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:05,  1.36s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:05,  1.36s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:05,  1.35s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:04<00:04,  1.49s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:04<00:04,  1.52s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:04<00:04,  1.54s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:04<00:04,  1.56s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:05<00:02,  1.32s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:05<00:02,  1.35s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:05<00:02,  1.40s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:05<00:02,  1.41s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.21s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.24s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.32s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.05s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.19s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.25s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.25s/it]
[rank3]:[W1113 03:11:26.096274381 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank1]:[W1113 03:11:26.096311311 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank0]:[W1113 03:11:26.096501775 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank2]:[W1113 03:11:26.096630895 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-13:03:11:42 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-13:03:11:42 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 3...
  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 393.62it/s]
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-13:03:11:42 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-13:03:11:42 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 0...
  0%|          | 0/20 [00:00<?, ?it/s]2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-13:03:11:42 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:42 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-13:03:11:42 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-13:03:11:42 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 2...
  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 390.56it/s]
100%|██████████| 20/20 [00:00<00:00, 389.94it/s]
2025-11-13:03:11:43 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:43 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-13:03:11:43 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:43 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-13:03:11:43 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:43 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-13:03:11:43 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:43 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-13:03:11:43 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:43 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-13:03:11:43 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:43 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-13:03:11:43 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-13:03:11:43 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-13:03:11:43 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 1...
  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 393.06it/s]
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 1...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 3...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 2...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 0...
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 416.12it/s]
100%|██████████| 20/20 [00:00<00:00, 413.13it/s]100%|██████████| 20/20 [00:00<00:00, 415.23it/s]

100%|██████████| 20/20 [00:00<00:00, 397.76it/s]
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 1...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 2...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 3...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 0...
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 416.55it/s]
100%|██████████| 20/20 [00:00<00:00, 414.00it/s]
100%|██████████| 20/20 [00:00<00:00, 411.86it/s]
100%|██████████| 20/20 [00:00<00:00, 395.01it/s]
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 2...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 3...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 1...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 0...
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 417.39it/s]
100%|██████████| 20/20 [00:00<00:00, 418.97it/s]
100%|██████████| 20/20 [00:00<00:00, 413.93it/s]
100%|██████████| 20/20 [00:00<00:00, 399.73it/s]
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 2...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 3...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 1...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 0...
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 422.37it/s]
100%|██████████| 20/20 [00:00<00:00, 400.93it/s]
100%|██████████| 20/20 [00:00<00:00, 268.38it/s]100%|██████████| 20/20 [00:00<00:00, 268.90it/s]

2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 1...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 0...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 3...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 2...
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 423.94it/s]
100%|██████████| 20/20 [00:00<00:00, 420.87it/s]
100%|██████████| 20/20 [00:00<00:00, 418.91it/s]
100%|██████████| 20/20 [00:00<00:00, 398.80it/s]
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 3...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 1...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 2...
2025-11-13:03:11:43 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 0...
  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]  0%|          | 0/20 [00:00<?, ?it/s]100%|██████████| 20/20 [00:00<00:00, 422.57it/s]
100%|██████████| 20/20 [00:00<00:00, 422.67it/s]
100%|██████████| 20/20 [00:00<00:00, 414.14it/s]
100%|██████████| 20/20 [00:00<00:00, 403.48it/s]
2025-11-13:03:11:43 INFO     [evaluator:574] Running generate_until requests
2025-11-13:03:11:43 INFO     [evaluator:574] Running generate_until requests
2025-11-13:03:11:43 INFO     [evaluator:574] Running generate_until requests
2025-11-13:03:11:43 INFO     [evaluator:574] Running generate_until requests
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f1d441cb2e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-13:03:11:46 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f1d441cb2e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f441d0e32e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f45165c72e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/140 [00:00<?, ? examples/s]2025-11-13:03:11:46 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f441d0e32e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f143c1572e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-13:03:11:46 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f45165c72e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/140 [00:00<?, ? examples/s]2025-11-13:03:11:46 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f143c1572e0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/140 [00:00<?, ? examples/s]Map:   0%|          | 0/140 [00:00<?, ? examples/s]Map:  55%|█████▌    | 77/140 [00:00<00:00, 752.32 examples/s]Map:  56%|█████▌    | 78/140 [00:00<00:00, 771.99 examples/s]Map:  58%|█████▊    | 81/140 [00:00<00:00, 796.24 examples/s]Map:  56%|█████▌    | 78/140 [00:00<00:00, 762.50 examples/s]Map: 100%|██████████| 140/140 [00:00<00:00, 721.94 examples/s]
Generating...:   0%|          | 0/140 [00:00<?, ?it/s]Map: 100%|██████████| 140/140 [00:00<00:00, 711.49 examples/s]Map: 100%|██████████| 140/140 [00:00<00:00, 704.53 examples/s]

Generating...:   0%|          | 0/140 [00:00<?, ?it/s]Generating...:   0%|          | 0/140 [00:00<?, ?it/s]Map: 100%|██████████| 140/140 [00:00<00:00, 700.41 examples/s]
Generating...:   0%|          | 0/140 [00:00<?, ?it/s]Generating...:   1%|          | 1/140 [02:57<6:50:24, 177.15s/it]Generating...:   1%|          | 1/140 [02:57<6:50:23, 177.15s/it]Generating...:   1%|          | 1/140 [02:57<6:50:23, 177.15s/it]Generating...:   1%|          | 1/140 [02:57<6:50:23, 177.15s/it]Generating...:   1%|▏         | 2/140 [05:54<6:47:43, 177.27s/it]Generating...:   1%|▏         | 2/140 [05:54<6:47:43, 177.27s/it]Generating...:   1%|▏         | 2/140 [05:54<6:47:43, 177.27s/it]Generating...:   1%|▏         | 2/140 [05:54<6:47:43, 177.27s/it]Generating...:   2%|▏         | 3/140 [08:52<6:45:55, 177.78s/it]Generating...:   2%|▏         | 3/140 [08:52<6:45:55, 177.78s/it]Generating...:   2%|▏         | 3/140 [08:52<6:45:55, 177.78s/it]Generating...:   2%|▏         | 3/140 [08:52<6:45:55, 177.78s/it]Generating...:   3%|▎         | 4/140 [12:03<6:54:46, 182.99s/it]Generating...:   3%|▎         | 4/140 [12:03<6:54:46, 182.99s/it]Generating...:   3%|▎         | 4/140 [12:03<6:54:46, 182.99s/it]Generating...:   3%|▎         | 4/140 [12:03<6:54:46, 182.99s/it]Generating...:   4%|▎         | 5/140 [15:00<6:46:50, 180.82s/it]Generating...:   4%|▎         | 5/140 [15:00<6:46:50, 180.82s/it]Generating...:   4%|▎         | 5/140 [15:00<6:46:50, 180.82s/it]Generating...:   4%|▎         | 5/140 [15:00<6:46:50, 180.82s/it]Generating...:   4%|▍         | 6/140 [17:58<6:41:30, 179.78s/it]Generating...:   4%|▍         | 6/140 [17:58<6:41:30, 179.78s/it]Generating...:   4%|▍         | 6/140 [17:58<6:41:30, 179.78s/it]Generating...:   4%|▍         | 6/140 [17:58<6:41:30, 179.78s/it]Generating...:   5%|▌         | 7/140 [20:55<6:36:16, 178.77s/it]Generating...:   5%|▌         | 7/140 [20:55<6:36:16, 178.77s/it]Generating...:   5%|▌         | 7/140 [20:55<6:36:16, 178.77s/it]Generating...:   5%|▌         | 7/140 [20:55<6:36:16, 178.77s/it]Generating...:   6%|▌         | 8/140 [23:52<6:32:07, 178.24s/it]Generating...:   6%|▌         | 8/140 [23:52<6:32:07, 178.24s/it]Generating...:   6%|▌         | 8/140 [23:52<6:32:07, 178.24s/it]Generating...:   6%|▌         | 8/140 [23:52<6:32:07, 178.24s/it]Generating...:   6%|▋         | 9/140 [26:49<6:28:19, 177.86s/it]Generating...:   6%|▋         | 9/140 [26:49<6:28:19, 177.86s/it]Generating...:   6%|▋         | 9/140 [26:49<6:28:19, 177.86s/it]Generating...:   6%|▋         | 9/140 [26:49<6:28:19, 177.86s/it]Generating...:   7%|▋         | 10/140 [29:46<6:24:38, 177.52s/it]Generating...:   7%|▋         | 10/140 [29:46<6:24:38, 177.52s/it]Generating...:   7%|▋         | 10/140 [29:46<6:24:38, 177.52s/it]Generating...:   7%|▋         | 10/140 [29:46<6:24:38, 177.52s/it]Generating...:   8%|▊         | 11/140 [32:43<6:21:39, 177.51s/it]Generating...:   8%|▊         | 11/140 [32:43<6:21:39, 177.51s/it]Generating...:   8%|▊         | 11/140 [32:43<6:21:39, 177.51s/it]Generating...:   8%|▊         | 11/140 [32:43<6:21:39, 177.51s/it]Generating...:   9%|▊         | 12/140 [35:40<6:18:04, 177.22s/it]Generating...:   9%|▊         | 12/140 [35:40<6:18:04, 177.22s/it]Generating...:   9%|▊         | 12/140 [35:40<6:18:04, 177.22s/it]Generating...:   9%|▊         | 12/140 [35:40<6:18:04, 177.22s/it]Generating...:   9%|▉         | 13/140 [39:06<6:33:56, 186.12s/it]Generating...:   9%|▉         | 13/140 [39:06<6:33:56, 186.12s/it]Generating...:   9%|▉         | 13/140 [39:06<6:33:56, 186.12s/it]Generating...:   9%|▉         | 13/140 [39:06<6:33:56, 186.12s/it]Generating...:  10%|█         | 14/140 [42:04<6:25:26, 183.54s/it]Generating...:  10%|█         | 14/140 [42:04<6:25:26, 183.54s/it]Generating...:  10%|█         | 14/140 [42:04<6:25:26, 183.54s/it]Generating...:  10%|█         | 14/140 [42:04<6:25:26, 183.54s/it]Generating...:  11%|█         | 15/140 [45:00<6:17:57, 181.42s/it]Generating...:  11%|█         | 15/140 [45:00<6:17:57, 181.42s/it]Generating...:  11%|█         | 15/140 [45:00<6:17:57, 181.42s/it]Generating...:  11%|█         | 15/140 [45:00<6:17:57, 181.42s/it]Generating...:  11%|█▏        | 16/140 [47:57<6:11:59, 179.99s/it]Generating...:  11%|█▏        | 16/140 [47:57<6:11:59, 179.99s/it]Generating...:  11%|█▏        | 16/140 [47:57<6:11:59, 179.99s/it]Generating...:  11%|█▏        | 16/140 [47:57<6:11:59, 179.99s/it]Generating...:  12%|█▏        | 17/140 [50:54<6:06:58, 179.01s/it]Generating...:  12%|█▏        | 17/140 [50:54<6:06:58, 179.01s/it]Generating...:  12%|█▏        | 17/140 [50:54<6:06:58, 179.01s/it]Generating...:  12%|█▏        | 17/140 [50:54<6:06:58, 179.01s/it]Generating...:  13%|█▎        | 18/140 [54:09<6:13:34, 183.73s/it]Generating...:  13%|█▎        | 18/140 [54:09<6:13:34, 183.73s/it]Generating...:  13%|█▎        | 18/140 [54:09<6:13:34, 183.73s/it]Generating...:  13%|█▎        | 18/140 [54:09<6:13:34, 183.73s/it]Generating...:  14%|█▎        | 19/140 [57:06<6:06:27, 181.72s/it]Generating...:  14%|█▎        | 19/140 [57:06<6:06:27, 181.72s/it]Generating...:  14%|█▎        | 19/140 [57:06<6:06:27, 181.72s/it]Generating...:  14%|█▎        | 19/140 [57:06<6:06:27, 181.72s/it]Generating...:  14%|█▍        | 20/140 [1:00:03<6:00:36, 180.30s/it]Generating...:  14%|█▍        | 20/140 [1:00:03<6:00:36, 180.30s/it]Generating...:  14%|█▍        | 20/140 [1:00:03<6:00:36, 180.30s/it]Generating...:  14%|█▍        | 20/140 [1:00:03<6:00:36, 180.30s/it]Generating...:  15%|█▌        | 21/140 [1:03:06<5:59:39, 181.34s/it]Generating...:  15%|█▌        | 21/140 [1:03:06<5:59:39, 181.34s/it]Generating...:  15%|█▌        | 21/140 [1:03:06<5:59:39, 181.34s/it]Generating...:  15%|█▌        | 21/140 [1:03:06<5:59:39, 181.34s/it]Generating...:  16%|█▌        | 22/140 [1:06:04<5:54:28, 180.24s/it]Generating...:  16%|█▌        | 22/140 [1:06:04<5:54:28, 180.24s/it]Generating...:  16%|█▌        | 22/140 [1:06:04<5:54:28, 180.24s/it]Generating...:  16%|█▌        | 22/140 [1:06:04<5:54:28, 180.24s/it]Generating...:  16%|█▋        | 23/140 [1:09:01<5:49:50, 179.41s/it]Generating...:  16%|█▋        | 23/140 [1:09:01<5:49:50, 179.41s/it]Generating...:  16%|█▋        | 23/140 [1:09:01<5:49:50, 179.41s/it]Generating...:  16%|█▋        | 23/140 [1:09:01<5:49:50, 179.41s/it]Generating...:  17%|█▋        | 24/140 [1:11:59<5:45:55, 178.93s/it]Generating...:  17%|█▋        | 24/140 [1:11:59<5:45:55, 178.93s/it]Generating...:  17%|█▋        | 24/140 [1:11:59<5:45:55, 178.93s/it]Generating...:  17%|█▋        | 24/140 [1:11:59<5:45:55, 178.93s/it]Generating...:  18%|█▊        | 25/140 [1:14:57<5:42:03, 178.47s/it]Generating...:  18%|█▊        | 25/140 [1:14:57<5:42:03, 178.47s/it]Generating...:  18%|█▊        | 25/140 [1:14:57<5:42:03, 178.47s/it]Generating...:  18%|█▊        | 25/140 [1:14:57<5:42:03, 178.47s/it]Generating...:  19%|█▊        | 26/140 [1:17:55<5:38:52, 178.35s/it]Generating...:  19%|█▊        | 26/140 [1:17:55<5:38:52, 178.35s/it]Generating...:  19%|█▊        | 26/140 [1:17:55<5:38:52, 178.35s/it]Generating...:  19%|█▊        | 26/140 [1:17:55<5:38:52, 178.35s/it]Generating...:  19%|█▉        | 27/140 [1:20:52<5:35:03, 177.91s/it]Generating...:  19%|█▉        | 27/140 [1:20:52<5:35:03, 177.91s/it]Generating...:  19%|█▉        | 27/140 [1:20:52<5:35:03, 177.91s/it]Generating...:  19%|█▉        | 27/140 [1:20:52<5:35:03, 177.91s/it]Generating...:  20%|██        | 28/140 [1:23:52<5:33:25, 178.62s/it]Generating...:  20%|██        | 28/140 [1:23:52<5:33:25, 178.62s/it]Generating...:  20%|██        | 28/140 [1:23:52<5:33:25, 178.62s/it]Generating...:  20%|██        | 28/140 [1:23:52<5:33:25, 178.62s/it]Generating...:  21%|██        | 29/140 [1:26:49<5:29:41, 178.21s/it]Generating...:  21%|██        | 29/140 [1:26:49<5:29:41, 178.21s/it]Generating...:  21%|██        | 29/140 [1:26:49<5:29:41, 178.21s/it]Generating...:  21%|██        | 29/140 [1:26:49<5:29:41, 178.21s/it]Generating...:  21%|██▏       | 30/140 [1:29:47<5:26:20, 178.01s/it]Generating...:  21%|██▏       | 30/140 [1:29:47<5:26:20, 178.01s/it]Generating...:  21%|██▏       | 30/140 [1:29:47<5:26:20, 178.01s/it]Generating...:  21%|██▏       | 30/140 [1:29:47<5:26:20, 178.01s/it]Generating...:  22%|██▏       | 31/140 [1:33:02<5:32:43, 183.15s/it]Generating...:  22%|██▏       | 31/140 [1:33:02<5:32:43, 183.15s/it]Generating...:  22%|██▏       | 31/140 [1:33:02<5:32:43, 183.15s/it]Generating...:  22%|██▏       | 31/140 [1:33:02<5:32:43, 183.15s/it]Generating...:  23%|██▎       | 32/140 [1:35:58<5:25:53, 181.05s/it]Generating...:  23%|██▎       | 32/140 [1:35:58<5:25:53, 181.05s/it]Generating...:  23%|██▎       | 32/140 [1:35:58<5:25:53, 181.05s/it]Generating...:  23%|██▎       | 32/140 [1:35:58<5:25:53, 181.05s/it]Generating...:  24%|██▎       | 33/140 [1:39:09<5:28:13, 184.05s/it]Generating...:  24%|██▎       | 33/140 [1:39:09<5:28:13, 184.05s/it]Generating...:  24%|██▎       | 33/140 [1:39:09<5:28:13, 184.05s/it]Generating...:  24%|██▎       | 33/140 [1:39:09<5:28:13, 184.05s/it]Generating...:  24%|██▍       | 34/140 [1:42:20<5:28:56, 186.20s/it]Generating...:  24%|██▍       | 34/140 [1:42:20<5:28:56, 186.20s/it]Generating...:  24%|██▍       | 34/140 [1:42:20<5:28:56, 186.20s/it]Generating...:  24%|██▍       | 34/140 [1:42:20<5:28:56, 186.20s/it]Generating...:  25%|██▌       | 35/140 [1:45:17<5:21:05, 183.48s/it]Generating...:  25%|██▌       | 35/140 [1:45:17<5:21:05, 183.48s/it]Generating...:  25%|██▌       | 35/140 [1:45:17<5:21:05, 183.48s/it]Generating...:  25%|██▌       | 35/140 [1:45:17<5:21:05, 183.48s/it]Generating...:  26%|██▌       | 36/140 [1:48:19<5:16:56, 182.86s/it]Generating...:  26%|██▌       | 36/140 [1:48:19<5:16:56, 182.86s/it]Generating...:  26%|██▌       | 36/140 [1:48:19<5:16:56, 182.86s/it]Generating...:  26%|██▌       | 36/140 [1:48:19<5:16:57, 182.86s/it]Generating...:  26%|██▋       | 37/140 [1:51:44<5:25:34, 189.65s/it]Generating...:  26%|██▋       | 37/140 [1:51:44<5:25:34, 189.65s/it]Generating...:  26%|██▋       | 37/140 [1:51:44<5:25:34, 189.65s/it]Generating...:  26%|██▋       | 37/140 [1:51:44<5:25:34, 189.65s/it]Generating...:  27%|██▋       | 38/140 [1:54:41<5:15:44, 185.73s/it]Generating...:  27%|██▋       | 38/140 [1:54:41<5:15:44, 185.73s/it]Generating...:  27%|██▋       | 38/140 [1:54:41<5:15:44, 185.73s/it]Generating...:  27%|██▋       | 38/140 [1:54:41<5:15:44, 185.73s/it]Generating...:  28%|██▊       | 39/140 [1:57:56<5:17:29, 188.61s/it]Generating...:  28%|██▊       | 39/140 [1:57:56<5:17:29, 188.61s/it]Generating...:  28%|██▊       | 39/140 [1:57:56<5:17:29, 188.61s/it]Generating...:  28%|██▊       | 39/140 [1:57:56<5:17:29, 188.61s/it]Generating...:  29%|██▊       | 40/140 [2:00:54<5:08:51, 185.32s/it]Generating...:  29%|██▊       | 40/140 [2:00:54<5:08:51, 185.32s/it]Generating...:  29%|██▊       | 40/140 [2:00:54<5:08:51, 185.32s/it]Generating...:  29%|██▊       | 40/140 [2:00:54<5:08:51, 185.32s/it]Generating...:  29%|██▉       | 41/140 [2:03:59<5:05:29, 185.14s/it]Generating...:  29%|██▉       | 41/140 [2:03:59<5:05:29, 185.14s/it]Generating...:  29%|██▉       | 41/140 [2:03:59<5:05:29, 185.14s/it]Generating...:  29%|██▉       | 41/140 [2:03:59<5:05:29, 185.14s/it]Generating...:  30%|███       | 42/140 [2:07:24<5:12:12, 191.15s/it]Generating...:  30%|███       | 42/140 [2:07:24<5:12:12, 191.15s/it]Generating...:  30%|███       | 42/140 [2:07:24<5:12:12, 191.15s/it]Generating...:  30%|███       | 42/140 [2:07:24<5:12:12, 191.15s/it]Generating...:  31%|███       | 43/140 [2:10:59<5:20:36, 198.31s/it]Generating...:  31%|███       | 43/140 [2:10:59<5:20:36, 198.31s/it]Generating...:  31%|███       | 43/140 [2:10:59<5:20:36, 198.31s/it]Generating...:  31%|███       | 43/140 [2:10:59<5:20:36, 198.31s/it]Generating...:  31%|███▏      | 44/140 [2:14:05<5:11:28, 194.67s/it]Generating...:  31%|███▏      | 44/140 [2:14:05<5:11:28, 194.67s/it]Generating...:  31%|███▏      | 44/140 [2:14:05<5:11:28, 194.67s/it]Generating...:  31%|███▏      | 44/140 [2:14:05<5:11:28, 194.67s/it]Generating...:  32%|███▏      | 45/140 [2:17:20<5:08:12, 194.66s/it]Generating...:  32%|███▏      | 45/140 [2:17:20<5:08:12, 194.66s/it]Generating...:  32%|███▏      | 45/140 [2:17:20<5:08:12, 194.66s/it]Generating...:  32%|███▏      | 45/140 [2:17:20<5:08:12, 194.66s/it]Generating...:  33%|███▎      | 46/140 [2:20:48<5:11:23, 198.76s/it]Generating...:  33%|███▎      | 46/140 [2:20:48<5:11:23, 198.76s/it]Generating...:  33%|███▎      | 46/140 [2:20:48<5:11:23, 198.76s/it]Generating...:  33%|███▎      | 46/140 [2:20:48<5:11:23, 198.76s/it]Generating...:  34%|███▎      | 47/140 [2:23:52<5:01:25, 194.47s/it]Generating...:  34%|███▎      | 47/140 [2:23:52<5:01:25, 194.47s/it]Generating...:  34%|███▎      | 47/140 [2:23:52<5:01:25, 194.47s/it]Generating...:  34%|███▎      | 47/140 [2:23:52<5:01:25, 194.47s/it]Generating...:  34%|███▍      | 48/140 [2:27:08<4:58:49, 194.88s/it]Generating...:  34%|███▍      | 48/140 [2:27:08<4:58:49, 194.88s/it]Generating...:  34%|███▍      | 48/140 [2:27:08<4:58:49, 194.88s/it]Generating...:  34%|███▍      | 48/140 [2:27:08<4:58:49, 194.88s/it]Generating...:  35%|███▌      | 49/140 [2:30:21<4:54:45, 194.35s/it]Generating...:  35%|███▌      | 49/140 [2:30:21<4:54:45, 194.35s/it]Generating...:  35%|███▌      | 49/140 [2:30:21<4:54:45, 194.35s/it]Generating...:  35%|███▌      | 49/140 [2:30:21<4:54:45, 194.35s/it]Generating...:  36%|███▌      | 50/140 [2:33:33<4:50:07, 193.41s/it]Generating...:  36%|███▌      | 50/140 [2:33:33<4:50:07, 193.41s/it]Generating...:  36%|███▌      | 50/140 [2:33:33<4:50:07, 193.41s/it]Generating...:  36%|███▌      | 50/140 [2:33:33<4:50:07, 193.41s/it]Generating...:  36%|███▋      | 51/140 [2:36:46<4:47:03, 193.53s/it]Generating...:  36%|███▋      | 51/140 [2:36:46<4:47:03, 193.53s/it]Generating...:  36%|███▋      | 51/140 [2:36:46<4:47:03, 193.53s/it]Generating...:  36%|███▋      | 51/140 [2:36:46<4:47:03, 193.53s/it]Generating...:  37%|███▋      | 52/140 [2:39:51<4:39:59, 190.90s/it]Generating...:  37%|███▋      | 52/140 [2:39:51<4:39:59, 190.90s/it]Generating...:  37%|███▋      | 52/140 [2:39:51<4:39:59, 190.90s/it]Generating...:  37%|███▋      | 52/140 [2:39:51<4:39:59, 190.90s/it]Generating...:  38%|███▊      | 53/140 [2:42:57<4:34:35, 189.37s/it]Generating...:  38%|███▊      | 53/140 [2:42:57<4:34:35, 189.37s/it]Generating...:  38%|███▊      | 53/140 [2:42:57<4:34:35, 189.37s/it]Generating...:  38%|███▊      | 53/140 [2:42:57<4:34:35, 189.37s/it]Generating...:  39%|███▊      | 54/140 [2:45:55<4:26:36, 186.01s/it]Generating...:  39%|███▊      | 54/140 [2:45:55<4:26:36, 186.01s/it]Generating...:  39%|███▊      | 54/140 [2:45:55<4:26:36, 186.01s/it]Generating...:  39%|███▊      | 54/140 [2:45:55<4:26:36, 186.01s/it]Generating...:  39%|███▉      | 55/140 [2:48:58<4:22:23, 185.22s/it]Generating...:  39%|███▉      | 55/140 [2:48:58<4:22:23, 185.22s/it]Generating...:  39%|███▉      | 55/140 [2:48:58<4:22:23, 185.22s/it]Generating...:  39%|███▉      | 55/140 [2:48:58<4:22:23, 185.22s/it]Generating...:  40%|████      | 56/140 [2:52:16<4:24:38, 189.04s/it]Generating...:  40%|████      | 56/140 [2:52:16<4:24:38, 189.04s/it]Generating...:  40%|████      | 56/140 [2:52:16<4:24:38, 189.04s/it]Generating...:  40%|████      | 56/140 [2:52:16<4:24:38, 189.04s/it]Generating...:  41%|████      | 57/140 [2:55:31<4:23:46, 190.68s/it]Generating...:  41%|████      | 57/140 [2:55:31<4:23:46, 190.68s/it]Generating...:  41%|████      | 57/140 [2:55:31<4:23:46, 190.68s/it]Generating...:  41%|████      | 57/140 [2:55:31<4:23:46, 190.68s/it]Generating...:  41%|████▏     | 58/140 [2:58:35<4:17:59, 188.78s/it]Generating...:  41%|████▏     | 58/140 [2:58:35<4:17:59, 188.78s/it]Generating...:  41%|████▏     | 58/140 [2:58:35<4:17:59, 188.78s/it]Generating...:  41%|████▏     | 58/140 [2:58:35<4:17:59, 188.78s/it]Generating...:  42%|████▏     | 59/140 [3:01:50<4:17:11, 190.51s/it]Generating...:  42%|████▏     | 59/140 [3:01:50<4:17:11, 190.51s/it]Generating...:  42%|████▏     | 59/140 [3:01:50<4:17:11, 190.51s/it]Generating...:  42%|████▏     | 59/140 [3:01:50<4:17:11, 190.51s/it]Generating...:  43%|████▎     | 60/140 [3:04:53<4:11:17, 188.46s/it]Generating...:  43%|████▎     | 60/140 [3:04:53<4:11:17, 188.46s/it]Generating...:  43%|████▎     | 60/140 [3:04:53<4:11:17, 188.46s/it]Generating...:  43%|████▎     | 60/140 [3:04:53<4:11:17, 188.46s/it]Generating...:  44%|████▎     | 61/140 [3:07:52<4:04:12, 185.48s/it]Generating...:  44%|████▎     | 61/140 [3:07:52<4:04:12, 185.48s/it]Generating...:  44%|████▎     | 61/140 [3:07:52<4:04:12, 185.48s/it]Generating...:  44%|████▎     | 61/140 [3:07:52<4:04:12, 185.48s/it]Generating...:  44%|████▍     | 62/140 [3:10:56<4:00:34, 185.06s/it]Generating...:  44%|████▍     | 62/140 [3:10:56<4:00:34, 185.06s/it]Generating...:  44%|████▍     | 62/140 [3:10:56<4:00:34, 185.06s/it]Generating...:  44%|████▍     | 62/140 [3:10:56<4:00:34, 185.06s/it]Generating...:  45%|████▌     | 63/140 [3:13:54<3:54:39, 182.85s/it]Generating...:  45%|████▌     | 63/140 [3:13:54<3:54:39, 182.85s/it]Generating...:  45%|████▌     | 63/140 [3:13:54<3:54:39, 182.85s/it]Generating...:  45%|████▌     | 63/140 [3:13:54<3:54:39, 182.85s/it]Generating...:  46%|████▌     | 64/140 [3:16:53<3:50:06, 181.67s/it]Generating...:  46%|████▌     | 64/140 [3:16:53<3:50:06, 181.67s/it]Generating...:  46%|████▌     | 64/140 [3:16:53<3:50:06, 181.67s/it]Generating...:  46%|████▌     | 64/140 [3:16:53<3:50:06, 181.67s/it]Generating...:  46%|████▋     | 65/140 [3:21:14<4:16:47, 205.43s/it]Generating...:  46%|████▋     | 65/140 [3:21:14<4:16:47, 205.43s/it]Generating...:  46%|████▋     | 65/140 [3:21:14<4:16:47, 205.43s/it]Generating...:  46%|████▋     | 65/140 [3:21:14<4:16:47, 205.43s/it]Generating...:  47%|████▋     | 66/140 [3:24:10<4:02:33, 196.67s/it]Generating...:  47%|████▋     | 66/140 [3:24:10<4:02:33, 196.67s/it]Generating...:  47%|████▋     | 66/140 [3:24:10<4:02:33, 196.67s/it]Generating...:  47%|████▋     | 66/140 [3:24:10<4:02:33, 196.67s/it]Generating...:  48%|████▊     | 67/140 [3:27:07<3:52:08, 190.80s/it]Generating...:  48%|████▊     | 67/140 [3:27:07<3:52:08, 190.80s/it]Generating...:  48%|████▊     | 67/140 [3:27:07<3:52:08, 190.80s/it]Generating...:  48%|████▊     | 67/140 [3:27:07<3:52:08, 190.80s/it]Generating...:  49%|████▊     | 68/140 [3:30:11<3:46:24, 188.67s/it]Generating...:  49%|████▊     | 68/140 [3:30:11<3:46:24, 188.67s/it]Generating...:  49%|████▊     | 68/140 [3:30:11<3:46:24, 188.67s/it]Generating...:  49%|████▊     | 68/140 [3:30:11<3:46:24, 188.67s/it]Generating...:  49%|████▉     | 69/140 [3:33:07<3:39:00, 185.08s/it]Generating...:  49%|████▉     | 69/140 [3:33:07<3:39:00, 185.08s/it]Generating...:  49%|████▉     | 69/140 [3:33:07<3:39:00, 185.08s/it]Generating...:  49%|████▉     | 69/140 [3:33:07<3:39:00, 185.08s/it]Generating...:  50%|█████     | 70/140 [3:36:05<3:33:22, 182.89s/it]Generating...:  50%|█████     | 70/140 [3:36:05<3:33:22, 182.89s/it]Generating...:  50%|█████     | 70/140 [3:36:05<3:33:22, 182.89s/it]Generating...:  50%|█████     | 70/140 [3:36:05<3:33:22, 182.89s/it]Generating...:  51%|█████     | 71/140 [3:39:04<3:28:48, 181.57s/it]Generating...:  51%|█████     | 71/140 [3:39:04<3:28:48, 181.57s/it]Generating...:  51%|█████     | 71/140 [3:39:04<3:28:48, 181.57s/it]Generating...:  51%|█████     | 71/140 [3:39:04<3:28:48, 181.57s/it]Generating...:  51%|█████▏    | 72/140 [3:42:01<3:24:19, 180.29s/it]Generating...:  51%|█████▏    | 72/140 [3:42:01<3:24:19, 180.29s/it]Generating...:  51%|█████▏    | 72/140 [3:42:01<3:24:19, 180.29s/it]Generating...:  51%|█████▏    | 72/140 [3:42:01<3:24:19, 180.29s/it]Generating...:  52%|█████▏    | 73/140 [3:45:05<3:22:33, 181.40s/it]Generating...:  52%|█████▏    | 73/140 [3:45:05<3:22:33, 181.40s/it]Generating...:  52%|█████▏    | 73/140 [3:45:05<3:22:33, 181.40s/it]Generating...:  52%|█████▏    | 73/140 [3:45:05<3:22:33, 181.40s/it]Generating...:  53%|█████▎    | 74/140 [3:48:06<3:19:19, 181.20s/it]Generating...:  53%|█████▎    | 74/140 [3:48:06<3:19:19, 181.20s/it]Generating...:  53%|█████▎    | 74/140 [3:48:06<3:19:19, 181.20s/it]Generating...:  53%|█████▎    | 74/140 [3:48:06<3:19:19, 181.20s/it]Generating...:  54%|█████▎    | 75/140 [3:51:06<3:15:54, 180.83s/it]Generating...:  54%|█████▎    | 75/140 [3:51:06<3:15:54, 180.83s/it]Generating...:  54%|█████▎    | 75/140 [3:51:06<3:15:54, 180.83s/it]Generating...:  54%|█████▎    | 75/140 [3:51:06<3:15:54, 180.83s/it]Generating...:  54%|█████▍    | 76/140 [3:54:05<3:12:34, 180.54s/it]Generating...:  54%|█████▍    | 76/140 [3:54:05<3:12:34, 180.54s/it]Generating...:  54%|█████▍    | 76/140 [3:54:05<3:12:34, 180.54s/it]Generating...:  54%|█████▍    | 76/140 [3:54:05<3:12:34, 180.54s/it]Generating...:  55%|█████▌    | 77/140 [3:57:03<3:08:44, 179.76s/it]Generating...:  55%|█████▌    | 77/140 [3:57:03<3:08:44, 179.76s/it]Generating...:  55%|█████▌    | 77/140 [3:57:03<3:08:44, 179.76s/it]Generating...:  55%|█████▌    | 77/140 [3:57:03<3:08:44, 179.76s/it]slurmstepd: error: *** JOB 6230807 ON SH-IDCA1404-10-140-54-68 CANCELLED AT 2025-11-13T07:10:23 DUE TO TIME LIMIT ***
W1113 07:10:23.164000 10740 site-packages/torch/distributed/elastic/agent/server/api.py:704] Received Signals.SIGTERM death signal, shutting down workers
W1113 07:10:23.168000 10740 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 10987 closing signal SIGTERM
W1113 07:10:23.171000 10740 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 10988 closing signal SIGTERM
W1113 07:10:23.172000 10740 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 10989 closing signal SIGTERM
W1113 07:10:23.183000 10740 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 10992 closing signal SIGTERM
