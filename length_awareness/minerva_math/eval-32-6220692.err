The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2025-11-10:14:04:44 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:44 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:44 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:44 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:44 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:44 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:44 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:44 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 32, 'steps': 32, 'block_length': 32, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:14:04:44 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:44 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:44 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 32, 'steps': 32, 'block_length': 32, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:14:04:44 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 32, 'steps': 32, 'block_length': 32, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
[W1110 14:04:44.479483554 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 14:04:44.479490538 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 14:04:44.479494212 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:44 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:44 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:44 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:44 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:44 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:44 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:44 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:44 INFO     [__main__:450] Selected Tasks: ['minerva_math']
2025-11-10:14:04:44 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:44 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 32, 'steps': 32, 'block_length': 32, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:14:04:44 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:44 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 32, 'steps': 32, 'block_length': 32, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:14:04:44 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-11-10:14:04:44 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:44 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 32, 'steps': 32, 'block_length': 32, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:14:04:44 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
[W1110 14:04:44.012977480 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:44 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 32, 'steps': 32, 'block_length': 32, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
2025-11-10:14:04:44 INFO     [__main__:450] Selected Tasks: ['minerva_math']
[W1110 14:04:44.014609967 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 14:04:44.017017034 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[W1110 14:04:44.018246386 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:44 INFO     [evaluator:202] Setting random seed to 42 | Setting numpy seed to 42 | Setting torch manual seed to 42 | Setting fewshot manual seed to 42
2025-11-10:14:04:44 INFO     [evaluator:240] Initializing llada model, with arguments: {'pretrained': '/mnt/lustrenew/mllm_aligned/shared/models/huggingface/GSAI-ML/LLaDA-8B-Instruct',
        'is_check_greedy': False, 'mc_num': 1, 'max_new_tokens': 32, 'steps': 32, 'block_length': 32, 'cfg': 0.0, 'confidence_eos_eot_inf':
        True}
[W1110 14:04:44.030763471 Utils.hpp:135] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:04:45 WARNING  [accelerate.utils.other:441] Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.09it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.09it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.08it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.08it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.08it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.08it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.07it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:00<00:04,  1.05it/s]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.07s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.08s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.08s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.08s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.09s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.12s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.11s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:02<00:04,  1.13s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.11s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.16s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.19s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.20s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.21s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:03<00:03,  1.20s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.14s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.14s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.18s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.24s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.24s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.24s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.25s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:04<00:02,  1.23s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.16s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.15s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:05<00:01,  1.20s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.26s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.26s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.26s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.26s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:06<00:01,  1.28s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.06s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.06s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:06<00:00,  1.13s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]

Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.18s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]
Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:07<00:00,  1.17s/it]
[rank5]:[W1110 14:04:56.731539517 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank3]:[W1110 14:04:56.731603626 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank7]:[W1110 14:04:56.731987205 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank6]:[W1110 14:04:56.732026200 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank4]:[W1110 14:04:56.732116681 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank2]:[W1110 14:04:56.732222364 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank0]:[W1110 14:04:56.732541037 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
[rank1]:[W1110 14:04:56.733174644 Utils.hpp:110] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
2025-11-10:14:05:13 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:13 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:13 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:13 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:13 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:13 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:13 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:13 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:13 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:13 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:13 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:13 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:13 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:13 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:13 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:13 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 360.67it/s]
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:14 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:14 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 5...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 367.42it/s]
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:14 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:14 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 2...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 363.62it/s]
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:14 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:14 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:14 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 4...
2025-11-10:14:05:14 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 3...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 361.46it/s]
100%|██████████| 10/10 [00:00<00:00, 362.82it/s]
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:14 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:14 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 7...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 361.56it/s]
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:14 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:14 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:15 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:15 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:15 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:15 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:15 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:15 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:15 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:15 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:15 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:15 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:15 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:15 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:15 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 366.68it/s]
2025-11-10:14:05:17 INFO     [evaluator:305] minerva_math_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:17 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_algebra from 4 to 4
2025-11-10:14:05:17 INFO     [evaluator:305] minerva_math_counting_and_prob: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:17 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_counting_and_prob from 4 to 4
2025-11-10:14:05:17 INFO     [evaluator:305] minerva_math_geometry: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:17 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_geometry from 4 to 4
2025-11-10:14:05:17 INFO     [evaluator:305] minerva_math_intermediate_algebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:17 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_intermediate_algebra from 4 to 4
2025-11-10:14:05:17 INFO     [evaluator:305] minerva_math_num_theory: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:17 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_num_theory from 4 to 4
2025-11-10:14:05:17 INFO     [evaluator:305] minerva_math_prealgebra: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:17 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_prealgebra from 4 to 4
2025-11-10:14:05:17 INFO     [evaluator:305] minerva_math_precalc: Using gen_kwargs: {'until': ['Problem:'], 'do_sample': False, 'temperature': 0.0}
2025-11-10:14:05:17 WARNING  [evaluator:324] Overwriting default num_fewshot of minerva_math_precalc from 4 to 4
2025-11-10:14:05:17 WARNING  [evaluator:480] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_algebra on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 363.31it/s]
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 1...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 0...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 7...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 4...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 3...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 5...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 2...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_counting_and_prob on rank 6...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 413.57it/s]
100%|██████████| 10/10 [00:00<00:00, 403.16it/s]100%|██████████| 10/10 [00:00<00:00, 407.00it/s]

100%|██████████| 10/10 [00:00<00:00, 393.07it/s]100%|██████████| 10/10 [00:00<00:00, 397.94it/s]100%|██████████| 10/10 [00:00<00:00, 395.65it/s]

100%|██████████| 10/10 [00:00<00:00, 387.50it/s]
100%|██████████| 10/10 [00:00<00:00, 385.93it/s]

2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 5...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 3...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 2...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 4...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 6...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 1...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 7...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_geometry on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 411.42it/s]
100%|██████████| 10/10 [00:00<00:00, 407.18it/s]100%|██████████| 10/10 [00:00<00:00, 411.97it/s]

100%|██████████| 10/10 [00:00<00:00, 396.40it/s]100%|██████████| 10/10 [00:00<00:00, 400.64it/s]100%|██████████| 10/10 [00:00<00:00, 398.81it/s]

100%|██████████| 10/10 [00:00<00:00, 384.86it/s]

100%|██████████| 10/10 [00:00<00:00, 387.79it/s]
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 5...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 7...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 6...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 4...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 2...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 1...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 3...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_intermediate_algebra on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 418.30it/s]
100%|██████████| 10/10 [00:00<00:00, 407.46it/s]100%|██████████| 10/10 [00:00<00:00, 411.95it/s]

100%|██████████| 10/10 [00:00<00:00, 402.79it/s]100%|██████████| 10/10 [00:00<00:00, 400.35it/s]100%|██████████| 10/10 [00:00<00:00, 397.56it/s]
100%|██████████| 10/10 [00:00<00:00, 393.17it/s]
100%|██████████| 10/10 [00:00<00:00, 390.64it/s]


2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 5...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 7...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 6...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 4...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 3...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 2...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 0...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_num_theory on rank 1...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 413.46it/s]
100%|██████████| 10/10 [00:00<00:00, 409.51it/s]
100%|██████████| 10/10 [00:00<00:00, 401.65it/s]100%|██████████| 10/10 [00:00<00:00, 406.49it/s]
100%|██████████| 10/10 [00:00<00:00, 397.37it/s]
100%|██████████| 10/10 [00:00<00:00, 394.77it/s]100%|██████████| 10/10 [00:00<00:00, 398.96it/s]100%|██████████| 10/10 [00:00<00:00, 395.71it/s]



2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 5...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 1...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 4...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 3...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 6...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 2...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 7...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_prealgebra on rank 0...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 417.37it/s]
100%|██████████| 10/10 [00:00<00:00, 414.12it/s]
100%|██████████| 10/10 [00:00<00:00, 410.20it/s]100%|██████████| 10/10 [00:00<00:00, 409.64it/s]
100%|██████████| 10/10 [00:00<00:00, 407.06it/s]
100%|██████████| 10/10 [00:00<00:00, 402.95it/s]100%|██████████| 10/10 [00:00<00:00, 415.03it/s]
100%|██████████| 10/10 [00:00<00:00, 393.03it/s]


2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 7...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 6...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 2...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 4...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 5...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 0...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 1...
2025-11-10:14:05:17 INFO     [api.task:434] Building contexts for minerva_math_precalc on rank 3...
  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]  0%|          | 0/10 [00:00<?, ?it/s]100%|██████████| 10/10 [00:00<00:00, 414.60it/s]100%|██████████| 10/10 [00:00<00:00, 417.78it/s]

100%|██████████| 10/10 [00:00<00:00, 408.46it/s]100%|██████████| 10/10 [00:00<00:00, 406.52it/s]100%|██████████| 10/10 [00:00<00:00, 410.60it/s]


100%|██████████| 10/10 [00:00<00:00, 391.54it/s]100%|██████████| 10/10 [00:00<00:00, 395.84it/s]100%|██████████| 10/10 [00:00<00:00, 393.57it/s]


2025-11-10:14:05:17 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:17 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:17 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:17 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:17 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:17 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:17 INFO     [evaluator:574] Running generate_until requests
2025-11-10:14:05:17 INFO     [evaluator:574] Running generate_until requests
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fcbef34f0a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:20 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fcbef34f0a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f06dd5ef490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:20 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f06dd5ef490> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f4c0b23b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:20 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f4c0b23b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f26b1c1b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:14:05:20 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7f26b1c1b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fb8e0187400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:20 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fb8e0187400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fb63884b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:20 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fb63884b400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fd77eb07400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]2025-11-10:14:05:20 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fd77eb07400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fa0f0173400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
2025-11-10:14:05:20 WARNING  [datasets.fingerprint:258] Parameter 'function'=<function LLaDAEvalHarness.generate_until.<locals>._tokenize at 0x7fa0f0173400> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map:   0%|          | 0/70 [00:00<?, ? examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 702.31 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 690.54 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 653.14 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 690.07 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 679.20 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 639.42 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 675.30 examples/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 686.08 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 675.41 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Map: 100%|██████████| 70/70 [00:00<00:00, 687.66 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 693.76 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 696.01 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 675.04 examples/s]
Map: 100%|██████████| 70/70 [00:00<00:00, 681.74 examples/s]Map: 100%|██████████| 70/70 [00:00<00:00, 680.81 examples/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]
Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Generating...:   0%|          | 0/70 [00:00<?, ?it/s]Generating...:   1%|▏         | 1/70 [00:03<03:46,  3.28s/it]Generating...:   1%|▏         | 1/70 [00:03<03:46,  3.29s/it]Generating...:   1%|▏         | 1/70 [00:03<03:47,  3.30s/it]Generating...:   1%|▏         | 1/70 [00:03<03:46,  3.29s/it]Generating...:   1%|▏         | 1/70 [00:03<03:46,  3.29s/it]Generating...:   1%|▏         | 1/70 [00:03<03:46,  3.28s/it]Generating...:   1%|▏         | 1/70 [00:03<03:46,  3.28s/it]Generating...:   1%|▏         | 1/70 [00:03<03:46,  3.28s/it]Generating...:   3%|▎         | 2/70 [00:06<03:30,  3.10s/it]Generating...:   3%|▎         | 2/70 [00:06<03:30,  3.09s/it]Generating...:   3%|▎         | 2/70 [00:06<03:30,  3.09s/it]Generating...:   3%|▎         | 2/70 [00:06<03:30,  3.09s/it]Generating...:   3%|▎         | 2/70 [00:06<03:30,  3.10s/it]Generating...:   3%|▎         | 2/70 [00:06<03:30,  3.10s/it]Generating...:   3%|▎         | 2/70 [00:06<03:30,  3.10s/it]Generating...:   3%|▎         | 2/70 [00:06<03:30,  3.09s/it]Generating...:   4%|▍         | 3/70 [00:08<03:00,  2.69s/it]Generating...:   4%|▍         | 3/70 [00:08<03:00,  2.69s/it]Generating...:   4%|▍         | 3/70 [00:08<03:00,  2.69s/it]Generating...:   4%|▍         | 3/70 [00:08<03:00,  2.69s/it]Generating...:   4%|▍         | 3/70 [00:08<03:00,  2.69s/it]Generating...:   4%|▍         | 3/70 [00:08<03:00,  2.69s/it]Generating...:   4%|▍         | 3/70 [00:08<03:00,  2.69s/it]Generating...:   4%|▍         | 3/70 [00:08<03:00,  2.69s/it]Generating...:   6%|▌         | 4/70 [00:10<02:45,  2.51s/it]Generating...:   6%|▌         | 4/70 [00:10<02:45,  2.51s/it]Generating...:   6%|▌         | 4/70 [00:10<02:45,  2.51s/it]Generating...:   6%|▌         | 4/70 [00:10<02:45,  2.51s/it]Generating...:   6%|▌         | 4/70 [00:10<02:45,  2.51s/it]Generating...:   6%|▌         | 4/70 [00:10<02:45,  2.51s/it]Generating...:   6%|▌         | 4/70 [00:10<02:45,  2.51s/it]Generating...:   6%|▌         | 4/70 [00:10<02:45,  2.51s/it]Generating...:   7%|▋         | 5/70 [00:12<02:36,  2.40s/it]Generating...:   7%|▋         | 5/70 [00:12<02:36,  2.40s/it]Generating...:   7%|▋         | 5/70 [00:12<02:36,  2.40s/it]Generating...:   7%|▋         | 5/70 [00:12<02:36,  2.40s/it]Generating...:   7%|▋         | 5/70 [00:12<02:36,  2.41s/it]Generating...:   7%|▋         | 5/70 [00:12<02:36,  2.40s/it]Generating...:   7%|▋         | 5/70 [00:12<02:36,  2.40s/it]Generating...:   7%|▋         | 5/70 [00:12<02:36,  2.40s/it]Generating...:   9%|▊         | 6/70 [00:15<02:29,  2.34s/it]Generating...:   9%|▊         | 6/70 [00:15<02:29,  2.34s/it]Generating...:   9%|▊         | 6/70 [00:15<02:29,  2.34s/it]Generating...:   9%|▊         | 6/70 [00:15<02:29,  2.34s/it]Generating...:   9%|▊         | 6/70 [00:15<02:29,  2.34s/it]Generating...:   9%|▊         | 6/70 [00:15<02:29,  2.34s/it]Generating...:   9%|▊         | 6/70 [00:15<02:29,  2.34s/it]Generating...:   9%|▊         | 6/70 [00:15<02:29,  2.34s/it]Generating...:  10%|█         | 7/70 [00:18<02:47,  2.66s/it]Generating...:  10%|█         | 7/70 [00:18<02:47,  2.66s/it]Generating...:  10%|█         | 7/70 [00:18<02:47,  2.66s/it]Generating...:  10%|█         | 7/70 [00:18<02:47,  2.66s/it]Generating...:  10%|█         | 7/70 [00:18<02:47,  2.66s/it]Generating...:  10%|█         | 7/70 [00:18<02:47,  2.66s/it]Generating...:  10%|█         | 7/70 [00:18<02:47,  2.66s/it]Generating...:  10%|█         | 7/70 [00:18<02:47,  2.66s/it]Generating...:  11%|█▏        | 8/70 [00:20<02:35,  2.51s/it]Generating...:  11%|█▏        | 8/70 [00:20<02:35,  2.51s/it]Generating...:  11%|█▏        | 8/70 [00:20<02:35,  2.51s/it]Generating...:  11%|█▏        | 8/70 [00:20<02:35,  2.51s/it]Generating...:  11%|█▏        | 8/70 [00:20<02:35,  2.51s/it]Generating...:  11%|█▏        | 8/70 [00:20<02:35,  2.51s/it]Generating...:  11%|█▏        | 8/70 [00:20<02:35,  2.51s/it]Generating...:  11%|█▏        | 8/70 [00:20<02:35,  2.51s/it]Generating...:  13%|█▎        | 9/70 [00:23<02:44,  2.69s/it]Generating...:  13%|█▎        | 9/70 [00:23<02:44,  2.69s/it]Generating...:  13%|█▎        | 9/70 [00:23<02:44,  2.69s/it]Generating...:  13%|█▎        | 9/70 [00:23<02:44,  2.69s/it]Generating...:  13%|█▎        | 9/70 [00:23<02:44,  2.69s/it]Generating...:  13%|█▎        | 9/70 [00:23<02:44,  2.69s/it]Generating...:  13%|█▎        | 9/70 [00:23<02:44,  2.69s/it]Generating...:  13%|█▎        | 9/70 [00:23<02:44,  2.69s/it]Generating...:  14%|█▍        | 10/70 [00:25<02:32,  2.55s/it]Generating...:  14%|█▍        | 10/70 [00:25<02:32,  2.55s/it]Generating...:  14%|█▍        | 10/70 [00:25<02:32,  2.55s/it]Generating...:  14%|█▍        | 10/70 [00:25<02:32,  2.55s/it]Generating...:  14%|█▍        | 10/70 [00:25<02:32,  2.55s/it]Generating...:  14%|█▍        | 10/70 [00:25<02:32,  2.55s/it]Generating...:  14%|█▍        | 10/70 [00:25<02:32,  2.55s/it]Generating...:  14%|█▍        | 10/70 [00:25<02:32,  2.55s/it]Generating...:  16%|█▌        | 11/70 [00:28<02:35,  2.64s/it]Generating...:  16%|█▌        | 11/70 [00:28<02:35,  2.64s/it]Generating...:  16%|█▌        | 11/70 [00:28<02:35,  2.64s/it]Generating...:  16%|█▌        | 11/70 [00:28<02:35,  2.64s/it]Generating...:  16%|█▌        | 11/70 [00:28<02:35,  2.64s/it]Generating...:  16%|█▌        | 11/70 [00:28<02:35,  2.64s/it]Generating...:  16%|█▌        | 11/70 [00:28<02:35,  2.64s/it]Generating...:  16%|█▌        | 11/70 [00:28<02:35,  2.64s/it]Generating...:  17%|█▋        | 12/70 [00:31<02:26,  2.52s/it]Generating...:  17%|█▋        | 12/70 [00:31<02:26,  2.52s/it]Generating...:  17%|█▋        | 12/70 [00:31<02:26,  2.52s/it]Generating...:  17%|█▋        | 12/70 [00:31<02:26,  2.52s/it]Generating...:  17%|█▋        | 12/70 [00:31<02:26,  2.52s/it]Generating...:  17%|█▋        | 12/70 [00:31<02:26,  2.52s/it]Generating...:  17%|█▋        | 12/70 [00:31<02:26,  2.52s/it]Generating...:  17%|█▋        | 12/70 [00:31<02:26,  2.52s/it]Generating...:  19%|█▊        | 13/70 [00:33<02:18,  2.43s/it]Generating...:  19%|█▊        | 13/70 [00:33<02:18,  2.43s/it]Generating...:  19%|█▊        | 13/70 [00:33<02:18,  2.43s/it]Generating...:  19%|█▊        | 13/70 [00:33<02:18,  2.43s/it]Generating...:  19%|█▊        | 13/70 [00:33<02:18,  2.43s/it]Generating...:  19%|█▊        | 13/70 [00:33<02:18,  2.43s/it]Generating...:  19%|█▊        | 13/70 [00:33<02:18,  2.43s/it]Generating...:  19%|█▊        | 13/70 [00:33<02:18,  2.43s/it]Generating...:  20%|██        | 14/70 [00:36<02:21,  2.53s/it]Generating...:  20%|██        | 14/70 [00:36<02:21,  2.53s/it]Generating...:  20%|██        | 14/70 [00:36<02:21,  2.53s/it]Generating...:  20%|██        | 14/70 [00:36<02:21,  2.53s/it]Generating...:  20%|██        | 14/70 [00:36<02:21,  2.53s/it]Generating...:  20%|██        | 14/70 [00:36<02:21,  2.53s/it]Generating...:  20%|██        | 14/70 [00:36<02:21,  2.53s/it]Generating...:  20%|██        | 14/70 [00:36<02:21,  2.53s/it]Generating...:  21%|██▏       | 15/70 [00:38<02:22,  2.59s/it]Generating...:  21%|██▏       | 15/70 [00:38<02:22,  2.59s/it]Generating...:  21%|██▏       | 15/70 [00:38<02:22,  2.59s/it]Generating...:  21%|██▏       | 15/70 [00:38<02:22,  2.59s/it]Generating...:  21%|██▏       | 15/70 [00:38<02:22,  2.59s/it]Generating...:  21%|██▏       | 15/70 [00:38<02:22,  2.59s/it]Generating...:  21%|██▏       | 15/70 [00:38<02:22,  2.59s/it]Generating...:  21%|██▏       | 15/70 [00:38<02:22,  2.59s/it]Generating...:  23%|██▎       | 16/70 [00:41<02:30,  2.79s/it]Generating...:  23%|██▎       | 16/70 [00:42<02:30,  2.79s/it]Generating...:  23%|██▎       | 16/70 [00:42<02:30,  2.79s/it]Generating...:  23%|██▎       | 16/70 [00:42<02:30,  2.79s/it]Generating...:  23%|██▎       | 16/70 [00:41<02:30,  2.79s/it]Generating...:  23%|██▎       | 16/70 [00:41<02:30,  2.79s/it]Generating...:  23%|██▎       | 16/70 [00:41<02:30,  2.79s/it]Generating...:  23%|██▎       | 16/70 [00:42<02:30,  2.79s/it]Generating...:  24%|██▍       | 17/70 [00:45<02:31,  2.86s/it]Generating...:  24%|██▍       | 17/70 [00:45<02:31,  2.86s/it]Generating...:  24%|██▍       | 17/70 [00:45<02:31,  2.86s/it]Generating...:  24%|██▍       | 17/70 [00:45<02:31,  2.86s/it]Generating...:  24%|██▍       | 17/70 [00:45<02:31,  2.86s/it]Generating...:  24%|██▍       | 17/70 [00:45<02:31,  2.86s/it]Generating...:  24%|██▍       | 17/70 [00:45<02:31,  2.86s/it]Generating...:  24%|██▍       | 17/70 [00:45<02:31,  2.86s/it]Generating...:  26%|██▌       | 18/70 [00:47<02:28,  2.85s/it]Generating...:  26%|██▌       | 18/70 [00:47<02:28,  2.85s/it]Generating...:  26%|██▌       | 18/70 [00:47<02:28,  2.85s/it]Generating...:  26%|██▌       | 18/70 [00:47<02:28,  2.85s/it]Generating...:  26%|██▌       | 18/70 [00:47<02:28,  2.85s/it]Generating...:  26%|██▌       | 18/70 [00:47<02:28,  2.85s/it]Generating...:  26%|██▌       | 18/70 [00:47<02:28,  2.85s/it]Generating...:  26%|██▌       | 18/70 [00:47<02:28,  2.85s/it]Generating...:  27%|██▋       | 19/70 [00:51<02:32,  3.00s/it]Generating...:  27%|██▋       | 19/70 [00:51<02:32,  3.00s/it]Generating...:  27%|██▋       | 19/70 [00:51<02:32,  3.00s/it]Generating...:  27%|██▋       | 19/70 [00:51<02:32,  3.00s/it]Generating...:  27%|██▋       | 19/70 [00:51<02:32,  3.00s/it]Generating...:  27%|██▋       | 19/70 [00:51<02:32,  3.00s/it]Generating...:  27%|██▋       | 19/70 [00:51<02:32,  3.00s/it]Generating...:  27%|██▋       | 19/70 [00:51<02:32,  3.00s/it]Generating...:  29%|██▊       | 20/70 [00:54<02:33,  3.07s/it]Generating...:  29%|██▊       | 20/70 [00:54<02:33,  3.07s/it]Generating...:  29%|██▊       | 20/70 [00:54<02:33,  3.07s/it]Generating...:  29%|██▊       | 20/70 [00:54<02:33,  3.07s/it]Generating...:  29%|██▊       | 20/70 [00:54<02:33,  3.07s/it]Generating...:  29%|██▊       | 20/70 [00:54<02:33,  3.07s/it]Generating...:  29%|██▊       | 20/70 [00:54<02:33,  3.07s/it]Generating...:  29%|██▊       | 20/70 [00:54<02:33,  3.07s/it]Generating...:  30%|███       | 21/70 [00:57<02:32,  3.12s/it]Generating...:  30%|███       | 21/70 [00:57<02:32,  3.12s/it]Generating...:  30%|███       | 21/70 [00:57<02:32,  3.12s/it]Generating...:  30%|███       | 21/70 [00:57<02:32,  3.12s/it]Generating...:  30%|███       | 21/70 [00:57<02:32,  3.12s/it]Generating...:  30%|███       | 21/70 [00:57<02:32,  3.12s/it]Generating...:  30%|███       | 21/70 [00:57<02:32,  3.12s/it]Generating...:  30%|███       | 21/70 [00:57<02:32,  3.12s/it]Generating...:  31%|███▏      | 22/70 [01:01<02:38,  3.31s/it]Generating...:  31%|███▏      | 22/70 [01:01<02:38,  3.31s/it]Generating...:  31%|███▏      | 22/70 [01:01<02:38,  3.31s/it]Generating...:  31%|███▏      | 22/70 [01:01<02:38,  3.31s/it]Generating...:  31%|███▏      | 22/70 [01:01<02:38,  3.31s/it]Generating...:  31%|███▏      | 22/70 [01:01<02:38,  3.31s/it]Generating...:  31%|███▏      | 22/70 [01:01<02:38,  3.31s/it]Generating...:  31%|███▏      | 22/70 [01:01<02:38,  3.31s/it]Generating...:  33%|███▎      | 23/70 [01:04<02:35,  3.32s/it]Generating...:  33%|███▎      | 23/70 [01:04<02:35,  3.32s/it]Generating...:  33%|███▎      | 23/70 [01:04<02:35,  3.32s/it]Generating...:  33%|███▎      | 23/70 [01:04<02:35,  3.32s/it]Generating...:  33%|███▎      | 23/70 [01:04<02:35,  3.32s/it]Generating...:  33%|███▎      | 23/70 [01:04<02:35,  3.32s/it]Generating...:  33%|███▎      | 23/70 [01:04<02:35,  3.32s/it]Generating...:  33%|███▎      | 23/70 [01:04<02:35,  3.32s/it]Generating...:  34%|███▍      | 24/70 [01:07<02:29,  3.25s/it]Generating...:  34%|███▍      | 24/70 [01:07<02:29,  3.25s/it]Generating...:  34%|███▍      | 24/70 [01:07<02:29,  3.25s/it]Generating...:  34%|███▍      | 24/70 [01:07<02:29,  3.25s/it]Generating...:  34%|███▍      | 24/70 [01:07<02:29,  3.25s/it]Generating...:  34%|███▍      | 24/70 [01:07<02:29,  3.25s/it]Generating...:  34%|███▍      | 24/70 [01:07<02:29,  3.25s/it]Generating...:  34%|███▍      | 24/70 [01:07<02:29,  3.25s/it]Generating...:  36%|███▌      | 25/70 [01:10<02:24,  3.20s/it]Generating...:  36%|███▌      | 25/70 [01:10<02:24,  3.20s/it]Generating...:  36%|███▌      | 25/70 [01:10<02:24,  3.20s/it]Generating...:  36%|███▌      | 25/70 [01:10<02:24,  3.20s/it]Generating...:  36%|███▌      | 25/70 [01:10<02:24,  3.20s/it]Generating...:  36%|███▌      | 25/70 [01:10<02:24,  3.20s/it]Generating...:  36%|███▌      | 25/70 [01:10<02:24,  3.20s/it]Generating...:  36%|███▌      | 25/70 [01:10<02:24,  3.20s/it]Generating...:  37%|███▋      | 26/70 [01:13<02:18,  3.15s/it]Generating...:  37%|███▋      | 26/70 [01:13<02:18,  3.15s/it]Generating...:  37%|███▋      | 26/70 [01:13<02:18,  3.15s/it]Generating...:  37%|███▋      | 26/70 [01:13<02:18,  3.15s/it]Generating...:  37%|███▋      | 26/70 [01:13<02:18,  3.15s/it]Generating...:  37%|███▋      | 26/70 [01:13<02:18,  3.15s/it]Generating...:  37%|███▋      | 26/70 [01:13<02:18,  3.15s/it]Generating...:  37%|███▋      | 26/70 [01:13<02:18,  3.15s/it]Generating...:  39%|███▊      | 27/70 [01:16<02:12,  3.08s/it]Generating...:  39%|███▊      | 27/70 [01:16<02:12,  3.08s/it]Generating...:  39%|███▊      | 27/70 [01:16<02:12,  3.08s/it]Generating...:  39%|███▊      | 27/70 [01:16<02:12,  3.08s/it]Generating...:  39%|███▊      | 27/70 [01:16<02:12,  3.08s/it]Generating...:  39%|███▊      | 27/70 [01:16<02:12,  3.08s/it]Generating...:  39%|███▊      | 27/70 [01:16<02:12,  3.08s/it]Generating...:  39%|███▊      | 27/70 [01:16<02:12,  3.08s/it]Generating...:  40%|████      | 28/70 [01:20<02:11,  3.14s/it]Generating...:  40%|████      | 28/70 [01:20<02:11,  3.14s/it]Generating...:  40%|████      | 28/70 [01:20<02:11,  3.14s/it]Generating...:  40%|████      | 28/70 [01:20<02:11,  3.14s/it]Generating...:  40%|████      | 28/70 [01:20<02:11,  3.14s/it]Generating...:  40%|████      | 28/70 [01:20<02:11,  3.14s/it]Generating...:  40%|████      | 28/70 [01:20<02:11,  3.14s/it]Generating...:  40%|████      | 28/70 [01:20<02:11,  3.14s/it]Generating...:  41%|████▏     | 29/70 [01:23<02:07,  3.11s/it]Generating...:  41%|████▏     | 29/70 [01:23<02:07,  3.11s/it]Generating...:  41%|████▏     | 29/70 [01:23<02:07,  3.11s/it]Generating...:  41%|████▏     | 29/70 [01:23<02:07,  3.11s/it]Generating...:  41%|████▏     | 29/70 [01:23<02:07,  3.11s/it]Generating...:  41%|████▏     | 29/70 [01:23<02:07,  3.11s/it]Generating...:  41%|████▏     | 29/70 [01:23<02:07,  3.11s/it]Generating...:  41%|████▏     | 29/70 [01:23<02:07,  3.11s/it]Generating...:  43%|████▎     | 30/70 [01:26<02:03,  3.09s/it]Generating...:  43%|████▎     | 30/70 [01:26<02:03,  3.09s/it]Generating...:  43%|████▎     | 30/70 [01:26<02:03,  3.09s/it]Generating...:  43%|████▎     | 30/70 [01:26<02:03,  3.09s/it]Generating...:  43%|████▎     | 30/70 [01:26<02:03,  3.09s/it]Generating...:  43%|████▎     | 30/70 [01:26<02:03,  3.09s/it]Generating...:  43%|████▎     | 30/70 [01:26<02:03,  3.09s/it]Generating...:  43%|████▎     | 30/70 [01:26<02:03,  3.09s/it]Generating...:  44%|████▍     | 31/70 [01:29<01:59,  3.05s/it]Generating...:  44%|████▍     | 31/70 [01:29<01:59,  3.05s/it]Generating...:  44%|████▍     | 31/70 [01:29<01:59,  3.05s/it]Generating...:  44%|████▍     | 31/70 [01:29<01:59,  3.05s/it]Generating...:  44%|████▍     | 31/70 [01:29<01:59,  3.05s/it]Generating...:  44%|████▍     | 31/70 [01:29<01:59,  3.05s/it]Generating...:  44%|████▍     | 31/70 [01:29<01:59,  3.05s/it]Generating...:  44%|████▍     | 31/70 [01:29<01:59,  3.05s/it]Generating...:  46%|████▌     | 32/70 [01:31<01:47,  2.82s/it]Generating...:  46%|████▌     | 32/70 [01:31<01:47,  2.82s/it]Generating...:  46%|████▌     | 32/70 [01:31<01:47,  2.82s/it]Generating...:  46%|████▌     | 32/70 [01:31<01:47,  2.82s/it]Generating...:  46%|████▌     | 32/70 [01:31<01:47,  2.82s/it]Generating...:  46%|████▌     | 32/70 [01:31<01:47,  2.82s/it]Generating...:  46%|████▌     | 32/70 [01:31<01:47,  2.82s/it]Generating...:  46%|████▌     | 32/70 [01:31<01:47,  2.82s/it]Generating...:  47%|████▋     | 33/70 [01:36<02:05,  3.40s/it]Generating...:  47%|████▋     | 33/70 [01:36<02:05,  3.40s/it]Generating...:  47%|████▋     | 33/70 [01:36<02:05,  3.40s/it]Generating...:  47%|████▋     | 33/70 [01:36<02:05,  3.40s/it]Generating...:  47%|████▋     | 33/70 [01:36<02:05,  3.40s/it]Generating...:  47%|████▋     | 33/70 [01:36<02:05,  3.40s/it]Generating...:  47%|████▋     | 33/70 [01:36<02:05,  3.40s/it]Generating...:  47%|████▋     | 33/70 [01:36<02:05,  3.40s/it]Generating...:  49%|████▊     | 34/70 [01:39<01:58,  3.28s/it]Generating...:  49%|████▊     | 34/70 [01:39<01:58,  3.28s/it]Generating...:  49%|████▊     | 34/70 [01:39<01:58,  3.28s/it]Generating...:  49%|████▊     | 34/70 [01:39<01:58,  3.28s/it]Generating...:  49%|████▊     | 34/70 [01:39<01:58,  3.28s/it]Generating...:  49%|████▊     | 34/70 [01:39<01:58,  3.28s/it]Generating...:  49%|████▊     | 34/70 [01:39<01:58,  3.28s/it]Generating...:  49%|████▊     | 34/70 [01:39<01:58,  3.28s/it]Generating...:  50%|█████     | 35/70 [01:41<01:48,  3.11s/it]Generating...:  50%|█████     | 35/70 [01:41<01:48,  3.11s/it]Generating...:  50%|█████     | 35/70 [01:41<01:48,  3.11s/it]Generating...:  50%|█████     | 35/70 [01:41<01:48,  3.11s/it]Generating...:  50%|█████     | 35/70 [01:41<01:48,  3.11s/it]Generating...:  50%|█████     | 35/70 [01:41<01:48,  3.11s/it]Generating...:  50%|█████     | 35/70 [01:41<01:48,  3.11s/it]Generating...:  50%|█████     | 35/70 [01:41<01:48,  3.11s/it]Generating...:  51%|█████▏    | 36/70 [01:44<01:37,  2.85s/it]Generating...:  51%|█████▏    | 36/70 [01:44<01:37,  2.85s/it]Generating...:  51%|█████▏    | 36/70 [01:44<01:37,  2.85s/it]Generating...:  51%|█████▏    | 36/70 [01:44<01:37,  2.85s/it]Generating...:  51%|█████▏    | 36/70 [01:44<01:37,  2.85s/it]Generating...:  51%|█████▏    | 36/70 [01:44<01:37,  2.85s/it]Generating...:  51%|█████▏    | 36/70 [01:44<01:37,  2.85s/it]Generating...:  51%|█████▏    | 36/70 [01:44<01:37,  2.85s/it]Generating...:  53%|█████▎    | 37/70 [01:47<01:34,  2.87s/it]Generating...:  53%|█████▎    | 37/70 [01:47<01:34,  2.87s/it]Generating...:  53%|█████▎    | 37/70 [01:47<01:34,  2.87s/it]Generating...:  53%|█████▎    | 37/70 [01:47<01:34,  2.87s/it]Generating...:  53%|█████▎    | 37/70 [01:47<01:34,  2.87s/it]Generating...:  53%|█████▎    | 37/70 [01:47<01:34,  2.87s/it]Generating...:  53%|█████▎    | 37/70 [01:47<01:34,  2.87s/it]Generating...:  53%|█████▎    | 37/70 [01:47<01:34,  2.87s/it]Generating...:  54%|█████▍    | 38/70 [01:49<01:30,  2.83s/it]Generating...:  54%|█████▍    | 38/70 [01:49<01:30,  2.83s/it]Generating...:  54%|█████▍    | 38/70 [01:49<01:30,  2.83s/it]Generating...:  54%|█████▍    | 38/70 [01:49<01:30,  2.83s/it]Generating...:  54%|█████▍    | 38/70 [01:49<01:30,  2.83s/it]Generating...:  54%|█████▍    | 38/70 [01:49<01:30,  2.83s/it]Generating...:  54%|█████▍    | 38/70 [01:49<01:30,  2.83s/it]Generating...:  54%|█████▍    | 38/70 [01:49<01:30,  2.83s/it]Generating...:  56%|█████▌    | 39/70 [01:52<01:27,  2.81s/it]Generating...:  56%|█████▌    | 39/70 [01:52<01:27,  2.81s/it]Generating...:  56%|█████▌    | 39/70 [01:52<01:27,  2.81s/it]Generating...:  56%|█████▌    | 39/70 [01:52<01:27,  2.81s/it]Generating...:  56%|█████▌    | 39/70 [01:52<01:27,  2.81s/it]Generating...:  56%|█████▌    | 39/70 [01:52<01:27,  2.81s/it]Generating...:  56%|█████▌    | 39/70 [01:52<01:27,  2.81s/it]Generating...:  56%|█████▌    | 39/70 [01:52<01:27,  2.81s/it]Generating...:  57%|█████▋    | 40/70 [01:54<01:19,  2.64s/it]Generating...:  57%|█████▋    | 40/70 [01:54<01:19,  2.64s/it]Generating...:  57%|█████▋    | 40/70 [01:54<01:19,  2.64s/it]Generating...:  57%|█████▋    | 40/70 [01:54<01:19,  2.64s/it]Generating...:  57%|█████▋    | 40/70 [01:54<01:19,  2.64s/it]Generating...:  57%|█████▋    | 40/70 [01:54<01:19,  2.64s/it]Generating...:  57%|█████▋    | 40/70 [01:54<01:19,  2.64s/it]Generating...:  57%|█████▋    | 40/70 [01:54<01:19,  2.64s/it]Generating...:  59%|█████▊    | 41/70 [01:57<01:13,  2.53s/it]Generating...:  59%|█████▊    | 41/70 [01:57<01:13,  2.53s/it]Generating...:  59%|█████▊    | 41/70 [01:57<01:13,  2.53s/it]Generating...:  59%|█████▊    | 41/70 [01:57<01:13,  2.53s/it]Generating...:  59%|█████▊    | 41/70 [01:57<01:13,  2.53s/it]Generating...:  59%|█████▊    | 41/70 [01:57<01:13,  2.53s/it]Generating...:  59%|█████▊    | 41/70 [01:57<01:13,  2.53s/it]Generating...:  59%|█████▊    | 41/70 [01:57<01:13,  2.53s/it]Generating...:  60%|██████    | 42/70 [01:59<01:12,  2.59s/it]Generating...:  60%|██████    | 42/70 [01:59<01:12,  2.59s/it]Generating...:  60%|██████    | 42/70 [01:59<01:12,  2.59s/it]Generating...:  60%|██████    | 42/70 [01:59<01:12,  2.59s/it]Generating...:  60%|██████    | 42/70 [01:59<01:12,  2.59s/it]Generating...:  60%|██████    | 42/70 [01:59<01:12,  2.59s/it]Generating...:  60%|██████    | 42/70 [01:59<01:12,  2.59s/it]Generating...:  60%|██████    | 42/70 [01:59<01:12,  2.59s/it]Generating...:  61%|██████▏   | 43/70 [02:02<01:07,  2.48s/it]Generating...:  61%|██████▏   | 43/70 [02:02<01:07,  2.48s/it]Generating...:  61%|██████▏   | 43/70 [02:02<01:07,  2.48s/it]Generating...:  61%|██████▏   | 43/70 [02:02<01:07,  2.48s/it]Generating...:  61%|██████▏   | 43/70 [02:02<01:07,  2.48s/it]Generating...:  61%|██████▏   | 43/70 [02:02<01:07,  2.48s/it]Generating...:  61%|██████▏   | 43/70 [02:02<01:07,  2.48s/it]Generating...:  61%|██████▏   | 43/70 [02:02<01:07,  2.48s/it]Generating...:  63%|██████▎   | 44/70 [02:04<01:02,  2.42s/it]Generating...:  63%|██████▎   | 44/70 [02:04<01:02,  2.42s/it]Generating...:  63%|██████▎   | 44/70 [02:04<01:02,  2.42s/it]Generating...:  63%|██████▎   | 44/70 [02:04<01:02,  2.42s/it]Generating...:  63%|██████▎   | 44/70 [02:04<01:02,  2.42s/it]Generating...:  63%|██████▎   | 44/70 [02:04<01:02,  2.42s/it]Generating...:  63%|██████▎   | 44/70 [02:04<01:02,  2.42s/it]Generating...:  63%|██████▎   | 44/70 [02:04<01:02,  2.42s/it]Generating...:  64%|██████▍   | 45/70 [02:06<00:59,  2.37s/it]Generating...:  64%|██████▍   | 45/70 [02:06<00:59,  2.37s/it]Generating...:  64%|██████▍   | 45/70 [02:06<00:59,  2.37s/it]Generating...:  64%|██████▍   | 45/70 [02:06<00:59,  2.37s/it]Generating...:  64%|██████▍   | 45/70 [02:06<00:59,  2.37s/it]Generating...:  64%|██████▍   | 45/70 [02:06<00:59,  2.37s/it]Generating...:  64%|██████▍   | 45/70 [02:06<00:59,  2.37s/it]Generating...:  64%|██████▍   | 45/70 [02:06<00:59,  2.37s/it]Generating...:  66%|██████▌   | 46/70 [02:09<01:00,  2.52s/it]Generating...:  66%|██████▌   | 46/70 [02:09<01:00,  2.52s/it]Generating...:  66%|██████▌   | 46/70 [02:09<01:00,  2.52s/it]Generating...:  66%|██████▌   | 46/70 [02:09<01:00,  2.52s/it]Generating...:  66%|██████▌   | 46/70 [02:09<01:00,  2.52s/it]Generating...:  66%|██████▌   | 46/70 [02:09<01:00,  2.52s/it]Generating...:  66%|██████▌   | 46/70 [02:09<01:00,  2.52s/it]Generating...:  66%|██████▌   | 46/70 [02:09<01:00,  2.52s/it]Generating...:  67%|██████▋   | 47/70 [02:12<00:59,  2.58s/it]Generating...:  67%|██████▋   | 47/70 [02:12<00:59,  2.58s/it]Generating...:  67%|██████▋   | 47/70 [02:12<00:59,  2.58s/it]Generating...:  67%|██████▋   | 47/70 [02:12<00:59,  2.58s/it]Generating...:  67%|██████▋   | 47/70 [02:12<00:59,  2.58s/it]Generating...:  67%|██████▋   | 47/70 [02:12<00:59,  2.58s/it]Generating...:  67%|██████▋   | 47/70 [02:12<00:59,  2.58s/it]Generating...:  67%|██████▋   | 47/70 [02:12<00:59,  2.58s/it]Generating...:  69%|██████▊   | 48/70 [02:14<00:57,  2.63s/it]Generating...:  69%|██████▊   | 48/70 [02:14<00:57,  2.63s/it]Generating...:  69%|██████▊   | 48/70 [02:14<00:57,  2.63s/it]Generating...:  69%|██████▊   | 48/70 [02:14<00:57,  2.63s/it]Generating...:  69%|██████▊   | 48/70 [02:14<00:57,  2.63s/it]Generating...:  69%|██████▊   | 48/70 [02:14<00:57,  2.63s/it]Generating...:  69%|██████▊   | 48/70 [02:14<00:57,  2.63s/it]Generating...:  69%|██████▊   | 48/70 [02:14<00:57,  2.63s/it]Generating...:  70%|███████   | 49/70 [02:17<00:53,  2.53s/it]Generating...:  70%|███████   | 49/70 [02:17<00:53,  2.53s/it]Generating...:  70%|███████   | 49/70 [02:17<00:53,  2.53s/it]Generating...:  70%|███████   | 49/70 [02:17<00:53,  2.53s/it]Generating...:  70%|███████   | 49/70 [02:17<00:53,  2.53s/it]Generating...:  70%|███████   | 49/70 [02:17<00:53,  2.53s/it]Generating...:  70%|███████   | 49/70 [02:17<00:53,  2.53s/it]Generating...:  70%|███████   | 49/70 [02:17<00:53,  2.53s/it]Generating...:  71%|███████▏  | 50/70 [02:19<00:48,  2.45s/it]Generating...:  71%|███████▏  | 50/70 [02:19<00:48,  2.45s/it]Generating...:  71%|███████▏  | 50/70 [02:19<00:48,  2.45s/it]Generating...:  71%|███████▏  | 50/70 [02:19<00:48,  2.45s/it]Generating...:  71%|███████▏  | 50/70 [02:19<00:48,  2.45s/it]Generating...:  71%|███████▏  | 50/70 [02:19<00:48,  2.45s/it]Generating...:  71%|███████▏  | 50/70 [02:19<00:48,  2.45s/it]Generating...:  71%|███████▏  | 50/70 [02:19<00:48,  2.45s/it]Generating...:  73%|███████▎  | 51/70 [02:22<00:49,  2.60s/it]Generating...:  73%|███████▎  | 51/70 [02:22<00:49,  2.60s/it]Generating...:  73%|███████▎  | 51/70 [02:22<00:49,  2.60s/it]Generating...:  73%|███████▎  | 51/70 [02:22<00:49,  2.60s/it]Generating...:  73%|███████▎  | 51/70 [02:22<00:49,  2.60s/it]Generating...:  73%|███████▎  | 51/70 [02:22<00:49,  2.60s/it]Generating...:  73%|███████▎  | 51/70 [02:22<00:49,  2.60s/it]Generating...:  73%|███████▎  | 51/70 [02:22<00:49,  2.60s/it]Generating...:  74%|███████▍  | 52/70 [02:25<00:48,  2.69s/it]Generating...:  74%|███████▍  | 52/70 [02:25<00:48,  2.69s/it]Generating...:  74%|███████▍  | 52/70 [02:25<00:48,  2.69s/it]Generating...:  74%|███████▍  | 52/70 [02:25<00:48,  2.69s/it]Generating...:  74%|███████▍  | 52/70 [02:25<00:48,  2.69s/it]Generating...:  74%|███████▍  | 52/70 [02:25<00:48,  2.69s/it]Generating...:  74%|███████▍  | 52/70 [02:25<00:48,  2.69s/it]Generating...:  74%|███████▍  | 52/70 [02:25<00:48,  2.69s/it]Generating...:  76%|███████▌  | 53/70 [02:29<00:54,  3.22s/it]Generating...:  76%|███████▌  | 53/70 [02:29<00:54,  3.22s/it]Generating...:  76%|███████▌  | 53/70 [02:29<00:54,  3.22s/it]Generating...:  76%|███████▌  | 53/70 [02:29<00:54,  3.22s/it]Generating...:  76%|███████▌  | 53/70 [02:29<00:54,  3.22s/it]Generating...:  76%|███████▌  | 53/70 [02:29<00:54,  3.22s/it]Generating...:  76%|███████▌  | 53/70 [02:29<00:54,  3.22s/it]Generating...:  76%|███████▌  | 53/70 [02:29<00:54,  3.22s/it]Generating...:  77%|███████▋  | 54/70 [02:32<00:51,  3.19s/it]Generating...:  77%|███████▋  | 54/70 [02:32<00:51,  3.19s/it]Generating...:  77%|███████▋  | 54/70 [02:32<00:51,  3.19s/it]Generating...:  77%|███████▋  | 54/70 [02:32<00:51,  3.19s/it]Generating...:  77%|███████▋  | 54/70 [02:32<00:51,  3.19s/it]Generating...:  77%|███████▋  | 54/70 [02:32<00:51,  3.19s/it]Generating...:  77%|███████▋  | 54/70 [02:32<00:51,  3.19s/it]Generating...:  77%|███████▋  | 54/70 [02:32<00:51,  3.19s/it]Generating...:  79%|███████▊  | 55/70 [02:35<00:43,  2.89s/it]Generating...:  79%|███████▊  | 55/70 [02:35<00:43,  2.89s/it]Generating...:  79%|███████▊  | 55/70 [02:35<00:43,  2.89s/it]Generating...:  79%|███████▊  | 55/70 [02:35<00:43,  2.89s/it]Generating...:  79%|███████▊  | 55/70 [02:35<00:43,  2.89s/it]Generating...:  79%|███████▊  | 55/70 [02:35<00:43,  2.89s/it]Generating...:  79%|███████▊  | 55/70 [02:35<00:43,  2.89s/it]Generating...:  79%|███████▊  | 55/70 [02:35<00:43,  2.89s/it]Generating...:  80%|████████  | 56/70 [02:37<00:39,  2.86s/it]Generating...:  80%|████████  | 56/70 [02:37<00:39,  2.86s/it]Generating...:  80%|████████  | 56/70 [02:37<00:39,  2.86s/it]Generating...:  80%|████████  | 56/70 [02:37<00:39,  2.86s/it]Generating...:  80%|████████  | 56/70 [02:37<00:39,  2.86s/it]Generating...:  80%|████████  | 56/70 [02:37<00:39,  2.86s/it]Generating...:  80%|████████  | 56/70 [02:37<00:39,  2.86s/it]Generating...:  80%|████████  | 56/70 [02:37<00:39,  2.86s/it]Generating...:  81%|████████▏ | 57/70 [02:40<00:37,  2.85s/it]Generating...:  81%|████████▏ | 57/70 [02:40<00:37,  2.85s/it]Generating...:  81%|████████▏ | 57/70 [02:40<00:37,  2.85s/it]Generating...:  81%|████████▏ | 57/70 [02:40<00:37,  2.85s/it]Generating...:  81%|████████▏ | 57/70 [02:40<00:37,  2.85s/it]Generating...:  81%|████████▏ | 57/70 [02:40<00:37,  2.85s/it]Generating...:  81%|████████▏ | 57/70 [02:40<00:37,  2.85s/it]Generating...:  81%|████████▏ | 57/70 [02:40<00:37,  2.85s/it]Generating...:  83%|████████▎ | 58/70 [02:43<00:33,  2.82s/it]Generating...:  83%|████████▎ | 58/70 [02:43<00:33,  2.82s/it]Generating...:  83%|████████▎ | 58/70 [02:43<00:33,  2.82s/it]Generating...:  83%|████████▎ | 58/70 [02:43<00:33,  2.82s/it]Generating...:  83%|████████▎ | 58/70 [02:43<00:33,  2.82s/it]Generating...:  83%|████████▎ | 58/70 [02:43<00:33,  2.82s/it]Generating...:  83%|████████▎ | 58/70 [02:43<00:33,  2.82s/it]Generating...:  83%|████████▎ | 58/70 [02:43<00:33,  2.82s/it]Generating...:  84%|████████▍ | 59/70 [02:46<00:31,  2.86s/it]Generating...:  84%|████████▍ | 59/70 [02:46<00:31,  2.86s/it]Generating...:  84%|████████▍ | 59/70 [02:46<00:31,  2.86s/it]Generating...:  84%|████████▍ | 59/70 [02:46<00:31,  2.86s/it]Generating...:  84%|████████▍ | 59/70 [02:46<00:31,  2.86s/it]Generating...:  84%|████████▍ | 59/70 [02:46<00:31,  2.86s/it]Generating...:  84%|████████▍ | 59/70 [02:46<00:31,  2.86s/it]Generating...:  84%|████████▍ | 59/70 [02:46<00:31,  2.86s/it]Generating...:  86%|████████▌ | 60/70 [02:49<00:28,  2.83s/it]Generating...:  86%|████████▌ | 60/70 [02:49<00:28,  2.83s/it]Generating...:  86%|████████▌ | 60/70 [02:49<00:28,  2.83s/it]Generating...:  86%|████████▌ | 60/70 [02:49<00:28,  2.83s/it]Generating...:  86%|████████▌ | 60/70 [02:49<00:28,  2.83s/it]Generating...:  86%|████████▌ | 60/70 [02:49<00:28,  2.83s/it]Generating...:  86%|████████▌ | 60/70 [02:49<00:28,  2.83s/it]Generating...:  86%|████████▌ | 60/70 [02:49<00:28,  2.83s/it]Generating...:  87%|████████▋ | 61/70 [02:52<00:26,  2.92s/it]Generating...:  87%|████████▋ | 61/70 [02:52<00:26,  2.92s/it]Generating...:  87%|████████▋ | 61/70 [02:52<00:26,  2.92s/it]Generating...:  87%|████████▋ | 61/70 [02:52<00:26,  2.92s/it]Generating...:  87%|████████▋ | 61/70 [02:52<00:26,  2.92s/it]Generating...:  87%|████████▋ | 61/70 [02:52<00:26,  2.92s/it]Generating...:  87%|████████▋ | 61/70 [02:52<00:26,  2.92s/it]Generating...:  87%|████████▋ | 61/70 [02:52<00:26,  2.92s/it]Generating...:  89%|████████▊ | 62/70 [02:55<00:22,  2.87s/it]Generating...:  89%|████████▊ | 62/70 [02:55<00:22,  2.87s/it]Generating...:  89%|████████▊ | 62/70 [02:55<00:22,  2.87s/it]Generating...:  89%|████████▊ | 62/70 [02:55<00:22,  2.87s/it]Generating...:  89%|████████▊ | 62/70 [02:55<00:22,  2.87s/it]Generating...:  89%|████████▊ | 62/70 [02:55<00:22,  2.87s/it]Generating...:  89%|████████▊ | 62/70 [02:55<00:22,  2.87s/it]Generating...:  89%|████████▊ | 62/70 [02:55<00:22,  2.87s/it]Generating...:  90%|█████████ | 63/70 [02:59<00:22,  3.22s/it]Generating...:  90%|█████████ | 63/70 [02:59<00:22,  3.22s/it]Generating...:  90%|█████████ | 63/70 [02:59<00:22,  3.22s/it]Generating...:  90%|█████████ | 63/70 [02:59<00:22,  3.22s/it]Generating...:  90%|█████████ | 63/70 [02:59<00:22,  3.22s/it]Generating...:  90%|█████████ | 63/70 [02:59<00:22,  3.22s/it]Generating...:  90%|█████████ | 63/70 [02:59<00:22,  3.22s/it]Generating...:  90%|█████████ | 63/70 [02:59<00:22,  3.22s/it]Generating...:  91%|█████████▏| 64/70 [03:01<00:18,  3.08s/it]Generating...:  91%|█████████▏| 64/70 [03:01<00:18,  3.08s/it]Generating...:  91%|█████████▏| 64/70 [03:01<00:18,  3.08s/it]Generating...:  91%|█████████▏| 64/70 [03:01<00:18,  3.08s/it]Generating...:  91%|█████████▏| 64/70 [03:01<00:18,  3.08s/it]Generating...:  91%|█████████▏| 64/70 [03:01<00:18,  3.08s/it]Generating...:  91%|█████████▏| 64/70 [03:01<00:18,  3.08s/it]Generating...:  91%|█████████▏| 64/70 [03:01<00:18,  3.08s/it]Generating...:  93%|█████████▎| 65/70 [03:04<00:14,  2.98s/it]Generating...:  93%|█████████▎| 65/70 [03:04<00:14,  2.98s/it]Generating...:  93%|█████████▎| 65/70 [03:04<00:14,  2.98s/it]Generating...:  93%|█████████▎| 65/70 [03:04<00:14,  2.98s/it]Generating...:  93%|█████████▎| 65/70 [03:04<00:14,  2.98s/it]Generating...:  93%|█████████▎| 65/70 [03:04<00:14,  2.98s/it]Generating...:  93%|█████████▎| 65/70 [03:04<00:14,  2.98s/it]Generating...:  93%|█████████▎| 65/70 [03:04<00:14,  2.98s/it]Generating...:  94%|█████████▍| 66/70 [03:06<00:11,  2.77s/it]Generating...:  94%|█████████▍| 66/70 [03:06<00:11,  2.77s/it]Generating...:  94%|█████████▍| 66/70 [03:06<00:11,  2.77s/it]Generating...:  94%|█████████▍| 66/70 [03:06<00:11,  2.77s/it]Generating...:  94%|█████████▍| 66/70 [03:06<00:11,  2.77s/it]Generating...:  94%|█████████▍| 66/70 [03:06<00:11,  2.77s/it]Generating...:  94%|█████████▍| 66/70 [03:06<00:11,  2.77s/it]Generating...:  94%|█████████▍| 66/70 [03:06<00:11,  2.77s/it]Generating...:  96%|█████████▌| 67/70 [03:09<00:08,  2.83s/it]Generating...:  96%|█████████▌| 67/70 [03:09<00:08,  2.83s/it]Generating...:  96%|█████████▌| 67/70 [03:09<00:08,  2.83s/it]Generating...:  96%|█████████▌| 67/70 [03:09<00:08,  2.83s/it]Generating...:  96%|█████████▌| 67/70 [03:09<00:08,  2.83s/it]Generating...:  96%|█████████▌| 67/70 [03:09<00:08,  2.83s/it]Generating...:  96%|█████████▌| 67/70 [03:09<00:08,  2.83s/it]Generating...:  96%|█████████▌| 67/70 [03:09<00:08,  2.83s/it]Generating...:  97%|█████████▋| 68/70 [03:12<00:05,  2.89s/it]Generating...:  97%|█████████▋| 68/70 [03:12<00:05,  2.89s/it]Generating...:  97%|█████████▋| 68/70 [03:12<00:05,  2.89s/it]Generating...:  97%|█████████▋| 68/70 [03:12<00:05,  2.89s/it]Generating...:  97%|█████████▋| 68/70 [03:12<00:05,  2.89s/it]Generating...:  97%|█████████▋| 68/70 [03:12<00:05,  2.89s/it]Generating...:  97%|█████████▋| 68/70 [03:12<00:05,  2.89s/it]Generating...:  97%|█████████▋| 68/70 [03:12<00:05,  2.89s/it]Generating...:  99%|█████████▊| 69/70 [03:15<00:02,  2.85s/it]Generating...:  99%|█████████▊| 69/70 [03:15<00:02,  2.85s/it]Generating...:  99%|█████████▊| 69/70 [03:15<00:02,  2.85s/it]Generating...:  99%|█████████▊| 69/70 [03:15<00:02,  2.85s/it]Generating...:  99%|█████████▊| 69/70 [03:15<00:02,  2.85s/it]Generating...:  99%|█████████▊| 69/70 [03:15<00:02,  2.85s/it]Generating...:  99%|█████████▊| 69/70 [03:15<00:02,  2.85s/it]Generating...:  99%|█████████▊| 69/70 [03:15<00:02,  2.85s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.87s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.87s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.87s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.87s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.87s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.87s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.87s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.87s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.84s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.84s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.84s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.84s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.84s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.84s/it]
Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.84s/it]Generating...: 100%|██████████| 70/70 [03:18<00:00,  2.84s/it]






[rank7]:W1110 14:08:42.074000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 29463 hash value: 17409055740863377138
[rank2]:W1110 14:08:42.102000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 31429 hash value: 14689999080920913805
[rank6]:W1110 14:08:42.171000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32757 hash value: 8781102258674998447
[rank1]:W1110 14:08:42.264000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 29677 hash value: 15065692456837483647
[rank3]:W1110 14:08:42.453000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30023 hash value: 12350207209889819237
[rank0]:W1110 14:08:42.564000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 29347 hash value: 4375144234715167480
[rank5]:W1110 14:08:42.582000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 28549 hash value: 15338591608398401266
[rank4]:W1110 14:08:42.623000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 31330 hash value: 10461429100824931754
[rank0]:W1110 14:08:42.806000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 32757 hash value: 1216832004101442127
[rank0]:W1110 14:08:42.808000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 32757 hash value: 1216832004101442127
[rank0]:W1110 14:08:42.810000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 32757 hash value: 1216832004101442127
[rank0]:W1110 14:08:42.812000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 32757 hash value: 1216832004101442127
[rank0]:W1110 14:08:42.814000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 32757 hash value: 1216832004101442127
[rank1]:W1110 14:08:42.815000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank5]:W1110 14:08:42.815000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank4]:W1110 14:08:42.815000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:08:42.815000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank2]:W1110 14:08:42.815000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:08:42.815000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:08:42.815000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:42.816000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 32757 hash value: 1216832004101442127
[rank0]:W1110 14:08:42.821000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 32757 hash value: 1216832004101442127
[rank0]:W1110 14:08:42.822000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 32757 hash value: 1216832004101442127
[rank0]:W1110 14:08:42.824000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:08:42.828000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5470268475356389102
[rank5]:W1110 14:08:42.828000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811288349344093
[rank6]:W1110 14:08:42.828000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634553868653783364
[rank4]:W1110 14:08:42.828000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5859782613744783699
[rank3]:W1110 14:08:42.828000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 262382661208901368
[rank2]:W1110 14:08:42.828000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475570979164714397
[rank7]:W1110 14:08:42.828000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 3192744725797894895
[rank1]:W1110 14:08:42.828000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12782271699394995588
[rank0]:W1110 14:08:42.830000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5470268475356389102
[rank0]:W1110 14:08:42.833000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5470268475356389102
[rank0]:W1110 14:08:42.834000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5470268475356389102
[rank0]:W1110 14:08:42.835000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5470268475356389102
[rank0]:W1110 14:08:42.836000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5470268475356389102
[rank0]:W1110 14:08:42.837000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5470268475356389102
[rank0]:W1110 14:08:42.838000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5470268475356389102
[rank0]:W1110 14:08:42.839000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 5135116141073894608
[rank0]:W1110 14:08:42.843000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10327086409373641479
[rank7]:W1110 14:08:42.843000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32878 hash value: 264437919736602634
[rank5]:W1110 14:08:42.843000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36043 hash value: 3013754945440877377
[rank6]:W1110 14:08:42.843000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34319 hash value: 13358572984376016294
[rank3]:W1110 14:08:42.843000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33261 hash value: 4060811453444832405
[rank1]:W1110 14:08:42.843000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35868 hash value: 453369085219000164
[rank2]:W1110 14:08:42.843000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35969 hash value: 10976331734622760668
[rank4]:W1110 14:08:42.843000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 29662 hash value: 14232281498716679962
[rank0]:W1110 14:08:42.844000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10327086409373641479
[rank0]:W1110 14:08:42.848000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10327086409373641479
[rank0]:W1110 14:08:42.849000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10327086409373641479
[rank0]:W1110 14:08:42.850000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10327086409373641479
[rank0]:W1110 14:08:42.851000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10327086409373641479
[rank0]:W1110 14:08:42.852000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10327086409373641479
[rank0]:W1110 14:08:42.852000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 10327086409373641479
[rank0]:W1110 14:08:42.854000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34263 hash value: 9233443461477236518
[rank6]:W1110 14:08:42.858000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:08:42.858000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:08:42.858000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank5]:W1110 14:08:42.858000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9223449677976106806
[rank1]:W1110 14:08:42.858000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank4]:W1110 14:08:42.858000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank2]:W1110 14:08:42.858000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:42.858000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36043 hash value: 13323246473676416285
[rank0]:W1110 14:08:42.863000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36043 hash value: 13323246473676416285
[rank0]:W1110 14:08:42.865000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36043 hash value: 13323246473676416285
[rank0]:W1110 14:08:42.866000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36043 hash value: 13323246473676416285
[rank0]:W1110 14:08:42.868000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36043 hash value: 13323246473676416285
[rank0]:W1110 14:08:42.870000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36043 hash value: 13323246473676416285
[rank0]:W1110 14:08:42.871000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36043 hash value: 13323246473676416285
[rank0]:W1110 14:08:42.873000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36043 hash value: 13323246473676416285
[rank0]:W1110 14:08:42.874000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:42.878000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2672403330962132764
[rank4]:W1110 14:08:42.878000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891809526
[rank5]:W1110 14:08:42.878000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 11154959494617359233
[rank6]:W1110 14:08:42.878000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank7]:W1110 14:08:42.878000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank3]:W1110 14:08:42.878000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994949750259
[rank1]:W1110 14:08:42.878000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank2]:W1110 14:08:42.878000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 16858811488333850520
[rank0]:W1110 14:08:42.880000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2672403330962132764
[rank0]:W1110 14:08:42.883000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2672403330962132764
[rank0]:W1110 14:08:42.884000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2672403330962132764
[rank0]:W1110 14:08:42.885000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2672403330962132764
[rank0]:W1110 14:08:42.885000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2672403330962132764
[rank0]:W1110 14:08:42.887000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2672403330962132764
[rank0]:W1110 14:08:42.888000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2672403330962132764
[rank0]:W1110 14:08:42.889000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank0]:W1110 14:08:42.893000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 104260649779927366
[rank5]:W1110 14:08:42.893000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38057 hash value: 10682694951466319608
[rank6]:W1110 14:08:42.893000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40617 hash value: 13626151635276397582
[rank2]:W1110 14:08:42.893000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38907 hash value: 7137645069533010551
[rank4]:W1110 14:08:42.893000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40659 hash value: 13356692443923899101
[rank3]:W1110 14:08:42.893000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40553 hash value: 3208847134998757167
[rank7]:W1110 14:08:42.893000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37715 hash value: 14068704043794746268
[rank1]:W1110 14:08:42.893000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36924 hash value: 2141036902634523858
[rank0]:W1110 14:08:42.894000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 104260649779927366
[rank0]:W1110 14:08:42.898000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 104260649779927366
[rank0]:W1110 14:08:42.899000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 104260649779927366
[rank0]:W1110 14:08:42.900000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 104260649779927366
[rank0]:W1110 14:08:42.901000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 104260649779927366
[rank0]:W1110 14:08:42.901000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 104260649779927366
[rank0]:W1110 14:08:42.902000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 104260649779927366
[rank0]:W1110 14:08:42.904000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38973 hash value: 10736037149098730040
[rank6]:W1110 14:08:42.908000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank2]:W1110 14:08:42.908000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:42.908000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40659 hash value: 12357554403047530554
[rank7]:W1110 14:08:42.908000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank5]:W1110 14:08:42.908000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank1]:W1110 14:08:42.908000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank4]:W1110 14:08:42.908000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:08:42.908000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank0]:W1110 14:08:42.911000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40659 hash value: 12357554403047530554
[rank0]:W1110 14:08:42.913000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40659 hash value: 12357554403047530554
[rank0]:W1110 14:08:42.915000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40659 hash value: 12357554403047530554
[rank0]:W1110 14:08:42.918000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40659 hash value: 12357554403047530554
[rank0]:W1110 14:08:42.920000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40659 hash value: 12357554403047530554
[rank0]:W1110 14:08:42.922000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40659 hash value: 12357554403047530554
[rank0]:W1110 14:08:42.923000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40659 hash value: 12357554403047530554
[rank0]:W1110 14:08:42.924000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:42.928000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2060301396965553833
[rank7]:W1110 14:08:42.929000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank5]:W1110 14:08:42.929000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank6]:W1110 14:08:42.929000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7824157749611474686
[rank1]:W1110 14:08:42.929000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank4]:W1110 14:08:42.929000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank2]:W1110 14:08:42.929000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:08:42.929000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank0]:W1110 14:08:42.930000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2060301396965553833
[rank0]:W1110 14:08:42.933000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2060301396965553833
[rank0]:W1110 14:08:42.934000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2060301396965553833
[rank0]:W1110 14:08:42.935000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2060301396965553833
[rank0]:W1110 14:08:42.936000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2060301396965553833
[rank0]:W1110 14:08:42.937000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2060301396965553833
[rank0]:W1110 14:08:42.938000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 2060301396965553833
[rank0]:W1110 14:08:42.939000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:42.943000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8987344773529516040
[rank5]:W1110 14:08:42.943000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34844 hash value: 14341517719299905488
[rank6]:W1110 14:08:42.943000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32784 hash value: 3180765783695445965
[rank2]:W1110 14:08:42.943000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35190 hash value: 16905226008568430340
[rank7]:W1110 14:08:42.943000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35240 hash value: 2493473474462383670
[rank1]:W1110 14:08:42.943000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35788 hash value: 175064856975321388
[rank3]:W1110 14:08:42.943000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32421 hash value: 14821225241025133305
[rank4]:W1110 14:08:42.943000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34306 hash value: 10137348062461674000
[rank0]:W1110 14:08:42.944000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8987344773529516040
[rank0]:W1110 14:08:42.948000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8987344773529516040
[rank0]:W1110 14:08:42.949000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8987344773529516040
[rank0]:W1110 14:08:42.950000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8987344773529516040
[rank0]:W1110 14:08:42.951000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8987344773529516040
[rank0]:W1110 14:08:42.952000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8987344773529516040
[rank0]:W1110 14:08:42.953000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8987344773529516040
[rank0]:W1110 14:08:42.954000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32913 hash value: 6261952363565716860
[rank5]:W1110 14:08:42.959000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:08:42.959000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank4]:W1110 14:08:42.959000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:08:42.959000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284946882
[rank2]:W1110 14:08:42.959000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:08:42.959000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284934289
[rank1]:W1110 14:08:42.959000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 1973457474976058696
[rank0]:W1110 14:08:42.960000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35788 hash value: 13911341944614264747
[rank0]:W1110 14:08:42.964000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35788 hash value: 13911341944614264747
[rank0]:W1110 14:08:42.966000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35788 hash value: 13911341944614264747
[rank0]:W1110 14:08:42.968000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35788 hash value: 13911341944614264747
[rank0]:W1110 14:08:42.969000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35788 hash value: 13911341944614264747
[rank0]:W1110 14:08:42.971000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35788 hash value: 13911341944614264747
[rank0]:W1110 14:08:42.973000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35788 hash value: 13911341944614264747
[rank0]:W1110 14:08:42.974000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 35788 hash value: 13911341944614264747
[rank0]:W1110 14:08:42.976000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank0]:W1110 14:08:42.979000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9567427820623407926
[rank2]:W1110 14:08:42.980000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994949746626
[rank5]:W1110 14:08:42.980000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:08:42.980000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank7]:W1110 14:08:42.980000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7391278077284946882
[rank1]:W1110 14:08:42.980000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17845255026049041173
[rank4]:W1110 14:08:42.980000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank3]:W1110 14:08:42.980000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634553868251696383
[rank0]:W1110 14:08:42.981000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9567427820623407926
[rank0]:W1110 14:08:42.985000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9567427820623407926
[rank0]:W1110 14:08:42.986000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9567427820623407926
[rank0]:W1110 14:08:42.987000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9567427820623407926
[rank0]:W1110 14:08:42.988000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9567427820623407926
[rank0]:W1110 14:08:42.989000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9567427820623407926
[rank0]:W1110 14:08:42.990000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 9567427820623407926
[rank0]:W1110 14:08:42.991000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530102404780745
[rank5]:W1110 14:08:42.995000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32261 hash value: 11238312195812609947
[rank0]:W1110 14:08:42.995000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14827904801747279041
[rank6]:W1110 14:08:42.995000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 31631 hash value: 3521928690179852988
[rank2]:W1110 14:08:42.995000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 34411 hash value: 249271231734475448
[rank4]:W1110 14:08:42.995000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32283 hash value: 12046108088619718550
[rank3]:W1110 14:08:42.995000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 31131 hash value: 8174911735980309987
[rank7]:W1110 14:08:42.995000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32936 hash value: 10345008375206452411
[rank1]:W1110 14:08:42.995000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 31166 hash value: 3834413717698963576
[rank0]:W1110 14:08:42.998000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14827904801747279041
[rank0]:W1110 14:08:43.001000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14827904801747279041
[rank0]:W1110 14:08:43.002000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14827904801747279041
[rank0]:W1110 14:08:43.003000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14827904801747279041
[rank0]:W1110 14:08:43.004000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14827904801747279041
[rank0]:W1110 14:08:43.005000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14827904801747279041
[rank0]:W1110 14:08:43.006000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 14827904801747279041
[rank0]:W1110 14:08:43.007000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 31844 hash value: 7945531796494529591
[rank6]:W1110 14:08:43.011000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank5]:W1110 14:08:43.011000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:08:43.011000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank1]:W1110 14:08:43.011000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank4]:W1110 14:08:43.011000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9223449677976106806
[rank3]:W1110 14:08:43.011000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank2]:W1110 14:08:43.011000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:43.011000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34411 hash value: 7297790159548938148
[rank0]:W1110 14:08:43.017000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34411 hash value: 7297790159548938148
[rank0]:W1110 14:08:43.018000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34411 hash value: 7297790159548938148
[rank0]:W1110 14:08:43.020000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34411 hash value: 7297790159548938148
[rank0]:W1110 14:08:43.022000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34411 hash value: 7297790159548938148
[rank0]:W1110 14:08:43.024000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34411 hash value: 7297790159548938148
[rank0]:W1110 14:08:43.025000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34411 hash value: 7297790159548938148
[rank0]:W1110 14:08:43.027000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 34411 hash value: 7297790159548938148
[rank0]:W1110 14:08:43.028000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank0]:W1110 14:08:43.032000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17861258521211492116
[rank3]:W1110 14:08:43.032000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9707684007058040015
[rank5]:W1110 14:08:43.032000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:08:43.032000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank4]:W1110 14:08:43.032000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8350198465046513010
[rank2]:W1110 14:08:43.032000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580209614566759
[rank1]:W1110 14:08:43.032000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 12760118203891625443
[rank7]:W1110 14:08:43.032000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:43.034000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17861258521211492116
[rank0]:W1110 14:08:43.038000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17861258521211492116
[rank0]:W1110 14:08:43.039000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17861258521211492116
[rank0]:W1110 14:08:43.040000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17861258521211492116
[rank0]:W1110 14:08:43.041000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17861258521211492116
[rank0]:W1110 14:08:43.042000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17861258521211492116
[rank0]:W1110 14:08:43.043000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 17861258521211492116
[rank0]:W1110 14:08:43.044000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8163821284794975731
[rank0]:W1110 14:08:43.048000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15606369306696614026
[rank3]:W1110 14:08:43.048000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32276 hash value: 16042352434273932848
[rank6]:W1110 14:08:43.048000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 32658 hash value: 10788360621657808666
[rank7]:W1110 14:08:43.048000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 29863 hash value: 16914526816847914155
[rank4]:W1110 14:08:43.048000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30951 hash value: 10354058848582352237
[rank2]:W1110 14:08:43.048000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 29510 hash value: 14361150885732155990
[rank5]:W1110 14:08:43.048000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33112 hash value: 12688333897420550760
[rank1]:W1110 14:08:43.048000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 30964 hash value: 6933586255340935093
[rank0]:W1110 14:08:43.049000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15606369306696614026
[rank0]:W1110 14:08:43.053000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15606369306696614026
[rank0]:W1110 14:08:43.054000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15606369306696614026
[rank0]:W1110 14:08:43.055000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15606369306696614026
[rank0]:W1110 14:08:43.056000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15606369306696614026
[rank0]:W1110 14:08:43.057000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15606369306696614026
[rank0]:W1110 14:08:43.058000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 15606369306696614026
[rank0]:W1110 14:08:43.059000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 33253 hash value: 2284827220684638653
[rank6]:W1110 14:08:43.063000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank5]:W1110 14:08:43.063000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank7]:W1110 14:08:43.063000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank4]:W1110 14:08:43.063000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8422895373523365856
[rank1]:W1110 14:08:43.063000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:08:43.063000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank2]:W1110 14:08:43.063000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475570979382230377
[rank0]:W1110 14:08:43.063000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33253 hash value: 1678624860013900016
[rank0]:W1110 14:08:43.068000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33253 hash value: 1678624860013900016
[rank0]:W1110 14:08:43.070000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33253 hash value: 1678624860013900016
[rank0]:W1110 14:08:43.071000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33253 hash value: 1678624860013900016
[rank0]:W1110 14:08:43.073000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33253 hash value: 1678624860013900016
[rank0]:W1110 14:08:43.075000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33253 hash value: 1678624860013900016
[rank0]:W1110 14:08:43.077000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33253 hash value: 1678624860013900016
[rank0]:W1110 14:08:43.078000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 33253 hash value: 1678624860013900016
[rank0]:W1110 14:08:43.080000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:43.084000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4689582657822675909
[rank5]:W1110 14:08:43.084000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8627674158715579790
[rank1]:W1110 14:08:43.084000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8617183975846398200
[rank6]:W1110 14:08:43.084000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 262382661208913771
[rank4]:W1110 14:08:43.084000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2510288887705533962
[rank7]:W1110 14:08:43.084000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 17424607371410957225
[rank3]:W1110 14:08:43.084000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9799981658433655582
[rank2]:W1110 14:08:43.084000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 8826366845631612472
[rank0]:W1110 14:08:43.086000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4689582657822675909
[rank0]:W1110 14:08:43.089000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4689582657822675909
[rank0]:W1110 14:08:43.090000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4689582657822675909
[rank0]:W1110 14:08:43.091000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4689582657822675909
[rank0]:W1110 14:08:43.092000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4689582657822675909
[rank0]:W1110 14:08:43.093000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4689582657822675909
[rank0]:W1110 14:08:43.094000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 4689582657822675909
[rank0]:W1110 14:08:43.095000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920318652597485750
[rank0]:W1110 14:08:43.099000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5336656202908405761
[rank7]:W1110 14:08:43.099000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 37133 hash value: 1501834913463228265
[rank6]:W1110 14:08:43.099000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35268 hash value: 8786451773992072913
[rank5]:W1110 14:08:43.099000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35538 hash value: 9960929681425523236
[rank4]:W1110 14:08:43.099000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 40307 hash value: 1582367801518197545
[rank3]:W1110 14:08:43.099000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36053 hash value: 15401932662226628427
[rank2]:W1110 14:08:43.099000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 35052 hash value: 495362913983419106
[rank1]:W1110 14:08:43.099000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 39922 hash value: 16210983973942806886
[rank0]:W1110 14:08:43.100000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5336656202908405761
[rank0]:W1110 14:08:43.104000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5336656202908405761
[rank0]:W1110 14:08:43.105000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5336656202908405761
[rank0]:W1110 14:08:43.106000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5336656202908405761
[rank0]:W1110 14:08:43.107000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5336656202908405761
[rank0]:W1110 14:08:43.108000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5336656202908405761
[rank0]:W1110 14:08:43.109000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 5336656202908405761
[rank0]:W1110 14:08:43.110000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 38910 hash value: 10928022483985620270
[rank5]:W1110 14:08:43.114000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank6]:W1110 14:08:43.114000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9223449677976106806
[rank4]:W1110 14:08:43.114000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank7]:W1110 14:08:43.114000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194379124359
[rank3]:W1110 14:08:43.114000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank2]:W1110 14:08:43.114000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415655568741
[rank1]:W1110 14:08:43.114000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:43.115000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40307 hash value: 14216679283120244693
[rank0]:W1110 14:08:43.119000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40307 hash value: 14216679283120244693
[rank0]:W1110 14:08:43.121000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40307 hash value: 14216679283120244693
[rank0]:W1110 14:08:43.123000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40307 hash value: 14216679283120244693
[rank0]:W1110 14:08:43.125000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40307 hash value: 14216679283120244693
[rank0]:W1110 14:08:43.126000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40307 hash value: 14216679283120244693
[rank0]:W1110 14:08:43.128000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40307 hash value: 14216679283120244693
[rank0]:W1110 14:08:43.130000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 40307 hash value: 14216679283120244693
[rank0]:W1110 14:08:43.131000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank0]:W1110 14:08:43.135000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 1421755330084609470
[rank7]:W1110 14:08:43.135000 11928 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14920316194395188097
[rank6]:W1110 14:08:43.135000 11927 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 6475571178142554729
[rank5]:W1110 14:08:43.135000 11926 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 9223450630421535561
[rank4]:W1110 14:08:43.135000 11924 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908222809
[rank3]:W1110 14:08:43.135000 11923 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 100762994949746626
[rank1]:W1110 14:08:43.135000 11921 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 14941580415908223210
[rank2]:W1110 14:08:43.135000 11922 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 2080530100130247313
[rank0]:W1110 14:08:43.137000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 1421755330084609470
[rank0]:W1110 14:08:43.140000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 1421755330084609470
[rank0]:W1110 14:08:43.141000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 1421755330084609470
[rank0]:W1110 14:08:43.142000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 1421755330084609470
[rank0]:W1110 14:08:43.143000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 1421755330084609470
[rank0]:W1110 14:08:43.144000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 1421755330084609470
[rank0]:W1110 14:08:43.145000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 1421755330084609470
[rank0]:W1110 14:08:43.146000 11919 site-packages/torch/distributed/distributed_c10d.py:2632] _object_to_tensor size: 36 hash value: 7634553868251725038
[rank0]:W1110 14:08:43.150000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8683200300839872551
[rank0]:W1110 14:08:43.151000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8683200300839872551
[rank0]:W1110 14:08:43.152000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8683200300839872551
[rank0]:W1110 14:08:43.153000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8683200300839872551
[rank0]:W1110 14:08:43.154000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8683200300839872551
[rank0]:W1110 14:08:43.155000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8683200300839872551
[rank0]:W1110 14:08:43.156000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8683200300839872551
[rank0]:W1110 14:08:43.157000 11919 site-packages/torch/distributed/distributed_c10d.py:2644] _tensor_to_object size: 36 hash value: 8683200300839872551
2025-11-10:14:08:50 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
2025-11-10:14:08:50 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_algebra
2025-11-10:14:08:50 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_counting_and_prob
2025-11-10:14:08:50 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_geometry
2025-11-10:14:08:50 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_intermediate_algebra
2025-11-10:14:08:51 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_num_theory
2025-11-10:14:08:51 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_prealgebra
2025-11-10:14:08:51 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: minerva_math_precalc
[rank0]:[W1110 14:08:52.334021713 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
